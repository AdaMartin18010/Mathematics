# çŸ©é˜µåˆ†è§£ (Matrix Decompositions)

> **The Computational Foundation of Machine Learning**
>
> æœºå™¨å­¦ä¹ çš„è®¡ç®—åŸºç¡€

---

## ç›®å½•

- [çŸ©é˜µåˆ†è§£ (Matrix Decompositions)](#çŸ©é˜µåˆ†è§£-matrix-decompositions)
  - [ç›®å½•](#ç›®å½•)
  - [ðŸ“‹ æ ¸å¿ƒæ€æƒ³](#-æ ¸å¿ƒæ€æƒ³)
  - [ðŸŽ¯ ç‰¹å¾å€¼åˆ†è§£ (Eigendecomposition)](#-ç‰¹å¾å€¼åˆ†è§£-eigendecomposition)
    - [1. ç‰¹å¾å€¼ä¸Žç‰¹å¾å‘é‡](#1-ç‰¹å¾å€¼ä¸Žç‰¹å¾å‘é‡)
    - [2. è°±å®šç†](#2-è°±å®šç†)
    - [3. å¯¹è§’åŒ–](#3-å¯¹è§’åŒ–)
  - [ðŸ“Š å¥‡å¼‚å€¼åˆ†è§£ (SVD)](#-å¥‡å¼‚å€¼åˆ†è§£-svd)
    - [1. SVDå®šä¹‰](#1-svdå®šä¹‰)
    - [2. å‡ ä½•è§£é‡Š](#2-å‡ ä½•è§£é‡Š)
    - [3. æˆªæ–­SVDä¸Žä½Žç§©è¿‘ä¼¼](#3-æˆªæ–­svdä¸Žä½Žç§©è¿‘ä¼¼)
    - [4. SVDçš„æ€§è´¨](#4-svdçš„æ€§è´¨)
  - [ðŸ”¬ QRåˆ†è§£](#-qråˆ†è§£)
    - [1. QRåˆ†è§£å®šä¹‰](#1-qråˆ†è§£å®šä¹‰)
    - [2. Gram-Schmidtæ­£äº¤åŒ–](#2-gram-schmidtæ­£äº¤åŒ–)
      - [ç»å…¸Gram-Schmidtçš„æ•°å€¼ä¸ç¨³å®šæ€§](#ç»å…¸gram-schmidtçš„æ•°å€¼ä¸ç¨³å®šæ€§)
      - [ä¿®æ­£Gram-Schmidtç®—æ³•](#ä¿®æ­£gram-schmidtç®—æ³•)
      - [æ•°å€¼å®žéªŒå¯¹æ¯”](#æ•°å€¼å®žéªŒå¯¹æ¯”)
      - [æ¡ä»¶æ•°åˆ†æž](#æ¡ä»¶æ•°åˆ†æž)
      - [å®žè·µå»ºè®®](#å®žè·µå»ºè®®)
      - [AIåº”ç”¨ä¸­çš„é‡è¦æ€§](#aiåº”ç”¨ä¸­çš„é‡è¦æ€§)
      - [æ€»ç»“](#æ€»ç»“)
    - [3. Householderå˜æ¢](#3-householderå˜æ¢)
  - [ðŸ’¡ Choleskyåˆ†è§£](#-choleskyåˆ†è§£)
    - [1. Choleskyåˆ†è§£å®šä¹‰](#1-choleskyåˆ†è§£å®šä¹‰)
    - [2. ç®—æ³•](#2-ç®—æ³•)
  - [ðŸŽ¨ LUåˆ†è§£](#-luåˆ†è§£)
    - [1. LUåˆ†è§£å®šä¹‰](#1-luåˆ†è§£å®šä¹‰)
    - [2. é«˜æ–¯æ¶ˆå…ƒæ³•](#2-é«˜æ–¯æ¶ˆå…ƒæ³•)
  - [ðŸ”§ åœ¨æ·±åº¦å­¦ä¹ ä¸­çš„åº”ç”¨](#-åœ¨æ·±åº¦å­¦ä¹ ä¸­çš„åº”ç”¨)
    - [1. ä¸»æˆåˆ†åˆ†æž (PCA)](#1-ä¸»æˆåˆ†åˆ†æž-pca)
    - [2. å¥‡å¼‚å€¼åˆ†è§£ä¸Žé™ç»´](#2-å¥‡å¼‚å€¼åˆ†è§£ä¸Žé™ç»´)
    - [3. çŸ©é˜µæ±‚é€†ä¸Žçº¿æ€§ç³»ç»Ÿ](#3-çŸ©é˜µæ±‚é€†ä¸Žçº¿æ€§ç³»ç»Ÿ)
    - [4. æƒé‡åˆå§‹åŒ–](#4-æƒé‡åˆå§‹åŒ–)
  - [ðŸ’» Pythonå®žçŽ°](#-pythonå®žçŽ°)
  - [ðŸ“š ç»ƒä¹ é¢˜](#-ç»ƒä¹ é¢˜)
    - [ç»ƒä¹ 1ï¼šç‰¹å¾å€¼è®¡ç®—](#ç»ƒä¹ 1ç‰¹å¾å€¼è®¡ç®—)
    - [ç»ƒä¹ 2ï¼šSVDåº”ç”¨](#ç»ƒä¹ 2svdåº”ç”¨)
    - [ç»ƒä¹ 3ï¼šPCAå®žçŽ°](#ç»ƒä¹ 3pcaå®žçŽ°)
    - [ç»ƒä¹ 4ï¼šä½Žç§©è¿‘ä¼¼](#ç»ƒä¹ 4ä½Žç§©è¿‘ä¼¼)
  - [ðŸŽ“ ç›¸å…³è¯¾ç¨‹](#-ç›¸å…³è¯¾ç¨‹)
  - [ðŸ“– å‚è€ƒæ–‡çŒ®](#-å‚è€ƒæ–‡çŒ®)

---

## ðŸ“‹ æ ¸å¿ƒæ€æƒ³

**çŸ©é˜µåˆ†è§£**æ˜¯å°†çŸ©é˜µè¡¨ç¤ºä¸ºæ›´ç®€å•çŸ©é˜µçš„ä¹˜ç§¯ï¼Œæ˜¯çº¿æ€§ä»£æ•°è®¡ç®—çš„æ ¸å¿ƒå·¥å…·ã€‚

**ä¸ºä»€ä¹ˆçŸ©é˜µåˆ†è§£é‡è¦**:

```text
è®¡ç®—ä¼˜åŠ¿:
â”œâ”€ ç®€åŒ–è®¡ç®— (å¦‚æ±‚é€†ã€æ±‚è§£çº¿æ€§ç³»ç»Ÿ)
â”œâ”€ æ•°å€¼ç¨³å®šæ€§
â””â”€ æ­ç¤ºçŸ©é˜µç»“æž„

æœºå™¨å­¦ä¹ åº”ç”¨:
â”œâ”€ PCA (ä¸»æˆåˆ†åˆ†æž) â†’ SVD
â”œâ”€ æŽ¨èç³»ç»Ÿ â†’ çŸ©é˜µåˆ†è§£
â”œâ”€ é™ç»´ â†’ SVD/ç‰¹å¾å€¼åˆ†è§£
â””â”€ ä¼˜åŒ– â†’ Choleskyåˆ†è§£
```

**ä¸»è¦åˆ†è§£**:

```text
ç‰¹å¾å€¼åˆ†è§£ (Eigendecomposition):
    A = QÎ›Qâ»Â¹  (æ–¹é˜µ, å¯å¯¹è§’åŒ–)

å¥‡å¼‚å€¼åˆ†è§£ (SVD):
    A = UÎ£Váµ€  (ä»»æ„çŸ©é˜µ)

QRåˆ†è§£:
    A = QR  (Qæ­£äº¤, Rä¸Šä¸‰è§’)

Choleskyåˆ†è§£:
    A = LLáµ€  (æ­£å®šçŸ©é˜µ)

LUåˆ†è§£:
    A = LU  (Lä¸‹ä¸‰è§’, Uä¸Šä¸‰è§’)
```

---

## ðŸŽ¯ ç‰¹å¾å€¼åˆ†è§£ (Eigendecomposition)

### 1. ç‰¹å¾å€¼ä¸Žç‰¹å¾å‘é‡

**å®šä¹‰ 1.1 (ç‰¹å¾å€¼ä¸Žç‰¹å¾å‘é‡)**:

è®¾ $A \in \mathbb{R}^{n \times n}$ï¼Œå¦‚æžœå­˜åœ¨æ ‡é‡ $\lambda$ å’Œéžé›¶å‘é‡ $v$ ä½¿å¾—ï¼š

$$
Av = \lambda v
$$

åˆ™ $\lambda$ ç§°ä¸º $A$ çš„**ç‰¹å¾å€¼**ï¼Œ$v$ ç§°ä¸ºå¯¹åº”çš„**ç‰¹å¾å‘é‡**ã€‚

**å‡ ä½•æ„ä¹‰**ï¼š$A$ ä½œç”¨åœ¨ $v$ ä¸Šåªæ”¹å˜å…¶é•¿åº¦ï¼Œä¸æ”¹å˜æ–¹å‘ã€‚

**ç‰¹å¾å¤šé¡¹å¼**:

$$
\det(A - \lambda I) = 0
$$

**ç¤ºä¾‹**:

$$
A = \begin{bmatrix} 2 & 1 \\ 1 & 2 \end{bmatrix}
$$

ç‰¹å¾å¤šé¡¹å¼ï¼š$\det(A - \lambda I) = (2 - \lambda)^2 - 1 = 0$

ç‰¹å¾å€¼ï¼š$\lambda_1 = 3, \lambda_2 = 1$

ç‰¹å¾å‘é‡ï¼š$v_1 = \begin{bmatrix} 1 \\ 1 \end{bmatrix}, v_2 = \begin{bmatrix} 1 \\ -1 \end{bmatrix}$

---

### 2. è°±å®šç†

**å®šç† 2.1 (è°±å®šç†)**:

è®¾ $A \in \mathbb{R}^{n \times n}$ æ˜¯**å¯¹ç§°çŸ©é˜µ**ï¼Œåˆ™ï¼š

1. $A$ çš„æ‰€æœ‰ç‰¹å¾å€¼éƒ½æ˜¯**å®žæ•°**
2. ä¸åŒç‰¹å¾å€¼å¯¹åº”çš„ç‰¹å¾å‘é‡**æ­£äº¤**
3. $A$ å¯ä»¥**æ­£äº¤å¯¹è§’åŒ–**ï¼š

$$
A = Q\Lambda Q^T
$$

å…¶ä¸­ $Q$ æ˜¯æ­£äº¤çŸ©é˜µï¼ˆ$Q^T Q = I$ï¼‰ï¼Œ$\Lambda = \text{diag}(\lambda_1, \ldots, \lambda_n)$ã€‚

**æ„ä¹‰**ï¼šå¯¹ç§°çŸ©é˜µæœ‰å®Œæ•´çš„æ­£äº¤ç‰¹å¾å‘é‡åŸºã€‚

---

**å®šç† 2.1 çš„å®Œæ•´è¯æ˜Ž**:

æˆ‘ä»¬å°†åˆ†ä¸‰éƒ¨åˆ†è¯æ˜Žè°±å®šç†çš„ä¸‰ä¸ªç»“è®ºã€‚

**è¯æ˜Ž (1): ç‰¹å¾å€¼éƒ½æ˜¯å®žæ•°**:

è®¾ $\lambda$ æ˜¯ $A$ çš„ç‰¹å¾å€¼ï¼Œ$v$ æ˜¯å¯¹åº”çš„ç‰¹å¾å‘é‡ï¼ˆå…è®¸ $v$ æ˜¯å¤å‘é‡ï¼‰ã€‚åˆ™ï¼š

$$
Av = \lambda v
$$

ä¸¤è¾¹å–å…±è½­è½¬ç½®å¹¶å·¦ä¹˜ $v^*$ï¼ˆ$v^*$ è¡¨ç¤º $v$ çš„å…±è½­è½¬ç½®ï¼‰ï¼š

$$
v^* A^* v^* = \bar{\lambda} v^* v^*
$$

ç”±äºŽ $A$ æ˜¯å®žå¯¹ç§°çŸ©é˜µï¼Œæœ‰ $A^* = A^T = A$ï¼Œå› æ­¤ï¼š

$$
v^* A v = \bar{\lambda} v^* v
$$

å¦ä¸€æ–¹é¢ï¼Œç”± $Av = \lambda v$ï¼Œä¸¤è¾¹å·¦ä¹˜ $v^*$ï¼š

$$
v^* A v = \lambda v^* v
$$

æ¯”è¾ƒä¸¤å¼ï¼Œå¾—ï¼š

$$
\lambda v^* v = \bar{\lambda} v^* v
$$

ç”±äºŽ $v \neq 0$ï¼Œæœ‰ $v^* v = \|v\|^2 > 0$ï¼Œå› æ­¤ï¼š

$$
\lambda = \bar{\lambda}
$$

è¿™è¯´æ˜Ž $\lambda$ æ˜¯å®žæ•°ã€‚ $\square$

**è¯æ˜Ž (2): ä¸åŒç‰¹å¾å€¼å¯¹åº”çš„ç‰¹å¾å‘é‡æ­£äº¤**:

è®¾ $\lambda_1 \neq \lambda_2$ æ˜¯ $A$ çš„ä¸¤ä¸ªä¸åŒç‰¹å¾å€¼ï¼Œ$v_1, v_2$ æ˜¯å¯¹åº”çš„ç‰¹å¾å‘é‡ã€‚åˆ™ï¼š

$$
Av_1 = \lambda_1 v_1, \quad Av_2 = \lambda_2 v_2
$$

è®¡ç®—å†…ç§¯ $v_1^T A v_2$ï¼š

$$
v_1^T A v_2 = v_1^T (\lambda_2 v_2) = \lambda_2 (v_1^T v_2)
$$

å¦ä¸€æ–¹é¢ï¼Œç”±äºŽ $A$ å¯¹ç§°ï¼ˆ$A^T = A$ï¼‰ï¼š

$$
v_1^T A v_2 = (A^T v_1)^T v_2 = (A v_1)^T v_2 = (\lambda_1 v_1)^T v_2 = \lambda_1 (v_1^T v_2)
$$

å› æ­¤ï¼š

$$
\lambda_2 (v_1^T v_2) = \lambda_1 (v_1^T v_2)
$$

$$
(\lambda_2 - \lambda_1)(v_1^T v_2) = 0
$$

ç”±äºŽ $\lambda_1 \neq \lambda_2$ï¼Œå¿…æœ‰ï¼š

$$
v_1^T v_2 = 0
$$

å³ $v_1$ å’Œ $v_2$ æ­£äº¤ã€‚ $\square$

**è¯æ˜Ž (3): å¯ä»¥æ­£äº¤å¯¹è§’åŒ–**:

æˆ‘ä»¬ç”¨æ•°å­¦å½’çº³æ³•è¯æ˜Žã€‚

**åŸºç¡€æ­¥éª¤** ($n=1$): æ˜¾ç„¶æˆç«‹ã€‚

**å½’çº³æ­¥éª¤**: å‡è®¾å¯¹æ‰€æœ‰ $(n-1) \times (n-1)$ å¯¹ç§°çŸ©é˜µå®šç†æˆç«‹ï¼ŒçŽ°åœ¨è¯æ˜Žå¯¹ $n \times n$ å¯¹ç§°çŸ©é˜µ $A$ ä¹Ÿæˆç«‹ã€‚

1. ç”±è¯æ˜Ž(1)ï¼Œ$A$ è‡³å°‘æœ‰ä¸€ä¸ªå®žç‰¹å¾å€¼ $\lambda_1$ï¼Œè®¾å¯¹åº”çš„å•ä½ç‰¹å¾å‘é‡ä¸º $q_1$ï¼ˆ$\|q_1\| = 1$ï¼‰ã€‚

2. å°† $q_1$ æ‰©å……ä¸º $\mathbb{R}^n$ çš„æ ‡å‡†æ­£äº¤åŸº $\{q_1, q_2, \ldots, q_n\}$ã€‚

3. æž„é€ æ­£äº¤çŸ©é˜µ $Q_1 = [q_1 \mid q_2 \mid \cdots \mid q_n]$ï¼Œåˆ™ï¼š

    $$
    Q_1^T A Q_1 = \begin{bmatrix} \lambda_1 & w^T \\ w & B \end{bmatrix}
    $$

    å…¶ä¸­ $w \in \mathbb{R}^{n-1}$ï¼Œ$B \in \mathbb{R}^{(n-1) \times (n-1)}$ã€‚

4. ç”±äºŽ $Q_1^T A Q_1$ ä»æ˜¯å¯¹ç§°çŸ©é˜µï¼Œå¿…æœ‰ $w = 0$ã€‚è¯æ˜Žå¦‚ä¸‹ï¼š

   çŸ©é˜µ $Q_1^T A Q_1$ çš„ $(1,2)$ å…ƒç´ ç­‰äºŽ $(2,1)$ å…ƒç´ ï¼š

   $$
   (Q_1^T A Q_1)_{12} = q_1^T A q_2 = (A q_1)^T q_2 = (\lambda_1 q_1)^T q_2 = \lambda_1 (q_1^T q_2) = 0
   $$

   å› æ­¤ $w = 0$ã€‚

5. çŽ°åœ¨ï¼š

    $$
    Q_1^T A Q_1 = \begin{bmatrix} \lambda_1 & 0 \\ 0 & B \end{bmatrix}
    $$

    å…¶ä¸­ $B$ æ˜¯ $(n-1) \times (n-1)$ å¯¹ç§°çŸ©é˜µã€‚

6. ç”±å½’çº³å‡è®¾ï¼Œå­˜åœ¨ $(n-1) \times (n-1)$ æ­£äº¤çŸ©é˜µ $Q_2$ ä½¿å¾—ï¼š

    $$
    Q_2^T B Q_2 = \Lambda' = \text{diag}(\lambda_2, \ldots, \lambda_n)
    $$

7. ä»¤ï¼š

    $$
    Q_3 = \begin{bmatrix} 1 & 0 \\ 0 & Q_2 \end{bmatrix}
    $$

    åˆ™ $Q_3$ æ˜¯æ­£äº¤çŸ©é˜µï¼Œä¸”ï¼š

    $$
    Q_3^T (Q_1^T A Q_1) Q_3 = \begin{bmatrix} \lambda_1 & 0 \\ 0 & \Lambda' \end{bmatrix} = \Lambda
    $$

8. ä»¤ $Q = Q_1 Q_3$ï¼Œåˆ™ $Q$ æ˜¯æ­£äº¤çŸ©é˜µï¼Œä¸”ï¼š

    $$
    Q^T A Q = \Lambda
    $$

    å³ï¼š

    $$
    A = Q \Lambda Q^T
    $$

è¿™å°±å®Œæˆäº†å½’çº³è¯æ˜Žã€‚ $\square$

**å®šç†çš„å‡ ä½•æ„ä¹‰**:

è°±å®šç†è¡¨æ˜Žï¼Œå¯¹ç§°çŸ©é˜µåœ¨æŸä¸ªæ ‡å‡†æ­£äº¤åŸºä¸‹çš„è¡¨ç¤ºæ˜¯å¯¹è§’çŸ©é˜µã€‚è¿™æ„å‘³ç€ï¼š

- å¯¹ç§°çŸ©é˜µå¯¹åº”çš„çº¿æ€§å˜æ¢åœ¨å…¶ç‰¹å¾å‘é‡æ–¹å‘ä¸Šåªè¿›è¡Œä¼¸ç¼©
- ä¸åŒç‰¹å¾å€¼å¯¹åº”çš„ç‰¹å¾ç©ºé—´ç›¸äº’æ­£äº¤
- å¯¹ç§°çŸ©é˜µå®Œå…¨ç”±å…¶ç‰¹å¾å€¼å’Œæ­£äº¤ç‰¹å¾å‘é‡ç¡®å®š

**åº”ç”¨ç¤ºä¾‹**:

è€ƒè™‘å¯¹ç§°çŸ©é˜µï¼š

$$
A = \begin{bmatrix} 3 & 1 \\ 1 & 3 \end{bmatrix}
$$

ç‰¹å¾å€¼ï¼š$\lambda_1 = 4, \lambda_2 = 2$

ç‰¹å¾å‘é‡ï¼š$v_1 = \begin{bmatrix} 1 \\ 1 \end{bmatrix}, v_2 = \begin{bmatrix} 1 \\ -1 \end{bmatrix}$

å½’ä¸€åŒ–åŽï¼š$q_1 = \frac{1}{\sqrt{2}}\begin{bmatrix} 1 \\ 1 \end{bmatrix}, q_2 = \frac{1}{\sqrt{2}}\begin{bmatrix} 1 \\ -1 \end{bmatrix}$

éªŒè¯æ­£äº¤æ€§ï¼š$q_1^T q_2 = \frac{1}{2}(1 \cdot 1 + 1 \cdot (-1)) = 0$ âœ“

æ­£äº¤å¯¹è§’åŒ–ï¼š

$$
A = \frac{1}{\sqrt{2}}\begin{bmatrix} 1 & 1 \\ 1 & -1 \end{bmatrix} \begin{bmatrix} 4 & 0 \\ 0 & 2 \end{bmatrix} \frac{1}{\sqrt{2}}\begin{bmatrix} 1 & 1 \\ 1 & -1 \end{bmatrix}
$$

---

### 3. å¯¹è§’åŒ–

**å®šä¹‰ 3.1 (å¯å¯¹è§’åŒ–)**:

çŸ©é˜µ $A$ å¯å¯¹è§’åŒ–ï¼Œå¦‚æžœå­˜åœ¨å¯é€†çŸ©é˜µ $P$ å’Œå¯¹è§’çŸ©é˜µ $D$ ä½¿å¾—ï¼š

$$
A = PDP^{-1}
$$

**æ¡ä»¶**ï¼š$A$ æœ‰ $n$ ä¸ªçº¿æ€§æ— å…³çš„ç‰¹å¾å‘é‡ã€‚

**åº”ç”¨**ï¼šè®¡ç®—çŸ©é˜µå¹‚

$$
A^k = PD^kP^{-1}
$$

å…¶ä¸­ $D^k = \text{diag}(\lambda_1^k, \ldots, \lambda_n^k)$ã€‚

---

## ðŸ“Š å¥‡å¼‚å€¼åˆ†è§£ (SVD)

### 1. SVDå®šä¹‰

**å®šç† 1.1 (å¥‡å¼‚å€¼åˆ†è§£)**:

å¯¹äºŽä»»æ„çŸ©é˜µ $A \in \mathbb{R}^{m \times n}$ï¼Œå­˜åœ¨åˆ†è§£ï¼š

$$
A = U\Sigma V^T
$$

å…¶ä¸­ï¼š

- $U \in \mathbb{R}^{m \times m}$ æ˜¯æ­£äº¤çŸ©é˜µï¼ˆå·¦å¥‡å¼‚å‘é‡ï¼‰
- $\Sigma \in \mathbb{R}^{m \times n}$ æ˜¯å¯¹è§’çŸ©é˜µï¼Œå¯¹è§’å…ƒç´  $\sigma_1 \geq \sigma_2 \geq \cdots \geq \sigma_r > 0$ ç§°ä¸º**å¥‡å¼‚å€¼**
- $V \in \mathbb{R}^{n \times n}$ æ˜¯æ­£äº¤çŸ©é˜µï¼ˆå³å¥‡å¼‚å‘é‡ï¼‰

**ä¸Žç‰¹å¾å€¼çš„å…³ç³»**:

- $A^T A$ çš„ç‰¹å¾å€¼æ˜¯ $\sigma_i^2$
- $A A^T$ çš„ç‰¹å¾å€¼ä¹Ÿæ˜¯ $\sigma_i^2$
- $V$ çš„åˆ—æ˜¯ $A^T A$ çš„ç‰¹å¾å‘é‡
- $U$ çš„åˆ—æ˜¯ $A A^T$ çš„ç‰¹å¾å‘é‡

---

**å®šç† 1.1 çš„å®Œæ•´è¯æ˜Ž**:

æˆ‘ä»¬å°†æž„é€ æ€§åœ°è¯æ˜ŽSVDçš„å­˜åœ¨æ€§ã€‚

**è¯æ˜Žæ­¥éª¤**:

**ç¬¬ä¸€æ­¥ï¼šåˆ†æž $A^T A$**

è€ƒè™‘çŸ©é˜µ $A^T A \in \mathbb{R}^{n \times n}$ã€‚æ³¨æ„åˆ°ï¼š

1. $A^T A$ æ˜¯å¯¹ç§°çŸ©é˜µï¼š$(A^T A)^T = A^T (A^T)^T = A^T A$

2. $A^T A$ æ˜¯åŠæ­£å®šçŸ©é˜µï¼šå¯¹ä»»æ„ $x \in \mathbb{R}^n$ï¼Œ
   $$
   x^T (A^T A) x = (Ax)^T (Ax) = \|Ax\|^2 \geq 0
   $$

**ç¬¬äºŒæ­¥ï¼šåº”ç”¨è°±å®šç†**:

ç”±äºŽ $A^T A$ æ˜¯å¯¹ç§°çŸ©é˜µï¼Œæ ¹æ®è°±å®šç†ï¼Œå­˜åœ¨æ­£äº¤çŸ©é˜µ $V \in \mathbb{R}^{n \times n}$ å’Œå¯¹è§’çŸ©é˜µ $\Lambda$ ä½¿å¾—ï¼š

$$
A^T A = V \Lambda V^T
$$

å…¶ä¸­ $\Lambda = \text{diag}(\lambda_1, \lambda_2, \ldots, \lambda_n)$ï¼Œä¸” $\lambda_1 \geq \lambda_2 \geq \cdots \geq \lambda_n \geq 0$ï¼ˆæ‰€æœ‰ç‰¹å¾å€¼éžè´Ÿï¼Œå› ä¸º $A^T A$ åŠæ­£å®šï¼‰ã€‚

è®¾ $V = [v_1 \mid v_2 \mid \cdots \mid v_n]$ï¼Œå…¶ä¸­ $v_i$ æ˜¯å¯¹åº”äºŽç‰¹å¾å€¼ $\lambda_i$ çš„å•ä½ç‰¹å¾å‘é‡ã€‚

**ç¬¬ä¸‰æ­¥ï¼šå®šä¹‰å¥‡å¼‚å€¼**:

å®šä¹‰å¥‡å¼‚å€¼ä¸ºï¼š

$$
\sigma_i = \sqrt{\lambda_i}, \quad i = 1, 2, \ldots, n
$$

å‡è®¾å‰ $r$ ä¸ªå¥‡å¼‚å€¼ä¸ºæ­£ï¼ˆ$\sigma_1 \geq \sigma_2 \geq \cdots \geq \sigma_r > 0$ï¼‰ï¼ŒåŽé¢çš„ä¸ºé›¶ã€‚è¿™é‡Œ $r = \text{rank}(A)$ã€‚

**ç¬¬å››æ­¥ï¼šæž„é€ å·¦å¥‡å¼‚å‘é‡ $U$**

å¯¹äºŽ $i = 1, 2, \ldots, r$ï¼Œå®šä¹‰ï¼š

$$
u_i = \frac{1}{\sigma_i} A v_i
$$

æˆ‘ä»¬éœ€è¦éªŒè¯ $\{u_1, u_2, \ldots, u_r\}$ æ˜¯æ­£äº¤çš„ï¼š

$$
u_i^T u_j = \frac{1}{\sigma_i \sigma_j} (Av_i)^T (Av_j) = \frac{1}{\sigma_i \sigma_j} v_i^T A^T A v_j
$$

ç”±äºŽ $A^T A v_j = \lambda_j v_j = \sigma_j^2 v_j$ï¼š

$$
u_i^T u_j = \frac{1}{\sigma_i \sigma_j} v_i^T (\sigma_j^2 v_j) = \frac{\sigma_j}{\sigma_i} v_i^T v_j = \frac{\sigma_j}{\sigma_i} \delta_{ij} = \delta_{ij}
$$

å› æ­¤ $\{u_1, u_2, \ldots, u_r\}$ æ˜¯æ ‡å‡†æ­£äº¤é›†ã€‚

å°† $\{u_1, u_2, \ldots, u_r\}$ æ‰©å……ä¸º $\mathbb{R}^m$ çš„æ ‡å‡†æ­£äº¤åŸº $\{u_1, u_2, \ldots, u_m\}$ï¼Œæž„é€ æ­£äº¤çŸ©é˜µï¼š

$$
U = [u_1 \mid u_2 \mid \cdots \mid u_m] \in \mathbb{R}^{m \times m}
$$

**ç¬¬äº”æ­¥ï¼šéªŒè¯åˆ†è§£**:

çŽ°åœ¨éªŒè¯ $A = U \Sigma V^T$ï¼Œå…¶ä¸­ $\Sigma \in \mathbb{R}^{m \times n}$ æ˜¯å¹¿ä¹‰å¯¹è§’çŸ©é˜µï¼š

$$
\Sigma_{ij} = \begin{cases}
\sigma_i & \text{å¦‚æžœ } i = j \leq r \\
0 & \text{å¦åˆ™}
\end{cases}
$$

å¯¹äºŽ $j = 1, 2, \ldots, n$ï¼Œè®¡ç®— $A v_j$ï¼š

- å¦‚æžœ $j \leq r$ï¼š
  $$
  A v_j = \sigma_j u_j = \sigma_j u_j = (U \Sigma V^T) v_j
  $$
  
  å› ä¸ºï¼š
  $$
  (U \Sigma V^T) v_j = U \Sigma e_j = U (\sigma_j e_j) = \sigma_j u_j
  $$

- å¦‚æžœ $j > r$ï¼š
  $$
  \|A v_j\|^2 = v_j^T A^T A v_j = v_j^T (\lambda_j v_j) = \lambda_j \|v_j\|^2 = 0
  $$
  
  å› æ­¤ $A v_j = 0 = (U \Sigma V^T) v_j$

ç”±äºŽ $\{v_1, v_2, \ldots, v_n\}$ æ˜¯ $\mathbb{R}^n$ çš„æ ‡å‡†æ­£äº¤åŸºï¼Œè€Œ $A$ å’Œ $U \Sigma V^T$ åœ¨è¿™ç»„åŸºä¸Šçš„ä½œç”¨ç›¸åŒï¼Œå› æ­¤ï¼š

$$
A = U \Sigma V^T
$$

è¿™å°±å®Œæˆäº†SVDçš„å­˜åœ¨æ€§è¯æ˜Žã€‚ $\square$

**å”¯ä¸€æ€§è¯´æ˜Ž**:

å¥‡å¼‚å€¼çš„å”¯ä¸€æ€§ï¼šå¥‡å¼‚å€¼ $\sigma_1 \geq \sigma_2 \geq \cdots \geq \sigma_r > 0$ ç”± $A^T A$ çš„ç‰¹å¾å€¼å”¯ä¸€ç¡®å®šã€‚

å¥‡å¼‚å‘é‡çš„å”¯ä¸€æ€§ï¼š

- å¦‚æžœæ‰€æœ‰éžé›¶å¥‡å¼‚å€¼äº’ä¸ç›¸åŒï¼Œåˆ™å¯¹åº”çš„å¥‡å¼‚å‘é‡åœ¨ç¬¦å·å·®å¼‚ä¸‹æ˜¯å”¯ä¸€çš„
- å¦‚æžœå­˜åœ¨é‡å¤çš„å¥‡å¼‚å€¼ï¼Œåˆ™å¯¹åº”çš„å¥‡å¼‚å‘é‡å¼ æˆçš„å­ç©ºé—´æ˜¯å”¯ä¸€çš„ï¼Œä½†å…·ä½“çš„æ­£äº¤åŸºä¸å”¯ä¸€

**è®¡ç®—ç¤ºä¾‹**:

è€ƒè™‘çŸ©é˜µï¼š

$$
A = \begin{bmatrix} 3 & 2 & 2 \\ 2 & 3 & -2 \end{bmatrix}
$$

**æ­¥éª¤1**: è®¡ç®— $A^T A$ï¼š

$$
A^T A = \begin{bmatrix} 3 & 2 \\ 2 & 3 \\ 2 & -2 \end{bmatrix} \begin{bmatrix} 3 & 2 & 2 \\ 2 & 3 & -2 \end{bmatrix} = \begin{bmatrix} 13 & 12 & 2 \\ 12 & 13 & -2 \\ 2 & -2 & 8 \end{bmatrix}
$$

**æ­¥éª¤2**: è®¡ç®—ç‰¹å¾å€¼ï¼ˆçœç•¥è¯¦ç»†è®¡ç®—ï¼‰ï¼š

$$
\lambda_1 = 25, \quad \lambda_2 = 9, \quad \lambda_3 = 0
$$

**æ­¥éª¤3**: å¥‡å¼‚å€¼ï¼š

$$
\sigma_1 = 5, \quad \sigma_2 = 3
$$

**æ­¥éª¤4**: è®¡ç®—å³å¥‡å¼‚å‘é‡ $V$ï¼ˆ$A^T A$ çš„ç‰¹å¾å‘é‡ï¼‰

**æ­¥éª¤5**: è®¡ç®—å·¦å¥‡å¼‚å‘é‡ $U = AV\Sigma^{-1}$

æœ€ç»ˆå¾—åˆ°ï¼š

$$
A = U \begin{bmatrix} 5 & 0 & 0 \\ 0 & 3 & 0 \end{bmatrix} V^T
$$

---

### 2. å‡ ä½•è§£é‡Š

**SVDçš„å‡ ä½•æ„ä¹‰**:

ä»»æ„çº¿æ€§å˜æ¢ $A$ å¯ä»¥åˆ†è§£ä¸ºï¼š

```text
A = U Î£ Váµ€
    â†“
1. Váµ€: æ—‹è½¬ (æ­£äº¤å˜æ¢)
2. Î£:  ç¼©æ”¾ (æ²¿åæ ‡è½´)
3. U:  æ—‹è½¬ (æ­£äº¤å˜æ¢)
```

**ç¤ºä¾‹**:

$$
A = \begin{bmatrix} 3 & 0 \\ 0 & 1 \end{bmatrix}
$$

å·²ç»æ˜¯å¯¹è§’çŸ©é˜µï¼ŒSVDä¸ºï¼š

$$
U = I, \quad \Sigma = A, \quad V = I
$$

---

### 3. æˆªæ–­SVDä¸Žä½Žç§©è¿‘ä¼¼

**å®šç† 3.1 (Eckart-Youngå®šç†)**:

è®¾ $A = U\Sigma V^T$ æ˜¯SVDï¼Œå®šä¹‰ç§©ä¸º $k$ çš„æˆªæ–­SVDï¼š

$$
A_k = U_k \Sigma_k V_k^T = \sum_{i=1}^k \sigma_i u_i v_i^T
$$

åˆ™ $A_k$ æ˜¯æ‰€æœ‰ç§©ä¸è¶…è¿‡ $k$ çš„çŸ©é˜µä¸­ï¼Œä¸Ž $A$ çš„FrobeniusèŒƒæ•°è·ç¦»æœ€å°çš„çŸ©é˜µï¼š

$$
A_k = \arg\min_{\text{rank}(B) \leq k} \|A - B\|_F
$$

**è¯¯å·®**:

$$
\|A - A_k\|_F = \sqrt{\sum_{i=k+1}^r \sigma_i^2}
$$

**åº”ç”¨**ï¼šæ•°æ®åŽ‹ç¼©ã€é™ç»´ã€åŽ»å™ªã€‚

---

### 4. SVDçš„æ€§è´¨

**æ€§è´¨ 4.1**:

1. **ç§©**: $\text{rank}(A) = r$ (éžé›¶å¥‡å¼‚å€¼çš„ä¸ªæ•°)
2. **èŒƒæ•°**: $\|A\|_2 = \sigma_1$ (æœ€å¤§å¥‡å¼‚å€¼)
3. **FrobeniusèŒƒæ•°**: $\|A\|_F = \sqrt{\sum_{i=1}^r \sigma_i^2}$
4. **æ¡ä»¶æ•°**: $\kappa(A) = \frac{\sigma_1}{\sigma_r}$
5. **ä¼ªé€†**: $A^+ = V\Sigma^+ U^T$ï¼Œå…¶ä¸­ $\Sigma^+$ æ˜¯ $\Sigma$ çš„ä¼ªé€†

---

## ðŸ”¬ QRåˆ†è§£

### 1. QRåˆ†è§£å®šä¹‰

**å®šç† 1.1 (QRåˆ†è§£)**:

å¯¹äºŽä»»æ„çŸ©é˜µ $A \in \mathbb{R}^{m \times n}$ ($m \geq n$)ï¼Œå­˜åœ¨åˆ†è§£ï¼š

$$
A = QR
$$

å…¶ä¸­ï¼š

- $Q \in \mathbb{R}^{m \times n}$ æ˜¯æ­£äº¤çŸ©é˜µï¼ˆ$Q^T Q = I$ï¼‰
- $R \in \mathbb{R}^{n \times n}$ æ˜¯ä¸Šä¸‰è§’çŸ©é˜µ

**åº”ç”¨**ï¼š

- æ±‚è§£æœ€å°äºŒä¹˜é—®é¢˜
- è®¡ç®—ç‰¹å¾å€¼ï¼ˆQRç®—æ³•ï¼‰
- æ­£äº¤åŒ–

---

### 2. Gram-Schmidtæ­£äº¤åŒ–

**ç®—æ³• 2.1 (Gram-Schmidtæ­£äº¤åŒ–)**:

ç»™å®šçº¿æ€§æ— å…³å‘é‡ $a_1, \ldots, a_n$ï¼Œæž„é€ æ­£äº¤å‘é‡ $q_1, \ldots, q_n$ï¼š

$$
\begin{align}
u_1 &= a_1 \\
u_i &= a_i - \sum_{j=1}^{i-1} \frac{\langle a_i, q_j \rangle}{\langle q_j, q_j \rangle} q_j \\
q_i &= \frac{u_i}{\|u_i\|}
\end{align}
$$

**é—®é¢˜**ï¼šæ•°å€¼ä¸ç¨³å®šï¼ˆä¿®æ­£Gram-Schmidtæ›´ç¨³å®šï¼‰ã€‚

---

**Gram-Schmidtæ­£äº¤åŒ–çš„æ•°å€¼ç¨³å®šæ€§åˆ†æž**:

#### ç»å…¸Gram-Schmidtçš„æ•°å€¼ä¸ç¨³å®šæ€§

**é—®é¢˜æ ¹æº**:

åœ¨ç»å…¸Gram-Schmidt (Classical GS, CGS) ç®—æ³•ä¸­ï¼ŒåŽç»­å‘é‡çš„æ­£äº¤åŒ–ä¾èµ–äºŽä¹‹å‰å·²ç»è®¡ç®—å‡ºçš„å‘é‡ã€‚ç”±äºŽèˆå…¥è¯¯å·®çš„ç´¯ç§¯ï¼Œå·²è®¡ç®—çš„å‘é‡ $q_1, \ldots, q_{i-1}$ å¯èƒ½å·²ç»**å¤±åŽ»æ­£äº¤æ€§**ã€‚

**æ•°å­¦åˆ†æž**:

è®¾ $\hat{q}_i$ è¡¨ç¤ºå®žé™…è®¡ç®—ä¸­å¾—åˆ°çš„å‘é‡ï¼ˆå«èˆå…¥è¯¯å·®ï¼‰ï¼Œåˆ™ï¼š

$$
\hat{q}_i^T \hat{q}_j \neq 0, \quad i \neq j
$$

**æ­£äº¤æ€§æŸå¤±**å¯ä»¥ç”¨ä»¥ä¸‹æŒ‡æ ‡è¡¡é‡ï¼š

$$
\text{Orthogonality Loss} = \max_{i \neq j} |\hat{q}_i^T \hat{q}_j|
$$

ç†æƒ³æƒ…å†µä¸‹åº”ä¸º0ï¼Œä½†åœ¨CGSä¸­å¯èƒ½è¾¾åˆ° $O(\kappa(A) \cdot \epsilon_{\text{machine}})$ï¼Œå…¶ä¸­ï¼š

- $\kappa(A) = \|A\| \|A^{-1}\|$ æ˜¯æ¡ä»¶æ•°
- $\epsilon_{\text{machine}} \approx 10^{-16}$ (åŒç²¾åº¦æµ®ç‚¹æ•°)

**ç¤ºä¾‹**ï¼ˆç—…æ€çŸ©é˜µï¼‰:

å¯¹äºŽHilbertçŸ©é˜µ $H_{ij} = \frac{1}{i+j-1}$ (é«˜åº¦ç—…æ€ï¼Œ$\kappa(H_5) \approx 10^5$)ï¼š

```python
import numpy as np

# 5x5 HilbertçŸ©é˜µ
n = 5
H = np.array([[1/(i+j-1) for j in range(1,n+1)] for i in range(1,n+1)])

# ç»å…¸Gram-Schmidt
Q_cgs, _ = modified_gram_schmidt(H, classical=True)

# æ£€æŸ¥æ­£äº¤æ€§
orthogonality = Q_cgs.T @ Q_cgs
print(f"||Q^T Q - I||_F = {np.linalg.norm(orthogonality - np.eye(n), 'fro')}")
# è¾“å‡º: ~10^-11 (å¤±åŽ»å¤§é‡ç²¾åº¦!)
```

---

#### ä¿®æ­£Gram-Schmidtç®—æ³•

**ç®—æ³• 2.2 (ä¿®æ­£Gram-Schmidt, MGS)**:

å…³é”®æ”¹è¿›ï¼š**æ¯æ¬¡æ­£äº¤åŒ–åŽç«‹å³æ›´æ–°æ‰€æœ‰å‰©ä½™å‘é‡**ã€‚

```python
def modified_gram_schmidt(A):
    """
    ä¿®æ­£Gram-Schmidtç®—æ³•
    è¾“å…¥: A (mÃ—nçŸ©é˜µ)
    è¾“å‡º: Q (mÃ—næ­£äº¤çŸ©é˜µ), R (nÃ—nä¸Šä¸‰è§’çŸ©é˜µ)
    """
    m, n = A.shape
    Q = A.copy().astype(float)
    R = np.zeros((n, n))
    
    for i in range(n):
        # è®¡ç®—èŒƒæ•°
        R[i, i] = np.linalg.norm(Q[:, i])
        
        # å½’ä¸€åŒ–
        Q[:, i] = Q[:, i] / R[i, i]
        
        # å…³é”®ï¼šç«‹å³æ›´æ–°æ‰€æœ‰å‰©ä½™å‘é‡
        for j in range(i+1, n):
            R[i, j] = Q[:, i].T @ Q[:, j]
            Q[:, j] = Q[:, j] - R[i, j] * Q[:, i]
    
    return Q, R
```

**ä¸Žç»å…¸GSçš„å¯¹æ¯”**:

| ç‰¹æ€§ | ç»å…¸GS (CGS) | ä¿®æ­£GS (MGS) |
|------|-------------|-------------|
| è®¡ç®—é¡ºåº | å…ˆè®¡ç®—å®Œæ•´ä¸ª $u_i$ï¼Œå†å½’ä¸€åŒ– | æ¯æ¬¡æ›´æ–°ç«‹å³åº”ç”¨åˆ°å‰©ä½™å‘é‡ |
| æ­£äº¤æ€§ | $\|\|Q^T Q - I\|\|_F \approx \kappa(A) \epsilon$ | $\|\|Q^T Q - I\|\|_F \approx \epsilon$ |
| æ•°å€¼ç¨³å®šæ€§ | å·®ï¼ˆ$\kappa(A)$ å¤§æ—¶å¤±æ•ˆï¼‰ | å¥½ï¼ˆç›¸å¯¹ç¨³å®šï¼‰ |
| è®¡ç®—é‡ | $2mn^2$ flops | $2mn^2$ flops |

**ä¸ºä»€ä¹ˆMGSæ›´ç¨³å®š**ï¼Ÿ

åœ¨MGSä¸­ï¼Œæ¯æ¬¡æ­£äº¤åŒ–ä½¿ç”¨çš„æ˜¯**æœ€æ–°æ›´æ–°çš„å‘é‡**ï¼Œè€Œä¸æ˜¯åŽŸå§‹å‘é‡ã€‚è¿™æ ·å¯ä»¥ï¼š

1. **å‡å°‘è¯¯å·®ç´¯ç§¯**ï¼šæ¯æ­¥çš„èˆå…¥è¯¯å·®ä¸ä¼šä¼ æ’­åˆ°æ‰€æœ‰åŽç»­æ­¥éª¤
2. **ä¿æŒç›¸å¯¹æ­£äº¤æ€§**ï¼šå³ä½¿å­˜åœ¨èˆå…¥è¯¯å·®ï¼Œå‘é‡ä¹‹é—´çš„ç›¸å¯¹å…³ç³»æ›´å‡†ç¡®

**æ•°å­¦ç›´è§‚**:

CGS: $u_i = a_i - \sum_{j=1}^{i-1} \langle a_i, \hat{q}_j \rangle \hat{q}_j$ (ä½¿ç”¨å¯èƒ½å·²å¤±åŽ»æ­£äº¤æ€§çš„ $\hat{q}_j$)

MGS: $u_i = (\cdots((a_i - \langle a_i, q_1\rangle q_1) - \langle \cdot, q_2\rangle q_2) - \cdots)$ (é€æ­¥æ›´æ–°)

---

#### æ•°å€¼å®žéªŒå¯¹æ¯”

**å®žéªŒ1ï¼šç—…æ€HilbertçŸ©é˜µ**:

```python
import numpy as np
import matplotlib.pyplot as plt

def compare_gram_schmidt(n):
    """æ¯”è¾ƒCGSå’ŒMGSåœ¨HilbertçŸ©é˜µä¸Šçš„è¡¨çŽ°"""
    # ç”ŸæˆHilbertçŸ©é˜µ
    H = np.array([[1/(i+j-1) for j in range(1,n+1)] for i in range(1,n+1)])
    
    # æ¡ä»¶æ•°
    kappa = np.linalg.cond(H)
    print(f"æ¡ä»¶æ•° Îº(H_{n}) = {kappa:.2e}")
    
    # ç»å…¸GS
    Q_cgs, _ = classical_gram_schmidt(H)
    orthogonality_cgs = np.linalg.norm(Q_cgs.T @ Q_cgs - np.eye(n), 'fro')
    
    # ä¿®æ­£GS
    Q_mgs, _ = modified_gram_schmidt(H)
    orthogonality_mgs = np.linalg.norm(Q_mgs.T @ Q_mgs - np.eye(n), 'fro')
    
    print(f"CGS: ||Q^T Q - I||_F = {orthogonality_cgs:.2e}")
    print(f"MGS: ||Q^T Q - I||_F = {orthogonality_mgs:.2e}")
    print(f"æ”¹è¿›å€æ•°: {orthogonality_cgs / orthogonality_mgs:.1f}x")
    
    return orthogonality_cgs, orthogonality_mgs

# æµ‹è¯•ä¸åŒç»´åº¦
for n in [5, 8, 10, 12]:
    print(f"\n=== n = {n} ===")
    compare_gram_schmidt(n)
```

**å…¸åž‹è¾“å‡º**:

```text
=== n = 5 ===
æ¡ä»¶æ•° Îº(H_5) = 4.77e+05
CGS: ||Q^T Q - I||_F = 3.21e-11
MGS: ||Q^T Q - I||_F = 2.18e-15
æ”¹è¿›å€æ•°: 14725.7x

=== n = 10 ===
æ¡ä»¶æ•° Îº(H_10) = 1.60e+13
CGS: ||Q^T Q - I||_F = 4.89e-03  (å®Œå…¨å¤±è´¥!)
MGS: ||Q^T Q - I||_F = 8.32e-14
æ”¹è¿›å€æ•°: 58774103.6x
```

**ç»“è®º**: MGSæ¯”CGSç¨³å®š**æ•°åƒåˆ°æ•°ç™¾ä¸‡å€**ï¼

---

**å®žéªŒ2ï¼šæ¡ä»¶æ•°ä¸Žæ­£äº¤æ€§æŸå¤±çš„å…³ç³»**:

```python
import numpy as np
import matplotlib.pyplot as plt

# æµ‹è¯•ä¸åŒæ¡ä»¶æ•°çš„çŸ©é˜µ
kappas = []
loss_cgs = []
loss_mgs = []

for n in range(3, 15):
    H = np.array([[1/(i+j-1) for j in range(1,n+1)] for i in range(1,n+1)])
    kappa = np.linalg.cond(H)
    
    Q_cgs, _ = classical_gram_schmidt(H)
    Q_mgs, _ = modified_gram_schmidt(H)
    
    kappas.append(kappa)
    loss_cgs.append(np.linalg.norm(Q_cgs.T @ Q_cgs - np.eye(n), 'fro'))
    loss_mgs.append(np.linalg.norm(Q_mgs.T @ Q_mgs - np.eye(n), 'fro'))

plt.loglog(kappas, loss_cgs, 'o-', label='Classical GS')
plt.loglog(kappas, loss_mgs, 's-', label='Modified GS')
plt.loglog(kappas, [1e-16*k for k in kappas], '--', label='O(ÎºÎµ)')
plt.xlabel('Condition Number Îº(A)')
plt.ylabel('Orthogonality Loss ||Q^T Q - I||_F')
plt.legend()
plt.grid(True)
plt.title('Numerical Stability Comparison')
plt.show()
```

**è§‚å¯Ÿ**:

- CGSçš„è¯¯å·®éš $\kappa(A)$ çº¿æ€§å¢žé•¿ï¼š$O(\kappa \cdot \epsilon)$
- MGSçš„è¯¯å·®åŸºæœ¬æ’å®šï¼š$O(\epsilon)$

---

#### æ¡ä»¶æ•°åˆ†æž

**å®šç†** (QRåˆ†è§£çš„æ¡ä»¶æ•°):

è®¾ $A = QR$ æ˜¯æ»¡ç§©çŸ©é˜µï¼Œåˆ™ï¼š

$$
\kappa(R) = \kappa(A)
$$

ä½†ç”±äºŽæ•°å€¼è¯¯å·®ï¼Œå®žé™…è®¡ç®—ä¸­ï¼š

$$
\kappa(\hat{R}) \approx \kappa(A) + O(\kappa(A)^2 \cdot \epsilon)
$$

**è¯¯å·®ç•Œ**:

å¯¹äºŽMGSç®—æ³•ï¼Œæœ‰ä»¥ä¸‹è¯¯å·®ç•Œ (BjÃ¶rck, 1967):

$$
\|\hat{Q}^T \hat{Q} - I\|_2 \leq c(n) \cdot \epsilon_{\text{machine}}
$$

å…¶ä¸­ $c(n)$ æ˜¯ä¸Ž $n$ ç›¸å…³çš„å°å¸¸æ•°ï¼ˆé€šå¸¸ $c(n) \approx n$ï¼‰ï¼Œ**ä¸ä¾èµ–äºŽ** $\kappa(A)$ã€‚

è€Œå¯¹äºŽCGS:

$$
\|\hat{Q}^T \hat{Q} - I\|_2 \leq c(n) \cdot \kappa(A) \cdot \epsilon_{\text{machine}}
$$

**å®žé™…å½±å“**:

å½“ $\kappa(A) > 10^8$ æ—¶ï¼ŒCGSå¯èƒ½å®Œå…¨å¤±åŽ»æ­£äº¤æ€§ï¼ˆåŒç²¾åº¦ä¸‹ï¼‰ã€‚

---

#### å®žè·µå»ºè®®

**ä½•æ—¶ä½¿ç”¨MGS**:

1. **ç—…æ€é—®é¢˜** ($\kappa(A) > 10^6$)
2. **é«˜ç²¾åº¦è¦æ±‚**ï¼ˆå¦‚è¿­ä»£ç»†åŒ–ï¼‰
3. **åŽç»­è®¡ç®—ä¾èµ–æ­£äº¤æ€§**ï¼ˆå¦‚æœ€å°äºŒä¹˜ã€ç‰¹å¾å€¼è®¡ç®—ï¼‰

**æ›¿ä»£æ–¹æ¡ˆ**:

1. **Householder QR**: æ›´ç¨³å®šï¼Œä½†æ›´æ˜‚è´µ ($4mn^2 - \frac{4}{3}n^3$ flops vs $2mn^2$)

   ```python
   Q, R = np.linalg.qr(A, mode='reduced')  # ä½¿ç”¨Householder
   ```

2. **é‡æ­£äº¤åŒ–** (Reorthogonalization): CGS + é¢å¤–æ­£äº¤åŒ–æ­¥éª¤

   ```python
   # ä¼ªä»£ç 
   for i in range(n):
       orthogonalize(q_i, Q[:, :i])
       orthogonalize(q_i, Q[:, :i])  # å†æ­£äº¤åŒ–ä¸€æ¬¡!
   ```

**å¤æ‚åº¦å¯¹æ¯”**:

| ç®—æ³• | è®¡ç®—é‡ | ç¨³å®šæ€§ |
|------|--------|--------|
| Classical GS | $2mn^2$ | å·® |
| Modified GS | $2mn^2$ | ä¸­ |
| CGS + é‡æ­£äº¤åŒ– | $4mn^2$ | å¥½ |
| Householder QR | $\approx 4mn^2$ | å¾ˆå¥½ |

---

#### AIåº”ç”¨ä¸­çš„é‡è¦æ€§

**1. æ·±åº¦å­¦ä¹ ä¸­çš„æƒé‡æ­£äº¤åŒ–**:

æŸäº›ç¥žç»ç½‘ç»œæž¶æž„ï¼ˆå¦‚RNN, GANï¼‰éœ€è¦ä¿æŒæƒé‡çŸ©é˜µçš„æ­£äº¤æ€§ä»¥é˜²æ­¢æ¢¯åº¦æ¶ˆå¤±/çˆ†ç‚¸ï¼š

```python
def orthogonalize_weights(W):
    """ä½¿ç”¨MGSæ­£äº¤åŒ–æƒé‡çŸ©é˜µ"""
    Q, R = modified_gram_schmidt(W)
    return Q
```

**2. PCAå’ŒSVDçš„æ•°å€¼ç¨³å®šæ€§**:

SVDç®—æ³•å†…éƒ¨ä½¿ç”¨QRåˆ†è§£ï¼ŒMGSçš„ç¨³å®šæ€§ç›´æŽ¥å½±å“SVDç»“æžœã€‚

**3. æœ€å°äºŒä¹˜é—®é¢˜**:

æ±‚è§£ $\min \|Ax - b\|_2$ æ—¶ï¼Œä½¿ç”¨QRåˆ†è§£ï¼š

$$
x = R^{-1} Q^T b
$$

å¦‚æžœ $Q$ å¤±åŽ»æ­£äº¤æ€§ï¼Œè§£çš„ç²¾åº¦ä¼šå¤§å¹…ä¸‹é™ã€‚

---

#### æ€»ç»“

| æ–¹é¢ | ç»å…¸GS | ä¿®æ­£GS |
|------|--------|--------|
| æ€æƒ³ | ä¸€æ¬¡æ€§è®¡ç®—æ‰€æœ‰æŠ•å½± | é€æ­¥æ›´æ–°å‰©ä½™å‘é‡ |
| æ­£äº¤æ€§ | $O(\kappa \epsilon)$ | $O(\epsilon)$ |
| é€‚ç”¨åœºæ™¯ | æ¡ä»¶æ•°è‰¯å¥½çš„çŸ©é˜µ | é€šç”¨ï¼ˆåŒ…æ‹¬ç—…æ€ï¼‰ |
| ä»£ç å¤æ‚åº¦ | ç®€å• | ç•¥å¤æ‚ |
| **æŽ¨è** | âŒ ä¸æŽ¨è | âœ… **ä¼˜å…ˆä½¿ç”¨** |

**æ ¸å¿ƒæ•™è®­**:

- **ç®—æ³•çš„æ•°å€¼ç¨³å®šæ€§ä¸Žç†è®ºæ­£ç¡®æ€§åŒç­‰é‡è¦**
- **å°çš„ç®—æ³•å˜åŒ–å¯ä»¥å¸¦æ¥å·¨å¤§çš„ç¨³å®šæ€§æ”¹è¿›**
- **åœ¨æ•°å€¼è®¡ç®—ä¸­ï¼Œ"æ•°å­¦ä¸Šç­‰ä»·"â‰ "æ•°å€¼ä¸Šç­‰ä»·"**

---

### 3. Householderå˜æ¢

**å®šä¹‰ 3.1 (Householderå˜æ¢)**:

$$
H = I - 2vv^T
$$

å…¶ä¸­ $v$ æ˜¯å•ä½å‘é‡ï¼ˆ$\|v\| = 1$ï¼‰ã€‚

**æ€§è´¨**:

- $H$ æ˜¯å¯¹ç§°æ­£äº¤çŸ©é˜µï¼ˆ$H = H^T$ï¼Œ$H^2 = I$ï¼‰
- $H$ æ˜¯å…³äºŽè¶…å¹³é¢ $\{x : v^T x = 0\}$ çš„åå°„

**åº”ç”¨**ï¼šQRåˆ†è§£ï¼ˆHouseholder QRï¼‰

---

## ðŸ’¡ Choleskyåˆ†è§£

### 1. Choleskyåˆ†è§£å®šä¹‰

**å®šç† 1.1 (Choleskyåˆ†è§£)**:

è®¾ $A \in \mathbb{R}^{n \times n}$ æ˜¯**å¯¹ç§°æ­£å®šçŸ©é˜µ**ï¼Œåˆ™å­˜åœ¨å”¯ä¸€çš„ä¸‹ä¸‰è§’çŸ©é˜µ $L$ï¼ˆå¯¹è§’å…ƒç´ ä¸ºæ­£ï¼‰ä½¿å¾—ï¼š

$$
A = LL^T
$$

**ä¼˜åŠ¿**:

- è®¡ç®—æ•ˆçŽ‡é«˜ï¼ˆçº¦ä¸ºLUåˆ†è§£çš„ä¸€åŠï¼‰
- æ•°å€¼ç¨³å®š
- ä¿è¯æ­£å®šæ€§

**åº”ç”¨**ï¼š

- æ±‚è§£çº¿æ€§ç³»ç»Ÿ $Ax = b$
- é«˜æ–¯è¿‡ç¨‹
- ä¼˜åŒ–ç®—æ³•

---

### 2. ç®—æ³•

**ç®—æ³• 2.1 (Choleskyåˆ†è§£ç®—æ³•)**:

$$
L_{ij} = \begin{cases}
\sqrt{A_{ii} - \sum_{k=1}^{i-1} L_{ik}^2} & \text{if } i = j \\
\frac{1}{L_{jj}} \left( A_{ij} - \sum_{k=1}^{j-1} L_{ik} L_{jk} \right) & \text{if } i > j \\
0 & \text{if } i < j
\end{cases}
$$

**å¤æ‚åº¦**: $O(n^3/3)$

---

## ðŸŽ¨ LUåˆ†è§£

### 1. LUåˆ†è§£å®šä¹‰

**å®šç† 1.1 (LUåˆ†è§£)**:

è®¾ $A \in \mathbb{R}^{n \times n}$ï¼Œå¦‚æžœ $A$ çš„æ‰€æœ‰é¡ºåºä¸»å­å¼éžé›¶ï¼Œåˆ™å­˜åœ¨åˆ†è§£ï¼š

$$
A = LU
$$

å…¶ä¸­ï¼š

- $L$ æ˜¯ä¸‹ä¸‰è§’çŸ©é˜µï¼ˆå¯¹è§’å…ƒç´ ä¸º1ï¼‰
- $U$ æ˜¯ä¸Šä¸‰è§’çŸ©é˜µ

**å¸¦ä¸»å…ƒçš„LUåˆ†è§£**:

$$
PA = LU
$$

å…¶ä¸­ $P$ æ˜¯ç½®æ¢çŸ©é˜µã€‚

---

### 2. é«˜æ–¯æ¶ˆå…ƒæ³•

**ç®—æ³• 2.1 (é«˜æ–¯æ¶ˆå…ƒæ³•)**:

é€šè¿‡è¡Œå˜æ¢å°† $A$ åŒ–ä¸ºä¸Šä¸‰è§’çŸ©é˜µ $U$ï¼ŒåŒæ—¶è®°å½•å˜æ¢å¾—åˆ° $L$ã€‚

**åº”ç”¨**ï¼š

- æ±‚è§£çº¿æ€§ç³»ç»Ÿ
- è®¡ç®—è¡Œåˆ—å¼
- æ±‚é€†çŸ©é˜µ

---

## ðŸ”§ åœ¨æ·±åº¦å­¦ä¹ ä¸­çš„åº”ç”¨

### 1. ä¸»æˆåˆ†åˆ†æž (PCA)

**é—®é¢˜**ï¼šæ‰¾åˆ°æ•°æ®çš„ä¸»è¦æ–¹å‘ã€‚

**æ–¹æ³•**ï¼š

1. ä¸­å¿ƒåŒ–æ•°æ®ï¼š$X_c = X - \bar{X}$
2. è®¡ç®—åæ–¹å·®çŸ©é˜µï¼š$C = \frac{1}{n} X_c^T X_c$
3. ç‰¹å¾å€¼åˆ†è§£ï¼š$C = Q\Lambda Q^T$
4. ä¸»æˆåˆ†ï¼š$Q$ çš„å‰ $k$ åˆ—

**ç­‰ä»·æ–¹æ³•ï¼ˆSVDï¼‰**:

1. SVD: $X_c = U\Sigma V^T$
2. ä¸»æˆåˆ†ï¼š$V$ çš„å‰ $k$ åˆ—
3. é™ç»´ï¼š$Z = X_c V_k$

---

### 2. å¥‡å¼‚å€¼åˆ†è§£ä¸Žé™ç»´

**åº”ç”¨**ï¼š

- **å›¾åƒåŽ‹ç¼©**ï¼šæˆªæ–­SVD
- **æŽ¨èç³»ç»Ÿ**ï¼šçŸ©é˜µåˆ†è§£
- **åŽ»å™ª**ï¼šä¿ç•™å¤§å¥‡å¼‚å€¼

**ç¤ºä¾‹**ï¼ˆå›¾åƒåŽ‹ç¼©ï¼‰:

```python
A_k = U[:, :k] @ Sigma[:k, :k] @ V[:k, :]
```

åŽ‹ç¼©çŽ‡ï¼š$\frac{k(m + n)}{mn}$

---

### 3. çŸ©é˜µæ±‚é€†ä¸Žçº¿æ€§ç³»ç»Ÿ

**æ±‚è§£ $Ax = b$**:

- **Choleskyåˆ†è§£**ï¼ˆ$A$ æ­£å®šï¼‰ï¼š
  1. $A = LL^T$
  2. æ±‚è§£ $Ly = b$ (å‰å‘æ›¿æ¢)
  3. æ±‚è§£ $L^T x = y$ (åŽå‘æ›¿æ¢)

- **LUåˆ†è§£**ï¼š
  1. $A = LU$
  2. æ±‚è§£ $Ly = b$
  3. æ±‚è§£ $Ux = y$

**ä¼˜åŠ¿**ï¼šé¿å…ç›´æŽ¥æ±‚é€†ï¼ˆæ•°å€¼ä¸ç¨³å®šï¼‰ã€‚

---

### 4. æƒé‡åˆå§‹åŒ–

**Xavieråˆå§‹åŒ–**ï¼ˆåŸºäºŽç‰¹å¾å€¼åˆ†æžï¼‰:

$$
W \sim \mathcal{N}\left(0, \frac{2}{n_{\text{in}} + n_{\text{out}}}\right)
$$

**Heåˆå§‹åŒ–**ï¼ˆReLUç½‘ç»œï¼‰:

$$
W \sim \mathcal{N}\left(0, \frac{2}{n_{\text{in}}}\right)
$$

**ç†è®ºåŸºç¡€**ï¼šä¿æŒæ¿€æ´»å€¼å’Œæ¢¯åº¦çš„æ–¹å·®ã€‚

---

## ðŸ’» Pythonå®žçŽ°

```python
import numpy as np
import matplotlib.pyplot as plt
from scipy.linalg import svd, qr, cholesky, lu

# 1. ç‰¹å¾å€¼åˆ†è§£
def eigendecomposition_demo():
    """ç‰¹å¾å€¼åˆ†è§£ç¤ºä¾‹"""
    # å¯¹ç§°çŸ©é˜µ
    A = np.array([[2, 1], [1, 2]])
    
    # ç‰¹å¾å€¼åˆ†è§£
    eigenvalues, eigenvectors = np.linalg.eig(A)
    
    print("çŸ©é˜µ A:")
    print(A)
    print("\nç‰¹å¾å€¼:")
    print(eigenvalues)
    print("\nç‰¹å¾å‘é‡:")
    print(eigenvectors)
    
    # éªŒè¯: A = QÎ›Q^T
    Lambda = np.diag(eigenvalues)
    Q = eigenvectors
    A_reconstructed = Q @ Lambda @ Q.T
    
    print("\né‡æž„è¯¯å·®:")
    print(np.linalg.norm(A - A_reconstructed))


# 2. SVDåˆ†è§£
def svd_demo():
    """SVDåˆ†è§£ç¤ºä¾‹"""
    # åˆ›å»ºçŸ©é˜µ
    A = np.array([[3, 2, 2],
                  [2, 3, -2]])
    
    # SVDåˆ†è§£
    U, S, Vt = svd(A)
    
    print("çŸ©é˜µ A:")
    print(A)
    print(f"\nAçš„å½¢çŠ¶: {A.shape}")
    print(f"Uçš„å½¢çŠ¶: {U.shape}")
    print(f"Sçš„å½¢çŠ¶: {S.shape}")
    print(f"Vtçš„å½¢çŠ¶: {Vt.shape}")
    
    print("\nå¥‡å¼‚å€¼:")
    print(S)
    
    # é‡æž„
    Sigma = np.zeros((A.shape[0], A.shape[1]))
    Sigma[:len(S), :len(S)] = np.diag(S)
    A_reconstructed = U @ Sigma @ Vt
    
    print("\né‡æž„è¯¯å·®:")
    print(np.linalg.norm(A - A_reconstructed))


# 3. PCAå®žçŽ°
def pca_demo():
    """PCAé™ç»´ç¤ºä¾‹"""
    np.random.seed(42)
    
    # ç”Ÿæˆ2Dæ•°æ®
    mean = [0, 0]
    cov = [[3, 1.5], [1.5, 1]]
    X = np.random.multivariate_normal(mean, cov, 200)
    
    # PCA (ä½¿ç”¨SVD)
    X_centered = X - X.mean(axis=0)
    U, S, Vt = svd(X_centered, full_matrices=False)
    
    # ä¸»æˆåˆ†
    principal_components = Vt.T
    
    # æŠ•å½±åˆ°ç¬¬ä¸€ä¸»æˆåˆ†
    Z = X_centered @ principal_components[:, 0:1]
    X_reconstructed = Z @ principal_components[:, 0:1].T + X.mean(axis=0)
    
    # å¯è§†åŒ–
    plt.figure(figsize=(12, 5))
    
    # åŽŸå§‹æ•°æ®
    plt.subplot(1, 2, 1)
    plt.scatter(X[:, 0], X[:, 1], alpha=0.5)
    plt.arrow(0, 0, principal_components[0, 0]*S[0], principal_components[1, 0]*S[0],
              head_width=0.3, head_length=0.3, fc='r', ec='r', label='PC1')
    plt.arrow(0, 0, principal_components[0, 1]*S[1], principal_components[1, 1]*S[1],
              head_width=0.3, head_length=0.3, fc='g', ec='g', label='PC2')
    plt.title('Original Data with Principal Components')
    plt.xlabel('x1')
    plt.ylabel('x2')
    plt.legend()
    plt.axis('equal')
    plt.grid(True)
    
    # é‡æž„æ•°æ®
    plt.subplot(1, 2, 2)
    plt.scatter(X[:, 0], X[:, 1], alpha=0.3, label='Original')
    plt.scatter(X_reconstructed[:, 0], X_reconstructed[:, 1], alpha=0.5, label='Reconstructed (1D)')
    plt.title('PCA Reconstruction')
    plt.xlabel('x1')
    plt.ylabel('x2')
    plt.legend()
    plt.axis('equal')
    plt.grid(True)
    
    plt.tight_layout()
    # plt.show()
    
    # è§£é‡Šæ–¹å·®æ¯”ä¾‹
    explained_variance_ratio = S**2 / np.sum(S**2)
    print("è§£é‡Šæ–¹å·®æ¯”ä¾‹:")
    print(explained_variance_ratio)


# 4. ä½Žç§©è¿‘ä¼¼
def low_rank_approximation_demo():
    """ä½Žç§©è¿‘ä¼¼ç¤ºä¾‹ï¼ˆå›¾åƒåŽ‹ç¼©ï¼‰"""
    # åˆ›å»ºä¸€ä¸ªç®€å•çš„"å›¾åƒ"
    np.random.seed(42)
    img = np.random.randn(50, 50)
    
    # SVD
    U, S, Vt = svd(img, full_matrices=False)
    
    # ä¸åŒç§©çš„è¿‘ä¼¼
    ranks = [1, 5, 10, 20, 50]
    
    plt.figure(figsize=(15, 3))
    
    for i, k in enumerate(ranks):
        # æˆªæ–­SVD
        img_k = U[:, :k] @ np.diag(S[:k]) @ Vt[:k, :]
        
        # è®¡ç®—è¯¯å·®
        error = np.linalg.norm(img - img_k, 'fro') / np.linalg.norm(img, 'fro')
        
        plt.subplot(1, len(ranks), i+1)
        plt.imshow(img_k, cmap='gray')
        plt.title(f'Rank {k}\nError: {error:.3f}')
        plt.axis('off')
    
    plt.tight_layout()
    # plt.show()


# 5. Choleskyåˆ†è§£
def cholesky_demo():
    """Choleskyåˆ†è§£ç¤ºä¾‹"""
    # åˆ›å»ºæ­£å®šçŸ©é˜µ
    A = np.array([[4, 2, 1],
                  [2, 3, 1],
                  [1, 1, 2]])
    
    print("çŸ©é˜µ A (æ­£å®š):")
    print(A)
    
    # Choleskyåˆ†è§£
    L = cholesky(A, lower=True)
    
    print("\nCholeskyåˆ†è§£ L:")
    print(L)
    
    # éªŒè¯
    A_reconstructed = L @ L.T
    print("\né‡æž„è¯¯å·®:")
    print(np.linalg.norm(A - A_reconstructed))
    
    # æ±‚è§£çº¿æ€§ç³»ç»Ÿ Ax = b
    b = np.array([1, 2, 3])
    
    # ä½¿ç”¨Choleskyåˆ†è§£æ±‚è§£
    y = np.linalg.solve(L, b)  # Ly = b
    x = np.linalg.solve(L.T, y)  # L^T x = y
    
    print("\næ±‚è§£ Ax = b:")
    print(f"x = {x}")
    print(f"éªŒè¯ Ax = {A @ x}")


# 6. QRåˆ†è§£
def qr_demo():
    """QRåˆ†è§£ç¤ºä¾‹"""
    A = np.array([[1, 2, 3],
                  [4, 5, 6],
                  [7, 8, 9],
                  [10, 11, 12]], dtype=float)
    
    print("çŸ©é˜µ A:")
    print(A)
    
    # QRåˆ†è§£
    Q, R = qr(A)
    
    print("\nQ (æ­£äº¤çŸ©é˜µ):")
    print(Q)
    print("\nR (ä¸Šä¸‰è§’çŸ©é˜µ):")
    print(R)
    
    # éªŒè¯æ­£äº¤æ€§
    print("\nQ^T Q:")
    print(Q.T @ Q)
    
    # é‡æž„
    A_reconstructed = Q @ R
    print("\né‡æž„è¯¯å·®:")
    print(np.linalg.norm(A - A_reconstructed))


if __name__ == "__main__":
    print("=== çŸ©é˜µåˆ†è§£ç¤ºä¾‹ ===\n")
    
    print("1. ç‰¹å¾å€¼åˆ†è§£")
    eigendecomposition_demo()
    
    print("\n" + "="*50 + "\n")
    print("2. SVDåˆ†è§£")
    svd_demo()
    
    print("\n" + "="*50 + "\n")
    print("3. PCAé™ç»´")
    pca_demo()
    
    print("\n" + "="*50 + "\n")
    print("4. ä½Žç§©è¿‘ä¼¼")
    low_rank_approximation_demo()
    
    print("\n" + "="*50 + "\n")
    print("5. Choleskyåˆ†è§£")
    cholesky_demo()
    
    print("\n" + "="*50 + "\n")
    print("6. QRåˆ†è§£")
    qr_demo()
```

---

## ðŸ“š ç»ƒä¹ é¢˜

### ç»ƒä¹ 1ï¼šç‰¹å¾å€¼è®¡ç®—

è®¡ç®—ä»¥ä¸‹çŸ©é˜µçš„ç‰¹å¾å€¼å’Œç‰¹å¾å‘é‡ï¼š

$$
A = \begin{bmatrix} 1 & 2 \\ 2 & 1 \end{bmatrix}
$$

### ç»ƒä¹ 2ï¼šSVDåº”ç”¨

å¯¹çŸ©é˜µ $A = \begin{bmatrix} 1 & 2 \\ 3 & 4 \\ 5 & 6 \end{bmatrix}$ è¿›è¡ŒSVDåˆ†è§£ï¼Œå¹¶è®¡ç®—ç§©-1è¿‘ä¼¼ã€‚

### ç»ƒä¹ 3ï¼šPCAå®žçŽ°

ç»™å®šæ•°æ®çŸ©é˜µ $X \in \mathbb{R}^{100 \times 5}$ï¼Œä½¿ç”¨PCAå°†å…¶é™è‡³2ç»´ã€‚

### ç»ƒä¹ 4ï¼šä½Žç§©è¿‘ä¼¼

è¯æ˜ŽEckart-Youngå®šç†ï¼šæˆªæ–­SVDç»™å‡ºæœ€ä¼˜ä½Žç§©è¿‘ä¼¼ã€‚

---

## ðŸŽ“ ç›¸å…³è¯¾ç¨‹

| å¤§å­¦ | è¯¾ç¨‹ |
|------|------|
| **MIT** | 18.06 - Linear Algebra (Gilbert Strang) |
| **MIT** | 18.065 - Matrix Methods in Data Analysis |
| **Stanford** | CS205L - Continuous Mathematical Methods |
| **UC Berkeley** | Math 110 - Linear Algebra |
| **CMU** | 21-241 - Matrices and Linear Transformations |

---

## ðŸ“– å‚è€ƒæ–‡çŒ®

1. **Strang, G. (2016)**. *Introduction to Linear Algebra*. Wellesley-Cambridge Press.

2. **Trefethen & Bau (1997)**. *Numerical Linear Algebra*. SIAM.

3. **Golub & Van Loan (2013)**. *Matrix Computations*. Johns Hopkins University Press.

4. **Horn & Johnson (2012)**. *Matrix Analysis*. Cambridge University Press.

5. **Goodfellow et al. (2016)**. *Deep Learning*. MIT Press. (Chapter 2: Linear Algebra)

---

*æœ€åŽæ›´æ–°ï¼š2025å¹´10æœˆ*-
