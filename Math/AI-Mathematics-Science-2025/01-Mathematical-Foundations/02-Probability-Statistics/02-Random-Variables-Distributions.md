# éšæœºå˜é‡ä¸åˆ†å¸ƒ (Random Variables and Distributions)

> **The Foundation of Probabilistic Machine Learning**
>
> æ¦‚ç‡æœºå™¨å­¦ä¹ çš„åŸºç¡€

---

## ç›®å½•

- [éšæœºå˜é‡ä¸åˆ†å¸ƒ (Random Variables and Distributions)](#éšæœºå˜é‡ä¸åˆ†å¸ƒ-random-variables-and-distributions)
  - [ç›®å½•](#ç›®å½•)
  - [ğŸ“‹ æ ¸å¿ƒæ€æƒ³](#-æ ¸å¿ƒæ€æƒ³)
  - [ğŸ¯ éšæœºå˜é‡](#-éšæœºå˜é‡)
    - [1. éšæœºå˜é‡å®šä¹‰](#1-éšæœºå˜é‡å®šä¹‰)
    - [2. åˆ†å¸ƒå‡½æ•°](#2-åˆ†å¸ƒå‡½æ•°)
    - [3. æ¦‚ç‡å¯†åº¦å‡½æ•°](#3-æ¦‚ç‡å¯†åº¦å‡½æ•°)
  - [ğŸ“Š å¸¸è§åˆ†å¸ƒ](#-å¸¸è§åˆ†å¸ƒ)
    - [1. ç¦»æ•£åˆ†å¸ƒ](#1-ç¦»æ•£åˆ†å¸ƒ)
    - [2. è¿ç»­åˆ†å¸ƒ](#2-è¿ç»­åˆ†å¸ƒ)
  - [ğŸ”¬ æœŸæœ›ä¸æ–¹å·®](#-æœŸæœ›ä¸æ–¹å·®)
    - [1. æœŸæœ›](#1-æœŸæœ›)
    - [2. æ–¹å·®](#2-æ–¹å·®)
    - [3. åæ–¹å·®ä¸ç›¸å…³ç³»æ•°](#3-åæ–¹å·®ä¸ç›¸å…³ç³»æ•°)
  - [ğŸ’¡ å¤šå…ƒéšæœºå˜é‡](#-å¤šå…ƒéšæœºå˜é‡)
    - [1. è”åˆåˆ†å¸ƒ](#1-è”åˆåˆ†å¸ƒ)
    - [2. è¾¹ç¼˜åˆ†å¸ƒ](#2-è¾¹ç¼˜åˆ†å¸ƒ)
    - [3. æ¡ä»¶åˆ†å¸ƒ](#3-æ¡ä»¶åˆ†å¸ƒ)
    - [4. ç‹¬ç«‹æ€§](#4-ç‹¬ç«‹æ€§)
  - [ğŸ¨ å˜æ¢ä¸çŸ©æ¯å‡½æ•°](#-å˜æ¢ä¸çŸ©æ¯å‡½æ•°)
    - [1. éšæœºå˜é‡çš„å˜æ¢](#1-éšæœºå˜é‡çš„å˜æ¢)
    - [2. çŸ©æ¯å‡½æ•°](#2-çŸ©æ¯å‡½æ•°)
    - [3. ç‰¹å¾å‡½æ•°](#3-ç‰¹å¾å‡½æ•°)
  - [ğŸ”§ åœ¨æœºå™¨å­¦ä¹ ä¸­çš„åº”ç”¨](#-åœ¨æœºå™¨å­¦ä¹ ä¸­çš„åº”ç”¨)
    - [1. è´å¶æ–¯æ¨æ–­](#1-è´å¶æ–¯æ¨æ–­)
    - [2. æœ€å¤§ä¼¼ç„¶ä¼°è®¡](#2-æœ€å¤§ä¼¼ç„¶ä¼°è®¡)
    - [3. å˜åˆ†æ¨æ–­](#3-å˜åˆ†æ¨æ–­)
    - [4. é‡‡æ ·æ–¹æ³•](#4-é‡‡æ ·æ–¹æ³•)
  - [ğŸ’» Pythonå®ç°](#-pythonå®ç°)
  - [ğŸ“š ç»ƒä¹ é¢˜](#-ç»ƒä¹ é¢˜)
    - [ç»ƒä¹ 1ï¼šåˆ†å¸ƒè®¡ç®—](#ç»ƒä¹ 1åˆ†å¸ƒè®¡ç®—)
    - [ç»ƒä¹ 2ï¼šæœŸæœ›ä¸æ–¹å·®](#ç»ƒä¹ 2æœŸæœ›ä¸æ–¹å·®)
    - [ç»ƒä¹ 3ï¼šå˜æ¢](#ç»ƒä¹ 3å˜æ¢)
    - [ç»ƒä¹ 4ï¼šæœ€å¤§ä¼¼ç„¶ä¼°è®¡](#ç»ƒä¹ 4æœ€å¤§ä¼¼ç„¶ä¼°è®¡)
  - [ğŸ“ ç›¸å…³è¯¾ç¨‹](#-ç›¸å…³è¯¾ç¨‹)
  - [ğŸ“– å‚è€ƒæ–‡çŒ®](#-å‚è€ƒæ–‡çŒ®)

---

## ğŸ“‹ æ ¸å¿ƒæ€æƒ³

**éšæœºå˜é‡**æ˜¯å°†éšæœºäº‹ä»¶æ˜ å°„åˆ°å®æ•°çš„å‡½æ•°ï¼Œæ˜¯æ¦‚ç‡è®ºçš„æ ¸å¿ƒæ¦‚å¿µã€‚

**ä¸ºä»€ä¹ˆéšæœºå˜é‡é‡è¦**:

```text
æœºå™¨å­¦ä¹ ä¸­çš„éšæœºæ€§:
â”œâ”€ æ•°æ®æœ¬èº«æ˜¯éšæœºçš„
â”œâ”€ æ¨¡å‹å‚æ•°æ˜¯éšæœºçš„ (è´å¶æ–¯è§‚ç‚¹)
â”œâ”€ è®­ç»ƒè¿‡ç¨‹æ˜¯éšæœºçš„ (SGD)
â””â”€ é¢„æµ‹æ˜¯æ¦‚ç‡æ€§çš„

æ ¸å¿ƒåº”ç”¨:
â”œâ”€ è´å¶æ–¯æ¨æ–­
â”œâ”€ æœ€å¤§ä¼¼ç„¶ä¼°è®¡
â”œâ”€ å˜åˆ†æ¨æ–­
â””â”€ ç”Ÿæˆæ¨¡å‹ (VAE, GAN)
```

---

## ğŸ¯ éšæœºå˜é‡

### 1. éšæœºå˜é‡å®šä¹‰

**å®šä¹‰ 1.1 (éšæœºå˜é‡)**:

è®¾ $(\Omega, \mathcal{F}, P)$ æ˜¯æ¦‚ç‡ç©ºé—´ï¼Œéšæœºå˜é‡ $X$ æ˜¯ä» $\Omega$ åˆ° $\mathbb{R}$ çš„**å¯æµ‹å‡½æ•°**ï¼š

$$
X: \Omega \to \mathbb{R}
$$

ä½¿å¾—å¯¹äºä»»æ„ $a \in \mathbb{R}$ï¼Œé›†åˆ $\{X \leq a\} = \{\omega \in \Omega : X(\omega) \leq a\} \in \mathcal{F}$ã€‚

**ç›´è§‰**ï¼šéšæœºå˜é‡å°†éšæœºäº‹ä»¶çš„ç»“æœæ˜ å°„åˆ°æ•°å€¼ã€‚

**ç¤ºä¾‹**:

- æ·éª°å­ï¼š$X(\omega) = \omega$ (ç‚¹æ•°)
- æŠ›ç¡¬å¸ï¼š$X(\text{æ­£}) = 1, X(\text{å}) = 0$

---

### 2. åˆ†å¸ƒå‡½æ•°

**å®šä¹‰ 2.1 (ç´¯ç§¯åˆ†å¸ƒå‡½æ•°, CDF)**:

éšæœºå˜é‡ $X$ çš„ç´¯ç§¯åˆ†å¸ƒå‡½æ•° $F_X: \mathbb{R} \to [0, 1]$ å®šä¹‰ä¸ºï¼š

$$
F_X(x) = P(X \leq x)
$$

**æ€§è´¨**:

1. **å•è°ƒæ€§**: $F_X$ æ˜¯éé€’å‡çš„
2. **å³è¿ç»­æ€§**: $\lim_{x \to a^+} F_X(x) = F_X(a)$
3. **æé™æ€§**: $\lim_{x \to -\infty} F_X(x) = 0$, $\lim_{x \to \infty} F_X(x) = 1$

---

**æ€§è´¨çš„å®Œæ•´è¯æ˜**:

**è¯æ˜1ï¼šå•è°ƒæ€§**:

éœ€è¦è¯æ˜ï¼šè‹¥ $x_1 \leq x_2$ï¼Œåˆ™ $F_X(x_1) \leq F_X(x_2)$

**è¯æ˜**:

è®¾ $x_1 \leq x_2$ã€‚æ³¨æ„åˆ°ï¼š

$$
\{X \leq x_1\} \subseteq \{X \leq x_2\}
$$

å› ä¸ºå¦‚æœ $X(\omega) \leq x_1$ï¼Œåˆ™ $X(\omega) \leq x_1 \leq x_2$ï¼Œæ‰€ä»¥ $X(\omega) \leq x_2$ã€‚

ç”±æ¦‚ç‡çš„å•è°ƒæ€§ï¼ˆå¦‚æœ $A \subseteq B$ï¼Œåˆ™ $P(A) \leq P(B)$ï¼‰ï¼š

$$
F_X(x_1) = P(X \leq x_1) \leq P(X \leq x_2) = F_X(x_2)
$$

$\square$

---

**è¯æ˜2ï¼šå³è¿ç»­æ€§**:

éœ€è¦è¯æ˜ï¼š$\lim_{x \to a^+} F_X(x) = F_X(a)$

**è¯æ˜**:

è€ƒè™‘é€’å‡åºåˆ— $x_n \downarrow a$ï¼ˆå³ $x_1 > x_2 > \cdots > a$ ä¸” $\lim_{n \to \infty} x_n = a$ï¼‰ã€‚

å®šä¹‰äº‹ä»¶åºåˆ—ï¼š

$$
A_n = \{X \leq x_n\}
$$

**å…³é”®è§‚å¯Ÿ**:

1. $A_1 \supseteq A_2 \supseteq A_3 \supseteq \cdots$ ï¼ˆé€’å‡åºåˆ—ï¼‰

2. $\bigcap_{n=1}^\infty A_n = \{X \leq a\}$

**è¯æ˜ç¬¬2ç‚¹**:

- è‹¥ $\omega \in \bigcap_{n=1}^\infty A_n$ï¼Œåˆ™å¯¹æ‰€æœ‰ $n$ï¼Œ$X(\omega) \leq x_n$ã€‚
  
  å–æé™ï¼š$X(\omega) \leq \lim_{n \to \infty} x_n = a$ï¼Œæ‰€ä»¥ $\omega \in \{X \leq a\}$ã€‚

- åä¹‹ï¼Œè‹¥ $\omega \in \{X \leq a\}$ï¼Œåˆ™ $X(\omega) \leq a < x_n$ å¯¹æ‰€æœ‰ $n$ï¼ˆå› ä¸º $x_n > a$ï¼‰ã€‚
  
  æ‰€ä»¥ $\omega \in A_n$ å¯¹æ‰€æœ‰ $n$ï¼Œå³ $\omega \in \bigcap_{n=1}^\infty A_n$ã€‚

**åº”ç”¨æµ‹åº¦çš„è¿ç»­æ€§**:

å¯¹äºé€’å‡äº‹ä»¶åºåˆ—ï¼Œæ¦‚ç‡æµ‹åº¦çš„è¿ç»­æ€§ç»™å‡ºï¼š

$$
\lim_{n \to \infty} P(A_n) = P\left(\bigcap_{n=1}^\infty A_n\right)
$$

å³ï¼š

$$
\lim_{n \to \infty} F_X(x_n) = \lim_{n \to \infty} P(X \leq x_n) = P(X \leq a) = F_X(a)
$$

ç”±äºè¿™å¯¹ä»»æ„é€’å‡åºåˆ— $x_n \downarrow a$ æˆç«‹ï¼Œæˆ‘ä»¬æœ‰ï¼š

$$
\lim_{x \to a^+} F_X(x) = F_X(a)
$$

$\square$

**æ³¨æ„**: CDFä¸€èˆ¬ä¸æ˜¯å·¦è¿ç»­çš„ã€‚å·¦æé™ä¸ºï¼š

$$
\lim_{x \to a^-} F_X(x) = P(X < a) = F_X(a) - P(X = a)
$$

å¦‚æœ $P(X = a) > 0$ï¼ˆå³ $a$ æ˜¯åŸå­ç‚¹ï¼‰ï¼Œåˆ™CDFåœ¨ $a$ å¤„æœ‰è·³è·ƒã€‚

---

**è¯æ˜3ï¼šæé™æ€§**:

éœ€è¦è¯æ˜ï¼š
1. $\lim_{x \to -\infty} F_X(x) = 0$
2. $\lim_{x \to \infty} F_X(x) = 1$

**è¯æ˜ (1)**:

è€ƒè™‘é€’å‡åºåˆ— $x_n \to -\infty$ï¼ˆä¾‹å¦‚ $x_n = -n$ï¼‰ã€‚

å®šä¹‰äº‹ä»¶åºåˆ—ï¼š

$$
A_n = \{X \leq x_n\}
$$

åˆ™ $A_1 \supseteq A_2 \supseteq A_3 \supseteq \cdots$ï¼ˆé€’å‡ï¼‰ã€‚

**å…³é”®è§‚å¯Ÿ**: $\bigcap_{n=1}^\infty A_n = \emptyset$

**è¯æ˜**:

å‡è®¾å­˜åœ¨ $\omega \in \bigcap_{n=1}^\infty A_n$ï¼Œåˆ™å¯¹æ‰€æœ‰ $n$ï¼Œ$X(\omega) \leq x_n$ã€‚

ä½† $x_n \to -\infty$ï¼Œè¿™æ„å‘³ç€ $X(\omega) \leq -n$ å¯¹æ‰€æœ‰ $n$ï¼Œå³ $X(\omega) = -\infty$ã€‚

è¿™ä¸ $X$ æ˜¯å®å€¼éšæœºå˜é‡çŸ›ç›¾ï¼ˆ$X: \Omega \to \mathbb{R}$ï¼‰ã€‚

å› æ­¤ $\bigcap_{n=1}^\infty A_n = \emptyset$ã€‚

**åº”ç”¨æµ‹åº¦çš„è¿ç»­æ€§**:

$$
\lim_{n \to \infty} P(A_n) = P\left(\bigcap_{n=1}^\infty A_n\right) = P(\emptyset) = 0
$$

å³ï¼š

$$
\lim_{x \to -\infty} F_X(x) = 0
$$

$\square$

**è¯æ˜ (2)**:

è€ƒè™‘é€’å¢åºåˆ— $x_n \to \infty$ï¼ˆä¾‹å¦‚ $x_n = n$ï¼‰ã€‚

å®šä¹‰äº‹ä»¶åºåˆ—ï¼š

$$
B_n = \{X \leq x_n\}
$$

åˆ™ $B_1 \subseteq B_2 \subseteq B_3 \subseteq \cdots$ï¼ˆé€’å¢ï¼‰ã€‚

**å…³é”®è§‚å¯Ÿ**: $\bigcup_{n=1}^\infty B_n = \Omega$

**è¯æ˜**:

å¯¹äºä»»æ„ $\omega \in \Omega$ï¼Œ$X(\omega)$ æ˜¯æœ‰é™å®æ•°ã€‚

é€‰æ‹© $n$ è¶³å¤Ÿå¤§ä½¿å¾— $x_n > X(\omega)$ï¼Œåˆ™ $\omega \in B_n$ã€‚

å› æ­¤ $\omega \in \bigcup_{n=1}^\infty B_n$ï¼Œæ‰€ä»¥ $\Omega \subseteq \bigcup_{n=1}^\infty B_n$ã€‚

åå‘åŒ…å«æ˜¾ç„¶ï¼Œå› æ­¤ $\bigcup_{n=1}^\infty B_n = \Omega$ã€‚

**åº”ç”¨æµ‹åº¦çš„è¿ç»­æ€§**:

$$
\lim_{n \to \infty} P(B_n) = P\left(\bigcup_{n=1}^\infty B_n\right) = P(\Omega) = 1
$$

å³ï¼š

$$
\lim_{x \to \infty} F_X(x) = 1
$$

$\square$

---

**æ€§è´¨çš„å‡ ä½•æ„ä¹‰**:

1. **å•è°ƒæ€§**: CDFæ˜¯é˜¶æ¢¯å‡½æ•°æˆ–è¿ç»­å¢å‡½æ•°ï¼Œæ°¸ä¸ä¸‹é™
2. **å³è¿ç»­æ€§**: CDFä»å³ä¾§é€¼è¿‘æ¯ä¸ªç‚¹çš„å€¼ï¼Œè·³è·ƒå‘ç”Ÿåœ¨å·¦ä¾§
3. **æé™æ€§**: CDFä»0å¼€å§‹ï¼Œæœ€ç»ˆè¾¾åˆ°1ï¼Œåæ˜ äº†æ¦‚ç‡çš„å½’ä¸€åŒ–

**åº”ç”¨ç¤ºä¾‹**:

è€ƒè™‘ç¦»æ•£éšæœºå˜é‡ $X \sim \text{Bernoulli}(p)$ï¼š

$$
F_X(x) = \begin{cases}
0 & x < 0 \\
1-p & 0 \leq x < 1 \\
1 & x \geq 1
\end{cases}
$$

éªŒè¯æ€§è´¨ï¼š
- å•è°ƒæ€§: $0 \leq 1-p \leq 1$ âœ“
- å³è¿ç»­æ€§: åœ¨ $x=0$ å’Œ $x=1$ å¤„å³è¿ç»­ âœ“
- æé™æ€§: $\lim_{x \to -\infty} F_X(x) = 0$, $\lim_{x \to \infty} F_X(x) = 1$ âœ“
- è·³è·ƒ: åœ¨ $x=0$ å¤„è·³è·ƒ $1-p$ï¼Œåœ¨ $x=1$ å¤„è·³è·ƒ $p$

---

### 3. æ¦‚ç‡å¯†åº¦å‡½æ•°

**å®šä¹‰ 3.1 (æ¦‚ç‡å¯†åº¦å‡½æ•°, PDF)**:

å¦‚æœå­˜åœ¨éè´Ÿå‡½æ•° $f_X: \mathbb{R} \to [0, \infty)$ ä½¿å¾—ï¼š

$$
F_X(x) = \int_{-\infty}^x f_X(t) \, dt
$$

åˆ™ç§° $X$ ä¸º**è¿ç»­éšæœºå˜é‡**ï¼Œ$f_X$ ä¸ºå…¶**æ¦‚ç‡å¯†åº¦å‡½æ•°**ã€‚

**æ€§è´¨**:

1. $f_X(x) \geq 0$
2. $\int_{-\infty}^\infty f_X(x) \, dx = 1$
3. $P(a \leq X \leq b) = \int_a^b f_X(x) \, dx$

**ç¦»æ•£æƒ…å†µ**:

å¯¹äºç¦»æ•£éšæœºå˜é‡ï¼Œä½¿ç”¨**æ¦‚ç‡è´¨é‡å‡½æ•° (PMF)**ï¼š

$$
p_X(x) = P(X = x)
$$

---

## ğŸ“Š å¸¸è§åˆ†å¸ƒ

### 1. ç¦»æ•£åˆ†å¸ƒ

**ä¼¯åŠªåˆ©åˆ†å¸ƒ** (Bernoulli):

$$
X \sim \text{Bernoulli}(p)
$$

$$
P(X = 1) = p, \quad P(X = 0) = 1 - p
$$

**æœŸæœ›**: $E[X] = p$  
**æ–¹å·®**: $\text{Var}(X) = p(1-p)$

**åº”ç”¨**: äºŒåˆ†ç±»é—®é¢˜

---

**äºŒé¡¹åˆ†å¸ƒ** (Binomial):

$$
X \sim \text{Binomial}(n, p)
$$

$$
P(X = k) = \binom{n}{k} p^k (1-p)^{n-k}
$$

**æœŸæœ›**: $E[X] = np$  
**æ–¹å·®**: $\text{Var}(X) = np(1-p)$

**åº”ç”¨**: $n$ æ¬¡ç‹¬ç«‹ä¼¯åŠªåˆ©è¯•éªŒä¸­æˆåŠŸçš„æ¬¡æ•°

---

**æ³Šæ¾åˆ†å¸ƒ** (Poisson):

$$
X \sim \text{Poisson}(\lambda)
$$

$$
P(X = k) = \frac{\lambda^k e^{-\lambda}}{k!}
$$

**æœŸæœ›**: $E[X] = \lambda$  
**æ–¹å·®**: $\text{Var}(X) = \lambda$

**åº”ç”¨**: å•ä½æ—¶é—´å†…äº‹ä»¶å‘ç”Ÿçš„æ¬¡æ•°

---

### 2. è¿ç»­åˆ†å¸ƒ

**å‡åŒ€åˆ†å¸ƒ** (Uniform):

$$
X \sim \text{Uniform}(a, b)
$$

$$
f_X(x) = \begin{cases}
\frac{1}{b-a} & \text{if } a \leq x \leq b \\
0 & \text{otherwise}
\end{cases}
$$

**æœŸæœ›**: $E[X] = \frac{a+b}{2}$  
**æ–¹å·®**: $\text{Var}(X) = \frac{(b-a)^2}{12}$

---

**æ­£æ€åˆ†å¸ƒ** (Gaussian):

$$
X \sim \mathcal{N}(\mu, \sigma^2)
$$

$$
f_X(x) = \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left(-\frac{(x-\mu)^2}{2\sigma^2}\right)
$$

**æœŸæœ›**: $E[X] = \mu$  
**æ–¹å·®**: $\text{Var}(X) = \sigma^2$

**æ€§è´¨**:

- **å¯¹ç§°æ€§**: å…³äº $\mu$ å¯¹ç§°
- **çº¿æ€§ç»„åˆ**: æ­£æ€åˆ†å¸ƒçš„çº¿æ€§ç»„åˆä»æ˜¯æ­£æ€åˆ†å¸ƒ
- **ä¸­å¿ƒæé™å®šç†**: ç‹¬ç«‹åŒåˆ†å¸ƒéšæœºå˜é‡çš„å’Œè¶‹å‘äºæ­£æ€åˆ†å¸ƒ

**åº”ç”¨**: æœ€å¸¸ç”¨çš„åˆ†å¸ƒï¼Œå™ªå£°å»ºæ¨¡

---

**æŒ‡æ•°åˆ†å¸ƒ** (Exponential):

$$
X \sim \text{Exp}(\lambda)
$$

$$
f_X(x) = \lambda e^{-\lambda x}, \quad x \geq 0
$$

**æœŸæœ›**: $E[X] = \frac{1}{\lambda}$  
**æ–¹å·®**: $\text{Var}(X) = \frac{1}{\lambda^2}$

**æ€§è´¨**: **æ— è®°å¿†æ€§** $P(X > s + t | X > s) = P(X > t)$

**åº”ç”¨**: ç­‰å¾…æ—¶é—´å»ºæ¨¡

---

## ğŸ”¬ æœŸæœ›ä¸æ–¹å·®

### 1. æœŸæœ›

**å®šä¹‰ 1.1 (æœŸæœ›)**:

**ç¦»æ•£æƒ…å†µ**:

$$
E[X] = \sum_x x \cdot P(X = x)
$$

**è¿ç»­æƒ…å†µ**:

$$
E[X] = \int_{-\infty}^\infty x \cdot f_X(x) \, dx
$$

**æ€§è´¨**:

1. **çº¿æ€§æ€§**: $E[aX + bY] = aE[X] + bE[Y]$
2. **éè´Ÿæ€§**: å¦‚æœ $X \geq 0$ï¼Œåˆ™ $E[X] \geq 0$
3. **å•è°ƒæ€§**: å¦‚æœ $X \leq Y$ï¼Œåˆ™ $E[X] \leq E[Y]$

**å‡½æ•°çš„æœŸæœ›**:

$$
E[g(X)] = \int_{-\infty}^\infty g(x) \cdot f_X(x) \, dx
$$

---

### 2. æ–¹å·®

**å®šä¹‰ 2.1 (æ–¹å·®)**:

$$
\text{Var}(X) = E[(X - E[X])^2] = E[X^2] - (E[X])^2
$$

**æ ‡å‡†å·®**: $\sigma_X = \sqrt{\text{Var}(X)}$

**æ€§è´¨**:

1. $\text{Var}(aX + b) = a^2 \text{Var}(X)$
2. $\text{Var}(X) \geq 0$
3. å¦‚æœ $X, Y$ ç‹¬ç«‹ï¼Œåˆ™ $\text{Var}(X + Y) = \text{Var}(X) + \text{Var}(Y)$

---

### 3. åæ–¹å·®ä¸ç›¸å…³ç³»æ•°

**å®šä¹‰ 3.1 (åæ–¹å·®)**:

$$
\text{Cov}(X, Y) = E[(X - E[X])(Y - E[Y])] = E[XY] - E[X]E[Y]
$$

**æ€§è´¨**:

1. $\text{Cov}(X, X) = \text{Var}(X)$
2. $\text{Cov}(X, Y) = \text{Cov}(Y, X)$
3. $\text{Cov}(aX + b, cY + d) = ac \cdot \text{Cov}(X, Y)$

**ç›¸å…³ç³»æ•°**:

$$
\rho_{XY} = \frac{\text{Cov}(X, Y)}{\sigma_X \sigma_Y}
$$

**æ€§è´¨**: $-1 \leq \rho_{XY} \leq 1$

- $\rho_{XY} = 1$: å®Œå…¨æ­£ç›¸å…³
- $\rho_{XY} = -1$: å®Œå…¨è´Ÿç›¸å…³
- $\rho_{XY} = 0$: ä¸ç›¸å…³ï¼ˆä½†ä¸ä¸€å®šç‹¬ç«‹ï¼‰

---

## ğŸ’¡ å¤šå…ƒéšæœºå˜é‡

### 1. è”åˆåˆ†å¸ƒ

**å®šä¹‰ 1.1 (è”åˆåˆ†å¸ƒ)**:

å¯¹äºéšæœºå‘é‡ $(X, Y)$ï¼Œå…¶è”åˆåˆ†å¸ƒå‡½æ•°ï¼š

$$
F_{X,Y}(x, y) = P(X \leq x, Y \leq y)
$$

**è”åˆå¯†åº¦å‡½æ•°**:

$$
f_{X,Y}(x, y) = \frac{\partial^2 F_{X,Y}}{\partial x \partial y}
$$

**æ€§è´¨**:

$$
\int_{-\infty}^\infty \int_{-\infty}^\infty f_{X,Y}(x, y) \, dx \, dy = 1
$$

---

### 2. è¾¹ç¼˜åˆ†å¸ƒ

**å®šä¹‰ 2.1 (è¾¹ç¼˜åˆ†å¸ƒ)**:

ä»è”åˆåˆ†å¸ƒå¾—åˆ°å•ä¸ªå˜é‡çš„åˆ†å¸ƒï¼š

$$
f_X(x) = \int_{-\infty}^\infty f_{X,Y}(x, y) \, dy
$$

$$
f_Y(y) = \int_{-\infty}^\infty f_{X,Y}(x, y) \, dx
$$

---

### 3. æ¡ä»¶åˆ†å¸ƒ

**å®šä¹‰ 3.1 (æ¡ä»¶åˆ†å¸ƒ)**:

ç»™å®š $Y = y$ æ—¶ï¼Œ$X$ çš„æ¡ä»¶å¯†åº¦ï¼š

$$
f_{X|Y}(x|y) = \frac{f_{X,Y}(x, y)}{f_Y(y)}
$$

**æ¡ä»¶æœŸæœ›**:

$$
E[X | Y = y] = \int_{-\infty}^\infty x \cdot f_{X|Y}(x|y) \, dx
$$

**å…¨æœŸæœ›å…¬å¼**:

$$
E[X] = E[E[X | Y]]
$$

---

### 4. ç‹¬ç«‹æ€§

**å®šä¹‰ 4.1 (ç‹¬ç«‹æ€§)**:

éšæœºå˜é‡ $X$ å’Œ $Y$ ç‹¬ç«‹ï¼Œå¦‚æœï¼š

$$
f_{X,Y}(x, y) = f_X(x) \cdot f_Y(y)
$$

**ç­‰ä»·æ¡ä»¶**:

- $P(X \in A, Y \in B) = P(X \in A) \cdot P(Y \in B)$
- $E[XY] = E[X] \cdot E[Y]$
- $\text{Cov}(X, Y) = 0$ (ä½†åä¹‹ä¸ä¸€å®šæˆç«‹)

---

## ğŸ¨ å˜æ¢ä¸çŸ©æ¯å‡½æ•°

### 1. éšæœºå˜é‡çš„å˜æ¢

**å®šç† 1.1 (å•è°ƒå˜æ¢)**:

è®¾ $Y = g(X)$ï¼Œå…¶ä¸­ $g$ æ˜¯ä¸¥æ ¼å•è°ƒå‡½æ•°ï¼Œåˆ™ï¼š

$$
f_Y(y) = f_X(g^{-1}(y)) \left| \frac{d g^{-1}}{dy}(y) \right|
$$

**ç¤ºä¾‹**: å¦‚æœ $X \sim \mathcal{N}(0, 1)$ï¼Œ$Y = X^2$ï¼Œåˆ™ $Y \sim \chi^2_1$ã€‚

---

### 2. çŸ©æ¯å‡½æ•°

**å®šä¹‰ 2.1 (çŸ©æ¯å‡½æ•°, MGF)**:

$$
M_X(t) = E[e^{tX}]
$$

**æ€§è´¨**:

1. **å”¯ä¸€æ€§**: MGFå”¯ä¸€ç¡®å®šåˆ†å¸ƒ
2. **çŸ©çš„è®¡ç®—**: $E[X^n] = M_X^{(n)}(0)$
3. **ç‹¬ç«‹å’Œ**: å¦‚æœ $X, Y$ ç‹¬ç«‹ï¼Œåˆ™ $M_{X+Y}(t) = M_X(t) \cdot M_Y(t)$

**ç¤ºä¾‹** (æ­£æ€åˆ†å¸ƒ):

$$
X \sim \mathcal{N}(\mu, \sigma^2) \Rightarrow M_X(t) = \exp\left(\mu t + \frac{\sigma^2 t^2}{2}\right)
$$

---

**MGFæ€§è´¨çš„å®Œæ•´è¯æ˜**:

**æ€§è´¨1ï¼šå”¯ä¸€æ€§å®šç†**

**å®šç†**: è‹¥ä¸¤ä¸ªéšæœºå˜é‡ $X$ å’Œ $Y$ çš„MGFåœ¨0çš„æŸä¸ªé‚»åŸŸå†…å­˜åœ¨ä¸”ç›¸ç­‰ï¼Œåˆ™ $X$ å’Œ $Y$ æœ‰ç›¸åŒçš„åˆ†å¸ƒã€‚

**è¯æ˜æ€è·¯**ï¼ˆå®Œæ•´è¯æ˜éœ€è¦å¤åˆ†æï¼‰:

MGFä¸ç‰¹å¾å‡½æ•°çš„å…³ç³»ï¼š$M_X(t) = \phi_X(-it)$ï¼ˆå½“MGFå­˜åœ¨æ—¶ï¼‰ã€‚

ç‰¹å¾å‡½æ•°å”¯ä¸€ç¡®å®šåˆ†å¸ƒï¼ˆLÃ©vyå”¯ä¸€æ€§å®šç†ï¼‰ã€‚

å› æ­¤ï¼Œè‹¥ $M_X(t) = M_Y(t)$ åœ¨0çš„é‚»åŸŸå†…ï¼Œåˆ™ $\phi_X(s) = \phi_Y(s)$ å¯¹çº¯è™šæ•° $s = -it$ æˆç«‹ã€‚

ç”±è§£æå»¶æ‹“ï¼Œè¿™æ„å‘³ç€ $\phi_X = \phi_Y$ å¤„å¤„æˆç«‹ã€‚

å› æ­¤ $X$ å’Œ $Y$ æœ‰ç›¸åŒçš„åˆ†å¸ƒã€‚ $\square$

**æ³¨æ„**: è¿™ä¸ªå®šç†çš„å®Œæ•´è¯æ˜éœ€è¦å¤åˆ†æå’Œæµ‹åº¦è®ºçš„æ·±å…¥çŸ¥è¯†ã€‚åœ¨å®è·µä¸­ï¼Œæˆ‘ä»¬é€šå¸¸ç›´æ¥å¼•ç”¨è¿™ä¸ªç»“æœã€‚

---

**æ€§è´¨2ï¼šçŸ©çš„è®¡ç®—**

**å®šç†**: è‹¥ $M_X(t)$ åœ¨0çš„é‚»åŸŸå†…å­˜åœ¨ï¼Œåˆ™ï¼š

$$
E[X^n] = M_X^{(n)}(0) = \frac{d^n M_X}{dt^n}\bigg|_{t=0}
$$

**è¯æ˜**:

**ç¬¬ä¸€æ­¥ï¼šTaylorå±•å¼€**

å‡è®¾å¯ä»¥äº¤æ¢æœŸæœ›å’Œæ±‚å¯¼ï¼ˆåœ¨MGFå­˜åœ¨çš„æ¡ä»¶ä¸‹é€šå¸¸æˆç«‹ï¼‰ï¼š

$$
M_X(t) = E[e^{tX}] = E\left[\sum_{n=0}^\infty \frac{(tX)^n}{n!}\right]
$$

äº¤æ¢æœŸæœ›å’Œæ±‚å’Œï¼ˆç”±å•è°ƒæ”¶æ•›å®šç†æˆ–æ§åˆ¶æ”¶æ•›å®šç†ï¼‰ï¼š

$$
M_X(t) = \sum_{n=0}^\infty \frac{E[X^n]}{n!} t^n
$$

è¿™æ˜¯ $M_X(t)$ åœ¨ $t=0$ å¤„çš„Taylorå±•å¼€ã€‚

**ç¬¬äºŒæ­¥ï¼šæ±‚å¯¼**

å¯¹ $M_X(t)$ æ±‚ $n$ é˜¶å¯¼æ•°ï¼š

$$
M_X^{(n)}(t) = \frac{d^n}{dt^n} E[e^{tX}]
$$

äº¤æ¢æœŸæœ›å’Œæ±‚å¯¼ï¼ˆåœ¨é€‚å½“æ¡ä»¶ä¸‹ï¼‰ï¼š

$$
M_X^{(n)}(t) = E\left[\frac{d^n}{dt^n} e^{tX}\right] = E[X^n e^{tX}]
$$

**ç¬¬ä¸‰æ­¥ï¼šåœ¨ $t=0$ å¤„æ±‚å€¼**

$$
M_X^{(n)}(0) = E[X^n e^{0 \cdot X}] = E[X^n]
$$

$\square$

**è¯¦ç»†ç¤ºä¾‹**:

å¯¹äº $X \sim \mathcal{N}(0, 1)$ï¼Œ$M_X(t) = e^{t^2/2}$ã€‚

**ä¸€é˜¶çŸ©**:

$$
M_X'(t) = e^{t^2/2} \cdot t
$$

$$
E[X] = M_X'(0) = 0
$$

**äºŒé˜¶çŸ©**:

$$
M_X''(t) = e^{t^2/2} \cdot (1 + t^2)
$$

$$
E[X^2] = M_X''(0) = 1
$$

**ä¸‰é˜¶çŸ©**:

$$
M_X'''(t) = e^{t^2/2} \cdot (3t + t^3)
$$

$$
E[X^3] = M_X'''(0) = 0
$$

**å››é˜¶çŸ©**:

$$
M_X^{(4)}(t) = e^{t^2/2} \cdot (3 + 6t^2 + t^4)
$$

$$
E[X^4] = M_X^{(4)}(0) = 3
$$

è¿™éªŒè¯äº†æ ‡å‡†æ­£æ€åˆ†å¸ƒçš„çŸ©ï¼š$E[X] = 0$, $E[X^2] = 1$, $E[X^3] = 0$, $E[X^4] = 3$ã€‚

---

**æ€§è´¨3ï¼šç‹¬ç«‹å’Œçš„MGF**

**å®šç†**: è‹¥ $X$ å’Œ $Y$ ç‹¬ç«‹ï¼Œåˆ™ï¼š

$$
M_{X+Y}(t) = M_X(t) \cdot M_Y(t)
$$

**è¯æ˜**:

$$
M_{X+Y}(t) = E[e^{t(X+Y)}] = E[e^{tX} \cdot e^{tY}]
$$

ç”±äº $X$ å’Œ $Y$ ç‹¬ç«‹ï¼Œ$e^{tX}$ å’Œ $e^{tY}$ ä¹Ÿç‹¬ç«‹ï¼ˆç‹¬ç«‹éšæœºå˜é‡çš„å‡½æ•°ä»ç‹¬ç«‹ï¼‰ã€‚

å› æ­¤ï¼Œç”±æœŸæœ›çš„ç‹¬ç«‹æ€§æ€§è´¨ï¼š

$$
M_{X+Y}(t) = E[e^{tX}] \cdot E[e^{tY}] = M_X(t) \cdot M_Y(t)
$$

$\square$

**åº”ç”¨ç¤ºä¾‹**:

**ä¾‹1**: æ­£æ€åˆ†å¸ƒçš„å¯åŠ æ€§

è‹¥ $X \sim \mathcal{N}(\mu_1, \sigma_1^2)$ï¼Œ$Y \sim \mathcal{N}(\mu_2, \sigma_2^2)$ ç‹¬ç«‹ï¼Œåˆ™ï¼š

$$
M_X(t) = \exp\left(\mu_1 t + \frac{\sigma_1^2 t^2}{2}\right)
$$

$$
M_Y(t) = \exp\left(\mu_2 t + \frac{\sigma_2^2 t^2}{2}\right)
$$

$$
M_{X+Y}(t) = M_X(t) \cdot M_Y(t) = \exp\left((\mu_1 + \mu_2) t + \frac{(\sigma_1^2 + \sigma_2^2) t^2}{2}\right)
$$

è¿™æ˜¯ $\mathcal{N}(\mu_1 + \mu_2, \sigma_1^2 + \sigma_2^2)$ çš„MGFã€‚

å› æ­¤ $X + Y \sim \mathcal{N}(\mu_1 + \mu_2, \sigma_1^2 + \sigma_2^2)$ã€‚

**ä¾‹2**: æ³Šæ¾åˆ†å¸ƒçš„å¯åŠ æ€§

è‹¥ $X \sim \text{Poisson}(\lambda_1)$ï¼Œ$Y \sim \text{Poisson}(\lambda_2)$ ç‹¬ç«‹ï¼Œåˆ™ï¼š

$$
M_X(t) = \exp(\lambda_1(e^t - 1))
$$

$$
M_Y(t) = \exp(\lambda_2(e^t - 1))
$$

$$
M_{X+Y}(t) = \exp((\lambda_1 + \lambda_2)(e^t - 1))
$$

å› æ­¤ $X + Y \sim \text{Poisson}(\lambda_1 + \lambda_2)$ã€‚

---

**MGFçš„å­˜åœ¨æ€§**:

**æ³¨æ„**: MGFä¸æ€»æ˜¯å­˜åœ¨ã€‚

**ä¾‹å­**: Cauchyåˆ†å¸ƒ

Cauchyåˆ†å¸ƒçš„MGFä¸å­˜åœ¨ï¼ˆç§¯åˆ†å‘æ•£ï¼‰ï¼Œä½†ç‰¹å¾å‡½æ•°å­˜åœ¨ï¼š

$$
\phi_X(t) = e^{-|t|}
$$

è¿™å°±æ˜¯ä¸ºä»€ä¹ˆåœ¨ç†è®ºå·¥ä½œä¸­ï¼Œç‰¹å¾å‡½æ•°æ¯”MGFæ›´å¸¸ç”¨ã€‚

---

**MGFä¸ä¸­å¿ƒæé™å®šç†**:

MGFåœ¨è¯æ˜ä¸­å¿ƒæé™å®šç†æ—¶èµ·å…³é”®ä½œç”¨ï¼ˆè™½ç„¶é€šå¸¸ä½¿ç”¨ç‰¹å¾å‡½æ•°ï¼‰ã€‚

**æ€è·¯**: 
1. è®¡ç®—æ ‡å‡†åŒ–å’Œçš„MGF
2. è¯æ˜å®ƒæ”¶æ•›åˆ°æ ‡å‡†æ­£æ€åˆ†å¸ƒçš„MGF
3. ç”±å”¯ä¸€æ€§å®šç†ï¼Œå¾—åˆ°åˆ†å¸ƒæ”¶æ•›

---

### 3. ç‰¹å¾å‡½æ•°

**å®šä¹‰ 3.1 (ç‰¹å¾å‡½æ•°)**:

$$
\phi_X(t) = E[e^{itX}] = \int_{-\infty}^\infty e^{itx} f_X(x) \, dx
$$

**ä¼˜åŠ¿**: æ€»æ˜¯å­˜åœ¨ï¼ˆMGFå¯èƒ½ä¸å­˜åœ¨ï¼‰

**æ€§è´¨**: ä¸MGFç±»ä¼¼ï¼Œä½†ä½¿ç”¨å¤æ•°

---

## ğŸ”§ åœ¨æœºå™¨å­¦ä¹ ä¸­çš„åº”ç”¨

### 1. è´å¶æ–¯æ¨æ–­

**è´å¶æ–¯å…¬å¼**:

$$
p(\theta | \mathcal{D}) = \frac{p(\mathcal{D} | \theta) p(\theta)}{p(\mathcal{D})}
$$

å…¶ä¸­ï¼š

- $p(\theta)$: å…ˆéªŒåˆ†å¸ƒ
- $p(\mathcal{D} | \theta)$: ä¼¼ç„¶å‡½æ•°
- $p(\theta | \mathcal{D})$: åéªŒåˆ†å¸ƒ

**åº”ç”¨**:

- è´å¶æ–¯çº¿æ€§å›å½’
- é«˜æ–¯è¿‡ç¨‹
- è´å¶æ–¯ç¥ç»ç½‘ç»œ

---

### 2. æœ€å¤§ä¼¼ç„¶ä¼°è®¡

**å®šä¹‰**:

$$
\hat{\theta}_{\text{MLE}} = \arg\max_\theta p(\mathcal{D} | \theta)
$$

**å¯¹æ•°ä¼¼ç„¶**:

$$
\ell(\theta) = \log p(\mathcal{D} | \theta) = \sum_{i=1}^n \log p(x_i | \theta)
$$

**ç¤ºä¾‹** (æ­£æ€åˆ†å¸ƒ):

ç»™å®šæ•°æ® $\{x_1, \ldots, x_n\}$ï¼Œå‡è®¾ $x_i \sim \mathcal{N}(\mu, \sigma^2)$ï¼š

$$
\hat{\mu}_{\text{MLE}} = \frac{1}{n} \sum_{i=1}^n x_i
$$

$$
\hat{\sigma}^2_{\text{MLE}} = \frac{1}{n} \sum_{i=1}^n (x_i - \hat{\mu})^2
$$

---

### 3. å˜åˆ†æ¨æ–­

**é—®é¢˜**: è®¡ç®—åéªŒåˆ†å¸ƒ $p(\theta | \mathcal{D})$ é€šå¸¸æ˜¯å›°éš¾çš„ã€‚

**å˜åˆ†æ¨æ–­**: ç”¨ç®€å•åˆ†å¸ƒ $q(\theta)$ è¿‘ä¼¼ $p(\theta | \mathcal{D})$ã€‚

**KLæ•£åº¦**:

$$
\text{KL}(q \| p) = \int q(\theta) \log \frac{q(\theta)}{p(\theta | \mathcal{D})} \, d\theta
$$

**ELBO** (Evidence Lower Bound):

$$
\mathcal{L}(q) = E_q[\log p(\mathcal{D}, \theta)] - E_q[\log q(\theta)]
$$

æœ€å¤§åŒ–ELBOç­‰ä»·äºæœ€å°åŒ–KLæ•£åº¦ã€‚

---

### 4. é‡‡æ ·æ–¹æ³•

**è’™ç‰¹å¡æ´›æ–¹æ³•**:

$$
E[f(X)] \approx \frac{1}{N} \sum_{i=1}^N f(x_i), \quad x_i \sim p(x)
$$

**é©¬å°”å¯å¤«é“¾è’™ç‰¹å¡æ´› (MCMC)**:

- Metropolis-Hastingsç®—æ³•
- Gibbsé‡‡æ ·
- Hamiltonian Monte Carlo (HMC)

**åº”ç”¨**: è´å¶æ–¯æ¨æ–­ã€ç”Ÿæˆæ¨¡å‹

---

## ğŸ’» Pythonå®ç°

```python
import numpy as np
import matplotlib.pyplot as plt
from scipy import stats
from scipy.special import comb

# 1. å¸¸è§åˆ†å¸ƒå¯è§†åŒ–
def plot_distributions():
    """å¯è§†åŒ–å¸¸è§æ¦‚ç‡åˆ†å¸ƒ"""
    fig, axes = plt.subplots(2, 3, figsize=(15, 10))
    
    # ä¼¯åŠªåˆ©åˆ†å¸ƒ
    ax = axes[0, 0]
    p = 0.7
    x = [0, 1]
    pmf = [1-p, p]
    ax.bar(x, pmf, width=0.3)
    ax.set_title(f'Bernoulli(p={p})')
    ax.set_xlabel('x')
    ax.set_ylabel('P(X=x)')
    
    # äºŒé¡¹åˆ†å¸ƒ
    ax = axes[0, 1]
    n, p = 10, 0.5
    x = np.arange(0, n+1)
    pmf = stats.binom.pmf(x, n, p)
    ax.bar(x, pmf)
    ax.set_title(f'Binomial(n={n}, p={p})')
    ax.set_xlabel('x')
    ax.set_ylabel('P(X=x)')
    
    # æ³Šæ¾åˆ†å¸ƒ
    ax = axes[0, 2]
    lambda_ = 3
    x = np.arange(0, 15)
    pmf = stats.poisson.pmf(x, lambda_)
    ax.bar(x, pmf)
    ax.set_title(f'Poisson(Î»={lambda_})')
    ax.set_xlabel('x')
    ax.set_ylabel('P(X=x)')
    
    # å‡åŒ€åˆ†å¸ƒ
    ax = axes[1, 0]
    a, b = 0, 1
    x = np.linspace(-0.5, 1.5, 1000)
    pdf = stats.uniform.pdf(x, a, b-a)
    ax.plot(x, pdf)
    ax.fill_between(x, pdf, alpha=0.3)
    ax.set_title(f'Uniform(a={a}, b={b})')
    ax.set_xlabel('x')
    ax.set_ylabel('f(x)')
    
    # æ­£æ€åˆ†å¸ƒ
    ax = axes[1, 1]
    mu, sigma = 0, 1
    x = np.linspace(-4, 4, 1000)
    pdf = stats.norm.pdf(x, mu, sigma)
    ax.plot(x, pdf)
    ax.fill_between(x, pdf, alpha=0.3)
    ax.set_title(f'Normal(Î¼={mu}, ÏƒÂ²={sigma**2})')
    ax.set_xlabel('x')
    ax.set_ylabel('f(x)')
    
    # æŒ‡æ•°åˆ†å¸ƒ
    ax = axes[1, 2]
    lambda_ = 1
    x = np.linspace(0, 5, 1000)
    pdf = stats.expon.pdf(x, scale=1/lambda_)
    ax.plot(x, pdf)
    ax.fill_between(x, pdf, alpha=0.3)
    ax.set_title(f'Exponential(Î»={lambda_})')
    ax.set_xlabel('x')
    ax.set_ylabel('f(x)')
    
    plt.tight_layout()
    # plt.show()


# 2. ä¸­å¿ƒæé™å®šç†æ¼”ç¤º
def central_limit_theorem_demo():
    """æ¼”ç¤ºä¸­å¿ƒæé™å®šç†"""
    np.random.seed(42)
    
    # åŸå§‹åˆ†å¸ƒ (å‡åŒ€åˆ†å¸ƒ)
    n_samples = 1000
    sample_sizes = [1, 5, 30, 100]
    
    fig, axes = plt.subplots(2, 2, figsize=(12, 10))
    axes = axes.flatten()
    
    for idx, n in enumerate(sample_sizes):
        # ç”Ÿæˆæ ·æœ¬å‡å€¼
        sample_means = []
        for _ in range(n_samples):
            sample = np.random.uniform(0, 1, n)
            sample_means.append(np.mean(sample))
        
        # ç»˜åˆ¶ç›´æ–¹å›¾
        ax = axes[idx]
        ax.hist(sample_means, bins=30, density=True, alpha=0.7, edgecolor='black')
        
        # ç†è®ºæ­£æ€åˆ†å¸ƒ
        mu = 0.5  # å‡åŒ€åˆ†å¸ƒçš„æœŸæœ›
        sigma = 1/np.sqrt(12*n)  # æ ·æœ¬å‡å€¼çš„æ ‡å‡†å·®
        x = np.linspace(0, 1, 100)
        pdf = stats.norm.pdf(x, mu, sigma)
        ax.plot(x, pdf, 'r-', linewidth=2, label='Theoretical Normal')
        
        ax.set_title(f'Sample Size n={n}')
        ax.set_xlabel('Sample Mean')
        ax.set_ylabel('Density')
        ax.legend()
    
    plt.suptitle('Central Limit Theorem: Sample Means of Uniform(0,1)', fontsize=14)
    plt.tight_layout()
    # plt.show()


# 3. æœ€å¤§ä¼¼ç„¶ä¼°è®¡
def maximum_likelihood_estimation():
    """æœ€å¤§ä¼¼ç„¶ä¼°è®¡ç¤ºä¾‹"""
    np.random.seed(42)
    
    # ç”Ÿæˆæ•°æ®
    true_mu = 2.0
    true_sigma = 1.5
    n = 100
    data = np.random.normal(true_mu, true_sigma, n)
    
    # MLEä¼°è®¡
    mu_mle = np.mean(data)
    sigma_mle = np.std(data, ddof=0)  # ä½¿ç”¨nè€Œä¸æ˜¯n-1
    
    print("=== æœ€å¤§ä¼¼ç„¶ä¼°è®¡ ===")
    print(f"çœŸå®å‚æ•°: Î¼={true_mu}, Ïƒ={true_sigma}")
    print(f"MLEä¼°è®¡: Î¼Ì‚={mu_mle:.4f}, ÏƒÌ‚={sigma_mle:.4f}")
    
    # å¯è§†åŒ–
    plt.figure(figsize=(10, 6))
    
    # æ•°æ®ç›´æ–¹å›¾
    plt.hist(data, bins=20, density=True, alpha=0.7, edgecolor='black', label='Data')
    
    # çœŸå®åˆ†å¸ƒ
    x = np.linspace(data.min(), data.max(), 100)
    pdf_true = stats.norm.pdf(x, true_mu, true_sigma)
    plt.plot(x, pdf_true, 'r-', linewidth=2, label=f'True: N({true_mu}, {true_sigma**2})')
    
    # MLEæ‹Ÿåˆçš„åˆ†å¸ƒ
    pdf_mle = stats.norm.pdf(x, mu_mle, sigma_mle)
    plt.plot(x, pdf_mle, 'b--', linewidth=2, label=f'MLE: N({mu_mle:.2f}, {sigma_mle**2:.2f})')
    
    plt.xlabel('x')
    plt.ylabel('Density')
    plt.title('Maximum Likelihood Estimation')
    plt.legend()
    plt.grid(True, alpha=0.3)
    # plt.show()


# 4. è´å¶æ–¯æ¨æ–­ç¤ºä¾‹
def bayesian_inference_demo():
    """è´å¶æ–¯æ¨æ–­ç¤ºä¾‹ (ç¡¬å¸æŠ•æ·)"""
    # å…ˆéªŒ: Beta(Î±, Î²)
    alpha_prior = 2
    beta_prior = 2
    
    # æ•°æ®: 10æ¬¡æŠ•æ·ï¼Œ7æ¬¡æ­£é¢
    n_heads = 7
    n_tails = 3
    
    # åéªŒ: Beta(Î± + n_heads, Î² + n_tails)
    alpha_post = alpha_prior + n_heads
    beta_post = beta_prior + n_tails
    
    # å¯è§†åŒ–
    p = np.linspace(0, 1, 100)
    
    prior = stats.beta.pdf(p, alpha_prior, beta_prior)
    likelihood = stats.binom.pmf(n_heads, n_heads + n_tails, p)
    posterior = stats.beta.pdf(p, alpha_post, beta_post)
    
    plt.figure(figsize=(10, 6))
    plt.plot(p, prior, 'b-', label=f'Prior: Beta({alpha_prior}, {beta_prior})', linewidth=2)
    plt.plot(p, likelihood / likelihood.max() * prior.max(), 'g--', 
             label=f'Likelihood (scaled)', linewidth=2)
    plt.plot(p, posterior, 'r-', label=f'Posterior: Beta({alpha_post}, {beta_post})', linewidth=2)
    
    plt.xlabel('p (probability of heads)')
    plt.ylabel('Density')
    plt.title('Bayesian Inference: Coin Flip')
    plt.legend()
    plt.grid(True, alpha=0.3)
    # plt.show()
    
    print("\n=== è´å¶æ–¯æ¨æ–­ ===")
    print(f"å…ˆéªŒå‡å€¼: {alpha_prior/(alpha_prior+beta_prior):.4f}")
    print(f"åéªŒå‡å€¼: {alpha_post/(alpha_post+beta_post):.4f}")
    print(f"MLEä¼°è®¡: {n_heads/(n_heads+n_tails):.4f}")


# 5. è’™ç‰¹å¡æ´›ç§¯åˆ†
def monte_carlo_integration():
    """è’™ç‰¹å¡æ´›ç§¯åˆ†ç¤ºä¾‹"""
    np.random.seed(42)
    
    # è®¡ç®— E[X^2] where X ~ N(0, 1)
    # ç†è®ºå€¼: 1
    
    sample_sizes = [10, 100, 1000, 10000]
    estimates = []
    
    for n in sample_sizes:
        samples = np.random.normal(0, 1, n)
        estimate = np.mean(samples**2)
        estimates.append(estimate)
        print(f"n={n:5d}: E[XÂ²] â‰ˆ {estimate:.6f}")
    
    print(f"\nç†è®ºå€¼: E[XÂ²] = 1.000000")
    
    # å¯è§†åŒ–æ”¶æ•›
    plt.figure(figsize=(10, 6))
    plt.semilogx(sample_sizes, estimates, 'bo-', markersize=8, label='MC Estimate')
    plt.axhline(y=1, color='r', linestyle='--', linewidth=2, label='True Value')
    plt.xlabel('Sample Size')
    plt.ylabel('Estimate of E[XÂ²]')
    plt.title('Monte Carlo Integration Convergence')
    plt.legend()
    plt.grid(True, alpha=0.3)
    # plt.show()


if __name__ == "__main__":
    print("=== éšæœºå˜é‡ä¸åˆ†å¸ƒç¤ºä¾‹ ===\n")
    
    print("1. å¸¸è§åˆ†å¸ƒå¯è§†åŒ–")
    plot_distributions()
    
    print("\n2. ä¸­å¿ƒæé™å®šç†")
    central_limit_theorem_demo()
    
    print("\n3. æœ€å¤§ä¼¼ç„¶ä¼°è®¡")
    maximum_likelihood_estimation()
    
    print("\n4. è´å¶æ–¯æ¨æ–­")
    bayesian_inference_demo()
    
    print("\n5. è’™ç‰¹å¡æ´›ç§¯åˆ†")
    monte_carlo_integration()
```

---

## ğŸ“š ç»ƒä¹ é¢˜

### ç»ƒä¹ 1ï¼šåˆ†å¸ƒè®¡ç®—

è®¾ $X \sim \mathcal{N}(0, 1)$ï¼Œè®¡ç®—ï¼š

1. $P(X \leq 1)$
2. $P(-1 \leq X \leq 1)$
3. $P(X^2 \leq 1)$

### ç»ƒä¹ 2ï¼šæœŸæœ›ä¸æ–¹å·®

è®¾ $X \sim \text{Uniform}(0, 1)$ï¼Œè®¡ç®—ï¼š

1. $E[X^2]$
2. $\text{Var}(X)$
3. $E[e^X]$

### ç»ƒä¹ 3ï¼šå˜æ¢

è®¾ $X \sim \text{Exp}(\lambda)$ï¼Œ$Y = \sqrt{X}$ï¼Œæ±‚ $Y$ çš„å¯†åº¦å‡½æ•°ã€‚

### ç»ƒä¹ 4ï¼šæœ€å¤§ä¼¼ç„¶ä¼°è®¡

ç»™å®šæ•°æ® $\{x_1, \ldots, x_n\}$ æ¥è‡ª $\text{Exp}(\lambda)$ï¼Œæ±‚ $\lambda$ çš„MLEä¼°è®¡ã€‚

---

## ğŸ“ ç›¸å…³è¯¾ç¨‹

| å¤§å­¦ | è¯¾ç¨‹ |
|------|------|
| **MIT** | 6.041 - Probabilistic Systems Analysis |
| **MIT** | 18.650 - Statistics for Applications |
| **Stanford** | CS109 - Probability for Computer Scientists |
| **Stanford** | STATS214 - Machine Learning Theory |
| **UC Berkeley** | STAT134 - Concepts of Probability |
| **CMU** | 36-705 - Intermediate Statistics |

---

## ğŸ“– å‚è€ƒæ–‡çŒ®

1. **Casella & Berger (2002)**. *Statistical Inference*. Duxbury Press.

2. **Wasserman, L. (2004)**. *All of Statistics*. Springer.

3. **Bishop, C. (2006)**. *Pattern Recognition and Machine Learning*. Springer.

4. **Murphy, K. (2012)**. *Machine Learning: A Probabilistic Perspective*. MIT Press.

5. **Goodfellow et al. (2016)**. *Deep Learning*. MIT Press. (Chapter 3: Probability)

---

*æœ€åæ›´æ–°ï¼š2025å¹´10æœˆ*-
