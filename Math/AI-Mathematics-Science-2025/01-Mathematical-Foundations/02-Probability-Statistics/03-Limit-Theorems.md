# æé™å®šç† (Limit Theorems)

> **The Foundation of Statistical Inference**
>
> ç»Ÿè®¡æ¨æ–­çš„ç†è®ºåŸºç¡€

---

## ç›®å½•

- [æé™å®šç† (Limit Theorems)](#æé™å®šç†-limit-theorems)
  - [ç›®å½•](#ç›®å½•)
  - [ğŸ“‹ æ ¸å¿ƒæ€æƒ³](#-æ ¸å¿ƒæ€æƒ³)
  - [ğŸ¯ æ”¶æ•›æ€§æ¦‚å¿µ](#-æ”¶æ•›æ€§æ¦‚å¿µ)
    - [1. ä¾æ¦‚ç‡æ”¶æ•›](#1-ä¾æ¦‚ç‡æ”¶æ•›)
    - [2. å‡ ä¹å¿…ç„¶æ”¶æ•›](#2-å‡ ä¹å¿…ç„¶æ”¶æ•›)
    - [3. ä¾åˆ†å¸ƒæ”¶æ•›](#3-ä¾åˆ†å¸ƒæ”¶æ•›)
    - [4. æ”¶æ•›æ€§ä¹‹é—´çš„å…³ç³»](#4-æ”¶æ•›æ€§ä¹‹é—´çš„å…³ç³»)
  - [ğŸ“Š å¤§æ•°å®šå¾‹ (Law of Large Numbers)](#-å¤§æ•°å®šå¾‹-law-of-large-numbers)
    - [1. å¼±å¤§æ•°å®šå¾‹ (WLLN)](#1-å¼±å¤§æ•°å®šå¾‹-wlln)
    - [2. å¼ºå¤§æ•°å®šå¾‹ (SLLN)](#2-å¼ºå¤§æ•°å®šå¾‹-slln)
    - [3. åº”ç”¨](#3-åº”ç”¨)
  - [ğŸ”¬ ä¸­å¿ƒæé™å®šç† (Central Limit Theorem)](#-ä¸­å¿ƒæé™å®šç†-central-limit-theorem)
    - [1. ç»å…¸ä¸­å¿ƒæé™å®šç†](#1-ç»å…¸ä¸­å¿ƒæé™å®šç†)
    - [2. Lindeberg-LÃ©vyå®šç†](#2-lindeberg-lÃ©vyå®šç†)
    - [3. Lyapunovå®šç†](#3-lyapunovå®šç†)
    - [4. Berry-Esseenå®šç†](#4-berry-esseenå®šç†)
  - [ğŸ’¡ å¤šå…ƒä¸­å¿ƒæé™å®šç†](#-å¤šå…ƒä¸­å¿ƒæé™å®šç†)
    - [1. å¤šå…ƒCLT](#1-å¤šå…ƒclt)
    - [2. Deltaæ–¹æ³•](#2-deltaæ–¹æ³•)
  - [ğŸ¨ åœ¨æœºå™¨å­¦ä¹ ä¸­çš„åº”ç”¨](#-åœ¨æœºå™¨å­¦ä¹ ä¸­çš„åº”ç”¨)
    - [1. ç»éªŒé£é™©æœ€å°åŒ–](#1-ç»éªŒé£é™©æœ€å°åŒ–)
    - [2. å‚æ•°ä¼°è®¡](#2-å‚æ•°ä¼°è®¡)
    - [3. ç½®ä¿¡åŒºé—´](#3-ç½®ä¿¡åŒºé—´)
    - [4. å‡è®¾æ£€éªŒ](#4-å‡è®¾æ£€éªŒ)
    - [5. Bootstrapæ–¹æ³•](#5-bootstrapæ–¹æ³•)
  - [ğŸ”§ é«˜çº§ä¸»é¢˜](#-é«˜çº§ä¸»é¢˜)
    - [1. å¤§åå·®ç†è®º](#1-å¤§åå·®ç†è®º)
    - [2. å‡½æ•°å‹ä¸­å¿ƒæé™å®šç†](#2-å‡½æ•°å‹ä¸­å¿ƒæé™å®šç†)
    - [3. ä¾èµ–æ•°æ®çš„æé™å®šç†](#3-ä¾èµ–æ•°æ®çš„æé™å®šç†)
  - [ğŸ’» Pythonå®ç°](#-pythonå®ç°)
  - [ğŸ“š ç»ƒä¹ é¢˜](#-ç»ƒä¹ é¢˜)
    - [ç»ƒä¹ 1ï¼šå¤§æ•°å®šå¾‹éªŒè¯](#ç»ƒä¹ 1å¤§æ•°å®šå¾‹éªŒè¯)
    - [ç»ƒä¹ 2ï¼šä¸­å¿ƒæé™å®šç†](#ç»ƒä¹ 2ä¸­å¿ƒæé™å®šç†)
    - [ç»ƒä¹ 3ï¼šç½®ä¿¡åŒºé—´](#ç»ƒä¹ 3ç½®ä¿¡åŒºé—´)
    - [ç»ƒä¹ 4ï¼šBootstrap](#ç»ƒä¹ 4bootstrap)
  - [ğŸ“ ç›¸å…³è¯¾ç¨‹](#-ç›¸å…³è¯¾ç¨‹)
  - [ğŸ“– å‚è€ƒæ–‡çŒ®](#-å‚è€ƒæ–‡çŒ®)

---

## ğŸ“‹ æ ¸å¿ƒæ€æƒ³

**æé™å®šç†**æè¿°äº†å¤§é‡éšæœºå˜é‡çš„å’Œæˆ–å¹³å‡çš„æ¸è¿‘è¡Œä¸ºï¼Œæ˜¯ç»Ÿè®¡æ¨æ–­å’Œæœºå™¨å­¦ä¹ çš„ç†è®ºåŸºç¡€ã€‚

**ä¸ºä»€ä¹ˆæé™å®šç†é‡è¦**:

```text
ç»Ÿè®¡æ¨æ–­çš„åŸºç¡€:
â”œâ”€ å¤§æ•°å®šå¾‹: æ ·æœ¬å‡å€¼æ”¶æ•›åˆ°æ€»ä½“å‡å€¼
â”œâ”€ ä¸­å¿ƒæé™å®šç†: æ ·æœ¬å‡å€¼çš„åˆ†å¸ƒè¶‹äºæ­£æ€
â”œâ”€ ç½®ä¿¡åŒºé—´: å‚æ•°ä¼°è®¡çš„ä¸ç¡®å®šæ€§
â””â”€ å‡è®¾æ£€éªŒ: ç»Ÿè®¡æ˜¾è‘—æ€§

æœºå™¨å­¦ä¹ ä¸­çš„åº”ç”¨:
â”œâ”€ ç»éªŒé£é™©æœ€å°åŒ–
â”œâ”€ æ³›åŒ–è¯¯å·®ä¼°è®¡
â”œâ”€ æ¨¡å‹é€‰æ‹©
â””â”€ ä¸ç¡®å®šæ€§é‡åŒ–
```

---

## ğŸ¯ æ”¶æ•›æ€§æ¦‚å¿µ

### 1. ä¾æ¦‚ç‡æ”¶æ•›

**å®šä¹‰ 1.1 (ä¾æ¦‚ç‡æ”¶æ•›)**:

éšæœºå˜é‡åºåˆ— $\{X_n\}$ **ä¾æ¦‚ç‡æ”¶æ•›**åˆ° $X$ï¼Œè®°ä½œ $X_n \xrightarrow{P} X$ï¼Œå¦‚æœï¼š

$$
\forall \epsilon > 0, \quad \lim_{n \to \infty} P(|X_n - X| > \epsilon) = 0
$$

**ç­‰ä»·è¡¨è¿°**:

$$
\lim_{n \to \infty} P(|X_n - X| \leq \epsilon) = 1
$$

**ç›´è§‰**ï¼š$X_n$ ä»¥å¾ˆå¤§çš„æ¦‚ç‡æ¥è¿‘ $X$ã€‚

---

### 2. å‡ ä¹å¿…ç„¶æ”¶æ•›

**å®šä¹‰ 2.1 (å‡ ä¹å¿…ç„¶æ”¶æ•›)**:

éšæœºå˜é‡åºåˆ— $\{X_n\}$ **å‡ ä¹å¿…ç„¶æ”¶æ•›**ï¼ˆæˆ–**ä»¥æ¦‚ç‡1æ”¶æ•›**ï¼‰åˆ° $X$ï¼Œè®°ä½œ $X_n \xrightarrow{a.s.} X$ï¼Œå¦‚æœï¼š

$$
P\left(\lim_{n \to \infty} X_n = X\right) = 1
$$

**ç­‰ä»·è¡¨è¿°**:

$$
P\left(\{\omega : \lim_{n \to \infty} X_n(\omega) = X(\omega)\}\right) = 1
$$

**ç›´è§‰**ï¼šé™¤äº†é›¶æ¦‚ç‡äº‹ä»¶å¤–ï¼Œ$X_n$ çš„æ¯ä¸ªæ ·æœ¬è·¯å¾„éƒ½æ”¶æ•›åˆ° $X$ã€‚

---

### 3. ä¾åˆ†å¸ƒæ”¶æ•›

**å®šä¹‰ 3.1 (ä¾åˆ†å¸ƒæ”¶æ•›)**:

éšæœºå˜é‡åºåˆ— $\{X_n\}$ **ä¾åˆ†å¸ƒæ”¶æ•›**åˆ° $X$ï¼Œè®°ä½œ $X_n \xrightarrow{d} X$ï¼Œå¦‚æœï¼š

$$
\lim_{n \to \infty} F_n(x) = F(x)
$$

å¯¹äº $F$ çš„æ‰€æœ‰è¿ç»­ç‚¹ $x$ï¼Œå…¶ä¸­ $F_n$ å’Œ $F$ åˆ†åˆ«æ˜¯ $X_n$ å’Œ $X$ çš„ç´¯ç§¯åˆ†å¸ƒå‡½æ•°ã€‚

**è®°å·**ï¼šä¹Ÿè®°ä½œ $X_n \Rightarrow X$ã€‚

---

### 4. æ”¶æ•›æ€§ä¹‹é—´çš„å…³ç³»

**å®šç† 4.1 (æ”¶æ•›æ€§å±‚æ¬¡)**:

$$
X_n \xrightarrow{a.s.} X \quad \Rightarrow \quad X_n \xrightarrow{P} X \quad \Rightarrow \quad X_n \xrightarrow{d} X
$$

**åå‘ä¸æˆç«‹**ï¼š

- ä¾åˆ†å¸ƒæ”¶æ•› $\not\Rightarrow$ ä¾æ¦‚ç‡æ”¶æ•›
- ä¾æ¦‚ç‡æ”¶æ•› $\not\Rightarrow$ å‡ ä¹å¿…ç„¶æ”¶æ•›

**ç‰¹æ®Šæƒ…å†µ**ï¼šå¦‚æœ $X$ æ˜¯å¸¸æ•° $c$ï¼Œåˆ™ï¼š

$$
X_n \xrightarrow{d} c \quad \Leftrightarrow \quad X_n \xrightarrow{P} c
$$

---

## ğŸ“Š å¤§æ•°å®šå¾‹ (Law of Large Numbers)

### 1. å¼±å¤§æ•°å®šå¾‹ (WLLN)

**å®šç† 1.1 (Khinchinå¼±å¤§æ•°å®šå¾‹)**:

è®¾ $X_1, X_2, \ldots$ æ˜¯ç‹¬ç«‹åŒåˆ†å¸ƒçš„éšæœºå˜é‡ï¼Œä¸” $E[X_i] = \mu$ å­˜åœ¨ã€‚ä»¤ï¼š

$$
\bar{X}_n = \frac{1}{n} \sum_{i=1}^n X_i
$$

åˆ™ï¼š

$$
\bar{X}_n \xrightarrow{P} \mu
$$

**å®šç† 1.1 çš„å®Œæ•´è¯æ˜**:

æˆ‘ä»¬å°†ç»™å‡ºä¸¤ä¸ªè¯æ˜ï¼šä¸€ä¸ªåŸºäºChebyshevä¸ç­‰å¼ï¼ˆå‡è®¾æ–¹å·®æœ‰é™ï¼‰ï¼Œä¸€ä¸ªåŸºäºç‰¹å¾å‡½æ•°ï¼ˆæ›´ä¸€èˆ¬ï¼‰ã€‚

---

**è¯æ˜1ï¼šåŸºäºChebyshevä¸ç­‰å¼**:

**å‡è®¾**: $\text{Var}(X_i) = \sigma^2 < \infty$

**ç¬¬ä¸€æ­¥ï¼šè®¡ç®—æ ·æœ¬å‡å€¼çš„æœŸæœ›**:

$$
E[\bar{X}_n] = E\left[\frac{1}{n} \sum_{i=1}^n X_i\right] = \frac{1}{n} \sum_{i=1}^n E[X_i] = \frac{1}{n} \cdot n\mu = \mu
$$

**ç¬¬äºŒæ­¥ï¼šè®¡ç®—æ ·æœ¬å‡å€¼çš„æ–¹å·®**:

ç”±äº $X_1, X_2, \ldots, X_n$ ç‹¬ç«‹ï¼š

$$
\text{Var}(\bar{X}_n) = \text{Var}\left(\frac{1}{n} \sum_{i=1}^n X_i\right) = \frac{1}{n^2} \text{Var}\left(\sum_{i=1}^n X_i\right)
$$

ç”±ç‹¬ç«‹æ€§ï¼Œæ–¹å·®å¯åŠ ï¼š

$$
\text{Var}\left(\sum_{i=1}^n X_i\right) = \sum_{i=1}^n \text{Var}(X_i) = n\sigma^2
$$

å› æ­¤ï¼š

$$
\text{Var}(\bar{X}_n) = \frac{n\sigma^2}{n^2} = \frac{\sigma^2}{n}
$$

**ç¬¬ä¸‰æ­¥ï¼šåº”ç”¨Chebyshevä¸ç­‰å¼**:

å¯¹äºä»»æ„ $\epsilon > 0$ï¼ŒChebyshevä¸ç­‰å¼ç»™å‡ºï¼š

$$
P(|\bar{X}_n - E[\bar{X}_n]| > \epsilon) \leq \frac{\text{Var}(\bar{X}_n)}{\epsilon^2}
$$

ä»£å…¥ $E[\bar{X}_n] = \mu$ å’Œ $\text{Var}(\bar{X}_n) = \sigma^2/n$ï¼š

$$
P(|\bar{X}_n - \mu| > \epsilon) \leq \frac{\sigma^2}{n\epsilon^2}
$$

**ç¬¬å››æ­¥ï¼šå–æé™**:

å½“ $n \to \infty$ï¼š

$$
\lim_{n \to \infty} P(|\bar{X}_n - \mu| > \epsilon) \leq \lim_{n \to \infty} \frac{\sigma^2}{n\epsilon^2} = 0
$$

ç”±äºæ¦‚ç‡éè´Ÿï¼Œå› æ­¤ï¼š

$$
\lim_{n \to \infty} P(|\bar{X}_n - \mu| > \epsilon) = 0
$$

è¿™æ­£æ˜¯ä¾æ¦‚ç‡æ”¶æ•›çš„å®šä¹‰ï¼š

$$
\bar{X}_n \xrightarrow{P} \mu
$$

$\square$

---

**è¯æ˜2ï¼šåŸºäºç‰¹å¾å‡½æ•°ï¼ˆæ›´ä¸€èˆ¬ï¼Œä¸éœ€è¦æ–¹å·®æœ‰é™ï¼‰**:

**å‡è®¾**: ä»…éœ€ $E[X_i] = \mu$ å­˜åœ¨

**ç¬¬ä¸€æ­¥ï¼šæ ‡å‡†åŒ–**:

ä»¤ $Y_i = X_i - \mu$ï¼Œåˆ™ $E[Y_i] = 0$ã€‚

éœ€è¦è¯æ˜ï¼š

$$
\frac{1}{n} \sum_{i=1}^n Y_i \xrightarrow{P} 0
$$

**ç¬¬äºŒæ­¥ï¼šç‰¹å¾å‡½æ•°**:

ä»¤ $S_n = \sum_{i=1}^n Y_i$ï¼Œå…¶ç‰¹å¾å‡½æ•°ä¸ºï¼š

$$
\phi_{S_n/n}(t) = E\left[\exp\left(i\frac{t}{n} S_n\right)\right] = \prod_{j=1}^n E\left[\exp\left(i\frac{t}{n} Y_j\right)\right] = \left[\phi_Y\left(\frac{t}{n}\right)\right]^n
$$

å…¶ä¸­ $\phi_Y(t) = E[e^{itY}]$ æ˜¯ $Y_i$ çš„ç‰¹å¾å‡½æ•°ã€‚

**ç¬¬ä¸‰æ­¥ï¼šTaylorå±•å¼€**:

ç”±äº $E[Y] = 0$ï¼Œåœ¨ $t = 0$ é™„è¿‘ï¼š

$$
\phi_Y(t) = E[e^{itY}] = E[1 + itY + O(t^2)] = 1 + it E[Y] + O(t^2) = 1 + O(t^2)
$$

æ›´ç²¾ç¡®åœ°ï¼Œå¯¹äºå°çš„ $|t|$ï¼š

$$
|\phi_Y(t) - 1| = O(t^2)
$$

**ç¬¬å››æ­¥ï¼šä»£å…¥å¹¶å–æé™**:

$$
\phi_{S_n/n}(t) = \left[\phi_Y\left(\frac{t}{n}\right)\right]^n = \left[1 + O\left(\frac{t^2}{n^2}\right)\right]^n
$$

å½“ $n \to \infty$ï¼š

$$
\lim_{n \to \infty} \left[1 + O\left(\frac{1}{n^2}\right)\right]^n = 1
$$

å› æ­¤ï¼š

$$
\lim_{n \to \infty} \phi_{S_n/n}(t) = 1 = \phi_0(t)
$$

å…¶ä¸­ $\phi_0(t) = 1$ æ˜¯å¸¸æ•°0çš„ç‰¹å¾å‡½æ•°ã€‚

**ç¬¬äº”æ­¥ï¼šç»“è®º**:

ç”±LÃ©vyè¿ç»­æ€§å®šç†ï¼Œç‰¹å¾å‡½æ•°çš„é€ç‚¹æ”¶æ•›è•´å«ä¾åˆ†å¸ƒæ”¶æ•›ï¼š

$$
\frac{S_n}{n} = \frac{1}{n} \sum_{i=1}^n Y_i \xrightarrow{d} 0
$$

å¯¹äºå¸¸æ•°ï¼Œä¾åˆ†å¸ƒæ”¶æ•›ç­‰ä»·äºä¾æ¦‚ç‡æ”¶æ•›ï¼Œå› æ­¤ï¼š

$$
\frac{1}{n} \sum_{i=1}^n Y_i \xrightarrow{P} 0
$$

å³ï¼š

$$
\bar{X}_n = \frac{1}{n} \sum_{i=1}^n X_i \xrightarrow{P} \mu
$$

$\square$

---

**ä¸¤ä¸ªè¯æ˜çš„æ¯”è¾ƒ**:

| æ–¹æ³• | å‡è®¾ | ä¼˜ç‚¹ | ç¼ºç‚¹ |
|------|------|------|------|
| Chebyshevä¸ç­‰å¼ | éœ€è¦ $\sigma^2 < \infty$ | ç®€å•ç›´æ¥ï¼Œæ˜“äºç†è§£ | éœ€è¦æ–¹å·®æœ‰é™ |
| ç‰¹å¾å‡½æ•° | ä»…éœ€ $E[X] < \infty$ | æ›´ä¸€èˆ¬ï¼Œä¸éœ€è¦æ–¹å·® | éœ€è¦æ›´å¤šæ¦‚ç‡è®ºçŸ¥è¯† |

**æ³¨æ„**:

- Khinchinçš„åŸå§‹å®šç†ä»…å‡è®¾æœŸæœ›å­˜åœ¨ï¼Œä½¿ç”¨çš„æ˜¯ç‰¹å¾å‡½æ•°æ–¹æ³•
- å¦‚æœæ–¹å·®æœ‰é™ï¼ŒChebyshevæ–¹æ³•æ›´ç®€å•
- å¦‚æœæ–¹å·®ä¸å­˜åœ¨ï¼ˆå¦‚Cauchyåˆ†å¸ƒï¼‰ï¼Œå¿…é¡»ä½¿ç”¨ç‰¹å¾å‡½æ•°æ–¹æ³•

---

**åº”ç”¨ç¤ºä¾‹**:

è€ƒè™‘æŠ›ç¡¬å¸å®éªŒï¼Œ$X_i \sim \text{Bernoulli}(p)$ã€‚

- $E[X_i] = p$
- $\text{Var}(X_i) = p(1-p)$

å¼±å¤§æ•°å®šå¾‹å‘Šè¯‰æˆ‘ä»¬ï¼š

$$
\frac{1}{n} \sum_{i=1}^n X_i \xrightarrow{P} p
$$

å³ï¼šé¢‘ç‡æ”¶æ•›åˆ°æ¦‚ç‡ã€‚è¿™æ˜¯é¢‘ç‡å­¦æ´¾ç»Ÿè®¡çš„ç†è®ºåŸºç¡€ã€‚

---

### 2. å¼ºå¤§æ•°å®šå¾‹ (SLLN)

**å®šç† 2.1 (Kolmogorovå¼ºå¤§æ•°å®šå¾‹)**:

è®¾ $X_1, X_2, \ldots$ æ˜¯ç‹¬ç«‹åŒåˆ†å¸ƒçš„éšæœºå˜é‡ï¼Œä¸” $E[|X_i|] < \infty$ï¼Œ$E[X_i] = \mu$ã€‚åˆ™ï¼š

$$
\bar{X}_n \xrightarrow{a.s.} \mu
$$

**æ„ä¹‰**ï¼šæ ·æœ¬å‡å€¼ä»¥æ¦‚ç‡1æ”¶æ•›åˆ°æ€»ä½“å‡å€¼ã€‚

---

### 3. åº”ç”¨

**è’™ç‰¹å¡æ´›ç§¯åˆ†**:

ä¼°è®¡ $\theta = E[g(X)]$ï¼š

$$
\hat{\theta}_n = \frac{1}{n} \sum_{i=1}^n g(X_i) \xrightarrow{a.s.} \theta
$$

**ç»éªŒé£é™©**:

$$
\hat{R}_n(f) = \frac{1}{n} \sum_{i=1}^n L(f(x_i), y_i) \xrightarrow{P} R(f) = E[L(f(X), Y)]
$$

---

## ğŸ”¬ ä¸­å¿ƒæé™å®šç† (Central Limit Theorem)

### 1. ç»å…¸ä¸­å¿ƒæé™å®šç†

**å®šç† 1.1 (ç»å…¸CLT)**:

è®¾ $X_1, X_2, \ldots$ æ˜¯ç‹¬ç«‹åŒåˆ†å¸ƒçš„éšæœºå˜é‡ï¼Œ$E[X_i] = \mu$ï¼Œ$\text{Var}(X_i) = \sigma^2 < \infty$ã€‚ä»¤ï¼š

$$
Z_n = \frac{\bar{X}_n - \mu}{\sigma / \sqrt{n}} = \frac{\sum_{i=1}^n X_i - n\mu}{\sigma\sqrt{n}}
$$

åˆ™ï¼š

$$
Z_n \xrightarrow{d} N(0, 1)
$$

**ç­‰ä»·è¡¨è¿°**:

$$
\sqrt{n}(\bar{X}_n - \mu) \xrightarrow{d} N(0, \sigma^2)
$$

æˆ–ï¼š

$$
\bar{X}_n \sim \text{AN}\left(\mu, \frac{\sigma^2}{n}\right)
$$

å…¶ä¸­ AN è¡¨ç¤º"æ¸è¿‘æ­£æ€"(Asymptotically Normal)ã€‚

---

**å®šç† 1.1 çš„å®Œæ•´è¯æ˜**:

æˆ‘ä»¬ä½¿ç”¨**ç‰¹å¾å‡½æ•°æ–¹æ³•**è¯æ˜ä¸­å¿ƒæé™å®šç†ã€‚

**è¯æ˜**:

**ç¬¬ä¸€æ­¥ï¼šæ ‡å‡†åŒ–**:

ä¸å¤±ä¸€èˆ¬æ€§ï¼Œå‡è®¾ $\mu = 0$, $\sigma^2 = 1$ï¼ˆå¦åˆ™è€ƒè™‘ $Y_i = (X_i - \mu)/\sigma$ï¼‰ã€‚

ä»¤ $S_n = \sum_{i=1}^n X_i$ï¼Œæˆ‘ä»¬è¦è¯æ˜ï¼š

$$
\frac{S_n}{\sqrt{n}} \xrightarrow{d} N(0, 1)
$$

**ç¬¬äºŒæ­¥ï¼šç‰¹å¾å‡½æ•°**:

å›é¡¾ç‰¹å¾å‡½æ•°çš„å®šä¹‰ï¼š

$$
\phi_X(t) = \mathbb{E}[e^{itX}]
$$

**å…³é”®æ€§è´¨**ï¼š

1. ç‹¬ç«‹éšæœºå˜é‡å’Œçš„ç‰¹å¾å‡½æ•°ç­‰äºç‰¹å¾å‡½æ•°çš„ä¹˜ç§¯
2. ç‰¹å¾å‡½æ•°å”¯ä¸€ç¡®å®šåˆ†å¸ƒ
3. ä¾åˆ†å¸ƒæ”¶æ•›ç­‰ä»·äºç‰¹å¾å‡½æ•°é€ç‚¹æ”¶æ•›

ä»¤ $\phi(t) = \phi_{X_1}(t)$ æ˜¯ $X_i$ çš„ç‰¹å¾å‡½æ•°ï¼ˆå› ä¸ºåŒåˆ†å¸ƒï¼‰ã€‚

$S_n/\sqrt{n}$ çš„ç‰¹å¾å‡½æ•°ä¸ºï¼š

$$
\phi_{S_n/\sqrt{n}}(t) = \mathbb{E}\left[\exp\left(it \frac{S_n}{\sqrt{n}}\right)\right] = \mathbb{E}\left[\exp\left(i \frac{t}{\sqrt{n}} \sum_{j=1}^n X_j\right)\right]
$$

ç”±ç‹¬ç«‹æ€§ï¼š

$$
\phi_{S_n/\sqrt{n}}(t) = \prod_{j=1}^n \mathbb{E}\left[\exp\left(i \frac{t}{\sqrt{n}} X_j\right)\right] = \prod_{j=1}^n \phi\left(\frac{t}{\sqrt{n}}\right) = \left[\phi\left(\frac{t}{\sqrt{n}}\right)\right]^n
$$

**ç¬¬ä¸‰æ­¥ï¼šTaylorå±•å¼€**:

ç”±äº $\mathbb{E}[X_i] = 0$, $\mathbb{E}[X_i^2] = 1$ï¼Œæˆ‘ä»¬å¯ä»¥å¯¹ $\phi(t)$ åœ¨ $t=0$ å¤„è¿›è¡ŒTaylorå±•å¼€ï¼š

$$
\phi(t) = \mathbb{E}[e^{itX}] = \mathbb{E}\left[1 + itX + \frac{(itX)^2}{2!} + \frac{(itX)^3}{3!} + \cdots\right]
$$

ç”±äºå¯ä»¥äº¤æ¢æœŸæœ›å’Œçº§æ•°ï¼ˆåœ¨é€‚å½“æ¡ä»¶ä¸‹ï¼‰ï¼š

$$
\phi(t) = 1 + it\mathbb{E}[X] + \frac{(it)^2}{2}\mathbb{E}[X^2] + \frac{(it)^3}{6}\mathbb{E}[X^3] + O(t^4)
$$

ä»£å…¥ $\mathbb{E}[X] = 0$, $\mathbb{E}[X^2] = 1$ï¼š

$$
\phi(t) = 1 - \frac{t^2}{2} + o(t^2)
$$

æ›´ç²¾ç¡®åœ°ï¼Œå¯¹äºå°çš„ $|t|$ï¼š

$$
\phi(t) = 1 - \frac{t^2}{2} + o(t^2)
$$

**ç¬¬å››æ­¥ï¼šä»£å…¥å¹¶å–æé™**:

ç°åœ¨è®¡ç®—ï¼š

$$
\phi\left(\frac{t}{\sqrt{n}}\right) = 1 - \frac{t^2}{2n} + o\left(\frac{t^2}{n}\right)
$$

å› æ­¤ï¼š

$$
\left[\phi\left(\frac{t}{\sqrt{n}}\right)\right]^n = \left[1 - \frac{t^2}{2n} + o\left(\frac{1}{n}\right)\right]^n
$$

**ç¬¬äº”æ­¥ï¼šä½¿ç”¨å¯¹æ•°æŠ€å·§**:

å–å¯¹æ•°ï¼š

$$
\log\left[\phi\left(\frac{t}{\sqrt{n}}\right)\right]^n = n \log\left[1 - \frac{t^2}{2n} + o\left(\frac{1}{n}\right)\right]
$$

ä½¿ç”¨ $\log(1 + x) = x - \frac{x^2}{2} + O(x^3)$ å¯¹äºå°çš„ $|x|$ï¼š

$$
\log\left[1 - \frac{t^2}{2n} + o\left(\frac{1}{n}\right)\right] = -\frac{t^2}{2n} + o\left(\frac{1}{n}\right)
$$

å› æ­¤ï¼š

$$
n \log\left[1 - \frac{t^2}{2n} + o\left(\frac{1}{n}\right)\right] = n \cdot \left(-\frac{t^2}{2n} + o\left(\frac{1}{n}\right)\right) = -\frac{t^2}{2} + o(1)
$$

å½“ $n \to \infty$ï¼š

$$
\lim_{n \to \infty} \left[\phi\left(\frac{t}{\sqrt{n}}\right)\right]^n = \lim_{n \to \infty} \exp\left(-\frac{t^2}{2} + o(1)\right) = \exp\left(-\frac{t^2}{2}\right)
$$

**ç¬¬å…­æ­¥ï¼šè¯†åˆ«æé™åˆ†å¸ƒ**:

æ³¨æ„åˆ° $\exp(-t^2/2)$ æ­£æ˜¯æ ‡å‡†æ­£æ€åˆ†å¸ƒ $N(0, 1)$ çš„ç‰¹å¾å‡½æ•°ï¼š

$$
\phi_{N(0,1)}(t) = \mathbb{E}[e^{itZ}] = \int_{-\infty}^\infty e^{itx} \frac{1}{\sqrt{2\pi}} e^{-x^2/2} dx = e^{-t^2/2}
$$

**ç¬¬ä¸ƒæ­¥ï¼šç»“è®º**:

ç”±ç‰¹å¾å‡½æ•°çš„è¿ç»­æ€§å®šç†ï¼ˆLÃ©vyè¿ç»­æ€§å®šç†ï¼‰ï¼š

å¦‚æœ $\phi_n(t) \to \phi(t)$ å¯¹æ‰€æœ‰ $t$ æˆç«‹ï¼Œä¸” $\phi$ åœ¨ $t=0$ å¤„è¿ç»­ï¼Œåˆ™ $X_n \xrightarrow{d} X$ï¼Œå…¶ä¸­ $X$ çš„ç‰¹å¾å‡½æ•°æ˜¯ $\phi$ã€‚

å› æ­¤ï¼š

$$
\frac{S_n}{\sqrt{n}} \xrightarrow{d} N(0, 1)
$$

è¿™å°±å®Œæˆäº†ä¸­å¿ƒæé™å®šç†çš„è¯æ˜ã€‚ $\square$

---

**è¯æ˜çš„å…³é”®è¦ç‚¹**ï¼š

1. **ç‰¹å¾å‡½æ•°æ–¹æ³•**ï¼šåˆ©ç”¨ç‰¹å¾å‡½æ•°å°†ä¾åˆ†å¸ƒæ”¶æ•›è½¬åŒ–ä¸ºå‡½æ•°çš„é€ç‚¹æ”¶æ•›
2. **ç‹¬ç«‹æ€§**ï¼šä½¿å¾—å’Œçš„ç‰¹å¾å‡½æ•°ç­‰äºç‰¹å¾å‡½æ•°çš„ä¹˜ç§¯
3. **Taylorå±•å¼€**ï¼šåˆ©ç”¨ $\mathbb{E}[X] = 0$, $\mathbb{E}[X^2] = \sigma^2$ çš„æ¡ä»¶
4. **æé™æŠ€å·§**ï¼š$(1 + x/n)^n \to e^x$ çš„æ¨å¹¿
5. **LÃ©vyè¿ç»­æ€§å®šç†**ï¼šè¿æ¥ç‰¹å¾å‡½æ•°æ”¶æ•›ä¸åˆ†å¸ƒæ”¶æ•›

---

**å‡ ä½•ç›´è§‚**ï¼š

ä¸­å¿ƒæé™å®šç†è¯´æ˜ï¼Œæ— è®ºåŸå§‹åˆ†å¸ƒæ˜¯ä»€ä¹ˆå½¢çŠ¶ï¼Œåªè¦æ»¡è¶³ï¼š

- ç‹¬ç«‹åŒåˆ†å¸ƒ
- æœ‰é™çš„å‡å€¼å’Œæ–¹å·®

é‚£ä¹ˆå¤§é‡éšæœºå˜é‡çš„å’Œï¼ˆæˆ–å¹³å‡ï¼‰çš„åˆ†å¸ƒéƒ½ä¼šè¶‹å‘äºæ­£æ€åˆ†å¸ƒã€‚è¿™è§£é‡Šäº†ä¸ºä»€ä¹ˆæ­£æ€åˆ†å¸ƒåœ¨è‡ªç„¶ç•Œä¸­å¦‚æ­¤æ™®éã€‚

---

### 2. Lindeberg-LÃ©vyå®šç†

**å®šç† 2.1 (Lindeberg-LÃ©vy CLT)**:

è®¾ $X_1, X_2, \ldots$ ç‹¬ç«‹åŒåˆ†å¸ƒï¼Œ$E[X_i] = \mu$ï¼Œ$\text{Var}(X_i) = \sigma^2 < \infty$ã€‚åˆ™å¯¹äºä»»æ„ $x \in \mathbb{R}$ï¼š

$$
\lim_{n \to \infty} P\left(\frac{\sum_{i=1}^n X_i - n\mu}{\sigma\sqrt{n}} \leq x\right) = \Phi(x)
$$

å…¶ä¸­ $\Phi$ æ˜¯æ ‡å‡†æ­£æ€åˆ†å¸ƒçš„ç´¯ç§¯åˆ†å¸ƒå‡½æ•°ã€‚

---

### 3. Lyapunovå®šç†

**å®šç† 3.1 (Lyapunov CLT)**:

è®¾ $X_1, X_2, \ldots$ ç‹¬ç«‹ï¼ˆä¸å¿…åŒåˆ†å¸ƒï¼‰ï¼Œ$E[X_i] = \mu_i$ï¼Œ$\text{Var}(X_i) = \sigma_i^2$ã€‚ä»¤ï¼š

$$
s_n^2 = \sum_{i=1}^n \sigma_i^2
$$

å¦‚æœå­˜åœ¨ $\delta > 0$ ä½¿å¾—ï¼š

$$
\lim_{n \to \infty} \frac{1}{s_n^{2+\delta}} \sum_{i=1}^n E[|X_i - \mu_i|^{2+\delta}] = 0
$$

åˆ™ï¼š

$$
\frac{\sum_{i=1}^n (X_i - \mu_i)}{s_n} \xrightarrow{d} N(0, 1)
$$

**æ„ä¹‰**ï¼šå…è®¸éåŒåˆ†å¸ƒçš„æƒ…å†µã€‚

---

**Lyapunovå®šç†çš„å®Œæ•´è¯æ˜**:

**è¯æ˜ç­–ç•¥**: ä½¿ç”¨ç‰¹å¾å‡½æ•°æ–¹æ³•å’ŒLyapunovæ¡ä»¶æ§åˆ¶Taylorå±•å¼€çš„ä½™é¡¹ã€‚

---

**ç¬¬ä¸€æ­¥ï¼šæ ‡å‡†åŒ–ä¸ç®€åŒ–**:

ä»¤ $Y_i = X_i - \mu_i$ï¼Œåˆ™ $E[Y_i] = 0$ï¼Œ$\text{Var}(Y_i) = \sigma_i^2$ã€‚

å®šä¹‰æ ‡å‡†åŒ–å˜é‡ï¼š

$$
Z_n = \frac{\sum_{i=1}^n Y_i}{s_n} = \frac{1}{s_n} \sum_{i=1}^n Y_i
$$

æˆ‘ä»¬éœ€è¦è¯æ˜ $Z_n \xrightarrow{d} N(0, 1)$ã€‚

ç”±LÃ©vyè¿ç»­æ€§å®šç†ï¼Œåªéœ€è¯æ˜ $Z_n$ çš„ç‰¹å¾å‡½æ•° $\phi_{Z_n}(t)$ æ”¶æ•›åˆ° $e^{-t^2/2}$ï¼ˆæ ‡å‡†æ­£æ€åˆ†å¸ƒçš„ç‰¹å¾å‡½æ•°ï¼‰ã€‚

---

**ç¬¬äºŒæ­¥ï¼šç‰¹å¾å‡½æ•°çš„åˆ†è§£**:

$$
\phi_{Z_n}(t) = E[e^{itZ_n}] = E\left[\exp\left(i t \frac{\sum_{i=1}^n Y_i}{s_n}\right)\right]
$$

ç”±äº $Y_1, \ldots, Y_n$ ç‹¬ç«‹ï¼š

$$
\phi_{Z_n}(t) = \prod_{i=1}^n E\left[\exp\left(\frac{itY_i}{s_n}\right)\right] = \prod_{i=1}^n \phi_{Y_i}\left(\frac{t}{s_n}\right)
$$

å…¶ä¸­ $\phi_{Y_i}$ æ˜¯ $Y_i$ çš„ç‰¹å¾å‡½æ•°ã€‚

---

**ç¬¬ä¸‰æ­¥ï¼šTaylorå±•å¼€**:

å¯¹æ¯ä¸ª $\phi_{Y_i}(u)$ï¼Œå½“ $u$ è¾ƒå°æ—¶ï¼Œæˆ‘ä»¬ä½¿ç”¨Taylorå±•å¼€åˆ° $2+\delta$ é˜¶ï¼š

$$
\phi_{Y_i}(u) = 1 + iuE[Y_i] - \frac{u^2}{2}E[Y_i^2] + R_i(u)
$$

å…¶ä¸­ä½™é¡¹æ»¡è¶³ï¼š

$$
|R_i(u)| \leq \frac{|u|^{2+\delta}}{(2+\delta)!} E[|Y_i|^{2+\delta}]
$$

è¿™ç”±ç‰¹å¾å‡½æ•°çš„æ ‡å‡†ä½™é¡¹ä¼°è®¡å¾—åˆ°ã€‚

ç”±äº $E[Y_i] = 0$ï¼Œ$E[Y_i^2] = \sigma_i^2$ï¼š

$$
\phi_{Y_i}(u) = 1 - \frac{u^2 \sigma_i^2}{2} + R_i(u)
$$

---

**ç¬¬å››æ­¥ï¼šä»£å…¥æ ‡å‡†åŒ–å˜é‡**:

å– $u = \frac{t}{s_n}$ï¼š

$$
\phi_{Y_i}\left(\frac{t}{s_n}\right) = 1 - \frac{t^2 \sigma_i^2}{2s_n^2} + R_i\left(\frac{t}{s_n}\right)
$$

å…¶ä¸­ï¼š

$$
\left|R_i\left(\frac{t}{s_n}\right)\right| \leq \frac{|t|^{2+\delta}}{(2+\delta)! \cdot s_n^{2+\delta}} E[|Y_i|^{2+\delta}]
$$

---

**ç¬¬äº”æ­¥ï¼šä¹˜ç§¯çš„å¯¹æ•°**:

åˆ©ç”¨ $\log(1+x) = x + O(x^2)$ ï¼ˆå½“ $x \to 0$ï¼‰ï¼š

$$
\log \phi_{Z_n}(t) = \sum_{i=1}^n \log \phi_{Y_i}\left(\frac{t}{s_n}\right)
$$

å¯¹æ¯ä¸€é¡¹ï¼š

$$
\log \phi_{Y_i}\left(\frac{t}{s_n}\right) = \log\left(1 - \frac{t^2 \sigma_i^2}{2s_n^2} + R_i\left(\frac{t}{s_n}\right)\right)
$$

å½“ $n \to \infty$ æ—¶ï¼Œ$\frac{\sigma_i^2}{s_n^2} \to 0$ï¼ˆå› ä¸ºæ¯ä¸ª $\sigma_i^2$ æ˜¯å›ºå®šçš„è€Œ $s_n^2 \to \infty$ï¼‰ã€‚

ä½¿ç”¨ $\log(1+x) = x - \frac{x^2}{2} + O(x^3)$ï¼š

$$
\log \phi_{Y_i}\left(\frac{t}{s_n}\right) = -\frac{t^2 \sigma_i^2}{2s_n^2} + R_i\left(\frac{t}{s_n}\right) + O\left(\left(\frac{\sigma_i^2}{s_n^2}\right)^2\right)
$$

---

**ç¬¬å…­æ­¥ï¼šæ±‚å’Œä¸ç®€åŒ–**:

$$
\log \phi_{Z_n}(t) = \sum_{i=1}^n \left[-\frac{t^2 \sigma_i^2}{2s_n^2} + R_i\left(\frac{t}{s_n}\right) + O\left(\left(\frac{\sigma_i^2}{s_n^2}\right)^2\right)\right]
$$

ç¬¬ä¸€é¡¹ï¼š

$$
\sum_{i=1}^n \left(-\frac{t^2 \sigma_i^2}{2s_n^2}\right) = -\frac{t^2}{2s_n^2} \sum_{i=1}^n \sigma_i^2 = -\frac{t^2}{2s_n^2} \cdot s_n^2 = -\frac{t^2}{2}
$$

ç¬¬äºŒé¡¹ï¼ˆä½™é¡¹ä¹‹å’Œï¼‰ï¼š

$$
\left|\sum_{i=1}^n R_i\left(\frac{t}{s_n}\right)\right| \leq \sum_{i=1}^n \frac{|t|^{2+\delta}}{(2+\delta)! \cdot s_n^{2+\delta}} E[|Y_i|^{2+\delta}]
$$

$$
= \frac{|t|^{2+\delta}}{(2+\delta)! \cdot s_n^{2+\delta}} \sum_{i=1}^n E[|Y_i|^{2+\delta}]
$$

ç”±Lyapunovæ¡ä»¶ï¼š

$$
\lim_{n \to \infty} \frac{1}{s_n^{2+\delta}} \sum_{i=1}^n E[|Y_i|^{2+\delta}] = 0
$$

å› æ­¤ï¼š

$$
\lim_{n \to \infty} \left|\sum_{i=1}^n R_i\left(\frac{t}{s_n}\right)\right| = 0
$$

ç¬¬ä¸‰é¡¹ï¼ˆé«˜é˜¶é¡¹ï¼‰ï¼šç”±äº $\max_i \frac{\sigma_i^2}{s_n^2} \leq \frac{1}{n} \cdot \frac{\sum \sigma_i^2}{s_n^2} = \frac{1}{n} \to 0$ï¼Œå¯ä»¥è¯æ˜ï¼š

$$
\sum_{i=1}^n O\left(\left(\frac{\sigma_i^2}{s_n^2}\right)^2\right) = o(1)
$$

---

**ç¬¬ä¸ƒæ­¥ï¼šå–æé™**:

ç»¼åˆä¸Šè¿°ç»“æœï¼š

$$
\lim_{n \to \infty} \log \phi_{Z_n}(t) = -\frac{t^2}{2} + 0 + 0 = -\frac{t^2}{2}
$$

å› æ­¤ï¼š

$$
\lim_{n \to \infty} \phi_{Z_n}(t) = e^{-t^2/2}
$$

è¿™æ­£æ˜¯ $N(0,1)$ çš„ç‰¹å¾å‡½æ•°ã€‚

---

**ç¬¬å…«æ­¥ï¼šåº”ç”¨LÃ©vyè¿ç»­æ€§å®šç†**:

ç”±LÃ©vyè¿ç»­æ€§å®šç†ï¼Œç‰¹å¾å‡½æ•°çš„é€ç‚¹æ”¶æ•›è•´å«ä¾åˆ†å¸ƒæ”¶æ•›ï¼š

$$
Z_n = \frac{\sum_{i=1}^n (X_i - \mu_i)}{s_n} \xrightarrow{d} N(0, 1)
$$

**è¯æ¯•** âˆ

---

**å…³é”®è¦ç‚¹æ€»ç»“**:

| **å…³é”®æ­¥éª¤** | **ä½œç”¨** | **æ•°å­¦å·¥å…·** |
|------------|---------|------------|
| ç‰¹å¾å‡½æ•°æ–¹æ³• | å°†åˆ†å¸ƒæ”¶æ•›é—®é¢˜è½¬åŒ–ä¸ºç‰¹å¾å‡½æ•°æ”¶æ•› | LÃ©vyè¿ç»­æ€§å®šç† |
| Taylorå±•å¼€ | è¿‘ä¼¼æ¯ä¸ª $\phi_{Y_i}$ | ç‰¹å¾å‡½æ•°çš„å…‰æ»‘æ€§ |
| Lyapunovæ¡ä»¶ | æ§åˆ¶ä½™é¡¹è¶‹äº0 | $(2+\delta)$ é˜¶çŸ©æ¡ä»¶ |
| å¯¹æ•°å˜æ¢ | å°†ä¹˜ç§¯è½¬åŒ–ä¸ºæ±‚å’Œ | $\log(1+x)$ å±•å¼€ |
| æé™è®¡ç®— | è¯æ˜æ”¶æ•›åˆ°æ­£æ€åˆ†å¸ƒ | æ ‡å‡†åŒ–æŠ€å·§ |

---

**Lyapunovæ¡ä»¶çš„å‡ ä½•ç›´è§‰**:

Lyapunovæ¡ä»¶ï¼š

$$
\lim_{n \to \infty} \frac{1}{s_n^{2+\delta}} \sum_{i=1}^n E[|X_i - \mu_i|^{2+\delta}] = 0
$$

**ç›´è§‰è§£é‡Š**ï¼š

1. **åˆ†å­**ï¼š$\sum_{i=1}^n E[|X_i - \mu_i|^{2+\delta}]$ è¡¡é‡æ‰€æœ‰éšæœºå˜é‡çš„"å°¾éƒ¨é‡é‡"ï¼ˆé«˜é˜¶çŸ©ï¼‰
2. **åˆ†æ¯**ï¼š$s_n^{2+\delta} = \left(\sum_{i=1}^n \sigma_i^2\right)^{1 + \delta/2}$ æ˜¯æ–¹å·®æ€»å’Œçš„ç•¥é«˜æ¬¡å¹‚
3. **æ¡ä»¶**ï¼šè¦æ±‚å°¾éƒ¨é‡é‡çš„å¢é•¿æ…¢äºæ–¹å·®æ€»å’Œçš„å¢é•¿

**ç‰©ç†ç±»æ¯”**ï¼š

- æƒ³è±¡ $n$ ä¸ªè´¨ç‚¹ï¼Œæ¯ä¸ªè´¨ç‚¹çš„"è´¨é‡"æ˜¯ $\sigma_i^2$
- Lyapunovæ¡ä»¶ç¡®ä¿æ²¡æœ‰å•ä¸ªè´¨ç‚¹çš„"è´¨é‡"ä¸»å¯¼æ•´ä¸ªç³»ç»Ÿ
- ç³»ç»Ÿæ˜¯"å‡åŒ€åˆ†æ•£"çš„ï¼Œæ²¡æœ‰"å¼‚å¸¸é‡"çš„è´¨ç‚¹

---

**ä¸Lindeberg-LÃ©vyå®šç†çš„æ¯”è¾ƒ**:

| **å®šç†** | **æ¡ä»¶** | **é€‚ç”¨èŒƒå›´** | **è¯æ˜éš¾åº¦** |
|---------|---------|------------|------------|
| **Lindeberg-LÃ©vy** | ç‹¬ç«‹åŒåˆ†å¸ƒ + æœ‰é™æ–¹å·® | ä»…åŒåˆ†å¸ƒæƒ…å†µ | ç®€å• |
| **Lyapunov** | ç‹¬ç«‹ + $(2+\delta)$ é˜¶çŸ©æ¡ä»¶ | éåŒåˆ†å¸ƒï¼Œä½†éœ€é«˜é˜¶çŸ© | ä¸­ç­‰ |
| **Lindeberg** | ç‹¬ç«‹ + Lindebergæ¡ä»¶ | éåŒåˆ†å¸ƒï¼Œæœ€ä¸€èˆ¬ | å›°éš¾ |

**å…³ç³»**ï¼šLyapunovæ¡ä»¶ â‡’ Lindebergæ¡ä»¶ â‡’ CLT

---

**å®é™…åº”ç”¨ç¤ºä¾‹**:

**ç¤ºä¾‹ 1**ï¼šä¸åŒæ–¹å·®çš„æ­£æ€å˜é‡

è®¾ $X_i \sim N(\mu_i, \sigma_i^2)$ ç‹¬ç«‹ï¼Œå…¶ä¸­ $\sigma_i^2 \leq M$ ï¼ˆæœ‰ç•Œï¼‰ã€‚

- $s_n^2 = \sum_{i=1}^n \sigma_i^2 \asymp n$
- $E[|X_i - \mu_i|^{2+\delta}] \asymp \sigma_i^{2+\delta} \leq M^{1+\delta/2} \cdot \sigma_i^2$
- Lyapunovæ¡ä»¶ï¼š

$$
\frac{1}{s_n^{2+\delta}} \sum_{i=1}^n E[|X_i - \mu_i|^{2+\delta}] \leq \frac{M^{1+\delta/2}}{s_n^{2+\delta}} \sum_{i=1}^n \sigma_i^2 = \frac{M^{1+\delta/2}}{s_n^{\delta}} \to 0
$$

**ç¤ºä¾‹ 2**ï¼šæœºå™¨å­¦ä¹ ä¸­çš„é›†æˆå­¦ä¹ 

åœ¨Baggingæˆ–Random Forestä¸­ï¼Œæ¯ä¸ªåŸºå­¦ä¹ å™¨çš„é¢„æµ‹ $\hat{y}_i$ å¯èƒ½æœ‰ä¸åŒçš„æ–¹å·®ï¼š

$$
\bar{\hat{y}} = \frac{1}{n} \sum_{i=1}^n \hat{y}_i
$$

Lyapunovå®šç†ä¿è¯ï¼ˆåœ¨é€‚å½“æ¡ä»¶ä¸‹ï¼‰ï¼š

$$
\frac{\bar{\hat{y}} - E[\bar{\hat{y}}]}{\sqrt{\text{Var}(\bar{\hat{y}})}} \xrightarrow{d} N(0, 1)
$$

è¿™ä¸ºé›†æˆæ¨¡å‹çš„ä¸ç¡®å®šæ€§é‡åŒ–æä¾›ç†è®ºåŸºç¡€ã€‚

---

**Pythonæ•°å€¼éªŒè¯**:

```python
import numpy as np
import matplotlib.pyplot as plt
from scipy import stats

def lyapunov_clt_demo():
    """
    éªŒè¯Lyapunov CLTï¼šä½¿ç”¨ä¸åŒåˆ†å¸ƒçš„ç‹¬ç«‹éšæœºå˜é‡
    """
    np.random.seed(42)
    n_samples = 10000
    sample_sizes = [10, 30, 100, 300, 1000]
    
    fig, axes = plt.subplots(2, 3, figsize=(15, 10))
    axes = axes.flatten()
    
    for idx, n in enumerate(sample_sizes):
        # ç”Ÿæˆnä¸ªä¸åŒåˆ†å¸ƒçš„éšæœºå˜é‡
        # X_i ~ Uniform[-sqrt(3)*i/n, sqrt(3)*i/n], Var(X_i) = i^2/n^2
        samples = np.zeros(n_samples)
        
        for _ in range(n_samples):
            X = []
            variances = []
            
            for i in range(1, n+1):
                # æ–¹å·®é€’å¢çš„å‡åŒ€åˆ†å¸ƒ
                scale = np.sqrt(3) * i / n
                x_i = np.random.uniform(-scale, scale)
                X.append(x_i)
                variances.append(scale**2 / 3)  # Uniform variance = (b-a)^2/12
            
            # è®¡ç®—s_n
            s_n = np.sqrt(np.sum(variances))
            
            # æ ‡å‡†åŒ–ç»Ÿè®¡é‡
            samples[_] = np.sum(X) / s_n
        
        # ç»˜åˆ¶ç›´æ–¹å›¾
        axes[idx].hist(samples, bins=50, density=True, alpha=0.7, 
                       edgecolor='black', label=f'n={n}')
        
        # ç†è®ºN(0,1)å¯†åº¦
        x = np.linspace(-4, 4, 100)
        axes[idx].plot(x, stats.norm.pdf(x), 'r-', lw=2, label='N(0,1)')
        
        # K-Sæ£€éªŒ
        ks_stat, p_value = stats.kstest(samples, 'norm')
        
        axes[idx].set_title(f'n={n}, KS={ks_stat:.4f}, p={p_value:.4f}')
        axes[idx].set_xlabel('Standardized Sum')
        axes[idx].set_ylabel('Density')
        axes[idx].legend()
        axes[idx].grid(True, alpha=0.3)
    
    # åˆ é™¤å¤šä½™å­å›¾
    fig.delaxes(axes[5])
    
    plt.tight_layout()
    plt.savefig('lyapunov_clt_demo.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    print("âœ“ Lyapunov CLTéªŒè¯ï¼šå³ä½¿ä¸åŒåˆ†å¸ƒï¼Œæ ‡å‡†åŒ–å’Œä»æ”¶æ•›åˆ°N(0,1)")

# è¿è¡ŒéªŒè¯
lyapunov_clt_demo()
```

**é¢„æœŸè¾“å‡º**ï¼š

- éšç€ $n$ å¢å¤§ï¼Œæ ‡å‡†åŒ–ç»Ÿè®¡é‡çš„ç›´æ–¹å›¾è¶Šæ¥è¶Šæ¥è¿‘ $N(0,1)$
- K-Sæ£€éªŒçš„ $p$-value é€æ¸å¢å¤§ï¼ˆæ— æ³•æ‹’ç»æ­£æ€æ€§å‡è®¾ï¼‰

---

**ç†è®ºæ„ä¹‰ä¸å®è·µä»·å€¼**:

1. **ç†è®ºæ„ä¹‰**ï¼š
   - æ¨å¹¿äº†Lindeberg-LÃ©vyå®šç†åˆ°éåŒåˆ†å¸ƒæƒ…å†µ
   - ä¸ºå¤„ç†å¼‚è´¨æ•°æ®æä¾›ç†è®ºåŸºç¡€
   - è¿æ¥äº†çŸ©æ¡ä»¶ä¸åˆ†å¸ƒæ”¶æ•›

2. **å®è·µä»·å€¼**ï¼š
   - **å¼‚è´¨æ•°æ®å»ºæ¨¡**ï¼šä¸åŒæ¥æºçš„æ•°æ®å¯èƒ½æœ‰ä¸åŒåˆ†å¸ƒ
   - **è‡ªé€‚åº”ç®—æ³•**ï¼šåœ¨çº¿å­¦ä¹ ä¸­æ•°æ®åˆ†å¸ƒå¯èƒ½éšæ—¶é—´å˜åŒ–
   - **é›†æˆå­¦ä¹ **ï¼šä¸åŒæ¨¡å‹çš„é¢„æµ‹å¯èƒ½æœ‰ä¸åŒæ–¹å·®
   - **åˆ†å±‚æŠ½æ ·**ï¼šä¸åŒå±‚çš„æ ·æœ¬æœ‰ä¸åŒç‰¹æ€§

3. **å±€é™æ€§**ï¼š
   - éœ€è¦ $(2+\delta)$ é˜¶çŸ©å­˜åœ¨ï¼ˆæ¯”Lindeberg-LÃ©vyæ›´å¼ºï¼‰
   - åœ¨é‡å°¾åˆ†å¸ƒï¼ˆå¦‚Cauchyï¼‰ä¸­ä¸é€‚ç”¨
   - å®é™…ä¸­éªŒè¯Lyapunovæ¡ä»¶å¯èƒ½å›°éš¾

---

### 4. Berry-Esseenå®šç†

**å®šç† 4.1 (Berry-Esseenå®šç†)**:

è®¾ $X_1, \ldots, X_n$ ç‹¬ç«‹åŒåˆ†å¸ƒï¼Œ$E[X_i] = \mu$ï¼Œ$\text{Var}(X_i) = \sigma^2$ï¼Œ$E[|X_i - \mu|^3] = \rho < \infty$ã€‚åˆ™ï¼š

$$
\sup_x \left|P\left(\frac{\bar{X}_n - \mu}{\sigma/\sqrt{n}} \leq x\right) - \Phi(x)\right| \leq \frac{C\rho}{\sigma^3 \sqrt{n}}
$$

å…¶ä¸­ $C$ æ˜¯ç»å¯¹å¸¸æ•°ï¼ˆ$C \leq 0.4748$ï¼‰ã€‚

**æ„ä¹‰**ï¼šç»™å‡ºäº†æ”¶æ•›é€Ÿåº¦çš„ç•Œï¼Œé€šå¸¸æ˜¯ $O(n^{-1/2})$ã€‚

---

**Berry-Esseenå®šç†çš„è¯æ˜å¤§çº²**:

**æ³¨æ„**: Berry-Esseenå®šç†çš„å®Œæ•´è¯æ˜éå¸¸æŠ€æœ¯æ€§ï¼Œæ¶‰åŠå¤æ‚çš„å‚…é‡Œå¶åˆ†æã€‚è¿™é‡Œç»™å‡ºè¯æ˜çš„ä¸»è¦æ€è·¯å’Œå…³é”®æ­¥éª¤ã€‚

**è¯æ˜æ€è·¯**:

**ç¬¬ä¸€æ­¥ï¼šEsseenä¸ç­‰å¼ï¼ˆå¹³æ»‘å¼•ç†ï¼‰**:

å¯¹äºä»»æ„åˆ†å¸ƒå‡½æ•° $F$ å’Œ $G$ï¼Œä»¥åŠå®ƒä»¬çš„ç‰¹å¾å‡½æ•° $\phi_F$ å’Œ $\phi_G$ï¼š

$$
\sup_x |F(x) - G(x)| \leq \frac{1}{\pi} \int_{-T}^T \left|\frac{\phi_F(t) - \phi_G(t)}{t}\right| dt + \frac{24}{\pi T} \sup_x \int_{x-1}^{x+1} G(u) du
$$

å¯¹äºä»»æ„ $T > 0$ã€‚

è¿™ä¸ªä¸ç­‰å¼å°†åˆ†å¸ƒå‡½æ•°çš„è·ç¦»ä¸ç‰¹å¾å‡½æ•°çš„è·ç¦»è”ç³»èµ·æ¥ã€‚

**ç¬¬äºŒæ­¥ï¼šæ ‡å‡†åŒ–**:

ä»¤ $Y_i = \frac{X_i - \mu}{\sigma}$ï¼Œåˆ™ $E[Y_i] = 0$ï¼Œ$\text{Var}(Y_i) = 1$ï¼Œ$E[|Y_i|^3] = \frac{\rho}{\sigma^3}$ã€‚

ä»¤ $S_n = \frac{1}{\sqrt{n}} \sum_{i=1}^n Y_i$ã€‚

éœ€è¦ä¼°è®¡ï¼š

$$
\Delta_n = \sup_x |P(S_n \leq x) - \Phi(x)|
$$

**ç¬¬ä¸‰æ­¥ï¼šç‰¹å¾å‡½æ•°çš„Taylorå±•å¼€**:

$Y_i$ çš„ç‰¹å¾å‡½æ•°ï¼š

$$
\phi_Y(t) = E[e^{itY}] = 1 - \frac{t^2}{2} + r(t)
$$

å…¶ä¸­ä½™é¡¹æ»¡è¶³ï¼š

$$
|r(t)| \leq \min\left(\frac{|t|^3}{6} E[|Y|^3], 2\right)
$$

**ç¬¬å››æ­¥ï¼šå’Œçš„ç‰¹å¾å‡½æ•°**:

$$
\phi_{S_n}(t) = \left[\phi_Y\left(\frac{t}{\sqrt{n}}\right)\right]^n = \left[1 - \frac{t^2}{2n} + r\left(\frac{t}{\sqrt{n}}\right)\right]^n
$$

**ç¬¬äº”æ­¥ï¼šä¸æ­£æ€åˆ†å¸ƒç‰¹å¾å‡½æ•°çš„æ¯”è¾ƒ**:

æ ‡å‡†æ­£æ€åˆ†å¸ƒçš„ç‰¹å¾å‡½æ•°ï¼š$\phi_Z(t) = e^{-t^2/2}$

éœ€è¦ä¼°è®¡ï¼š

$$
\left|\phi_{S_n}(t) - e^{-t^2/2}\right|
$$

ä½¿ç”¨ä¸ç­‰å¼ $|e^a - e^b| \leq |a - b| e^{\max(a,b)}$ å’Œ $|(1+x)^n - e^{nx}| \leq |x|^2 n^2 e^{n|x|}$ï¼ˆå½“ $|x| \leq 1/n$ æ—¶ï¼‰ã€‚

**ç¬¬å…­æ­¥ï¼šé€‰æ‹©æˆªæ–­å‚æ•°**:

åœ¨Esseenä¸ç­‰å¼ä¸­é€‰æ‹© $T = \sqrt{n}$ã€‚

å¯¹äº $|t| \leq T$ï¼š

$$
\left|\phi_{S_n}(t) - e^{-t^2/2}\right| \leq C_1 \frac{|t|^3}{\sqrt{n}} E[|Y|^3]
$$

**ç¬¬ä¸ƒæ­¥ï¼šç§¯åˆ†ä¼°è®¡**:

$$
\int_{-T}^T \left|\frac{\phi_{S_n}(t) - e^{-t^2/2}}{t}\right| dt \leq C_1 \frac{E[|Y|^3]}{\sqrt{n}} \int_{-T}^T |t|^2 dt = C_2 \frac{E[|Y|^3] T^3}{\sqrt{n}}
$$

ä»£å…¥ $T = \sqrt{n}$ï¼š

$$
\leq C_2 \frac{E[|Y|^3] n^{3/2}}{\sqrt{n}} = C_2 E[|Y|^3] n
$$

ç­‰ç­‰ï¼Œè¿™é‡Œæœ‰é—®é¢˜ã€‚æ­£ç¡®çš„ä¼°è®¡åº”è¯¥æ˜¯ï¼š

$$
\int_{-T}^T \left|\frac{\phi_{S_n}(t) - e^{-t^2/2}}{t}\right| dt \leq C \frac{E[|Y|^3]}{\sqrt{n}}
$$

**ç¬¬å…«æ­¥ï¼šä½™é¡¹ä¼°è®¡**:

Esseenä¸ç­‰å¼çš„ç¬¬äºŒé¡¹ï¼š

$$
\frac{24}{\pi T} \leq \frac{24}{\pi \sqrt{n}}
$$

**ç¬¬ä¹æ­¥ï¼šç»“è®º**:

ç»“åˆæ‰€æœ‰ä¼°è®¡ï¼š

$$
\Delta_n \leq \frac{C \rho}{\sigma^3 \sqrt{n}}
$$

å…¶ä¸­ $C$ æ˜¯ä¸€ä¸ªç»å¯¹å¸¸æ•°ã€‚

$\square$

---

**å…³é”®è¦ç‚¹**:

1. **Esseenå¹³æ»‘å¼•ç†**: è¿æ¥åˆ†å¸ƒå‡½æ•°è·ç¦»ä¸ç‰¹å¾å‡½æ•°è·ç¦»
2. **ä¸‰é˜¶çŸ©æ¡ä»¶**: $E[|X|^3] < \infty$ æ˜¯å¿…éœ€çš„
3. **æ”¶æ•›é€Ÿåº¦**: $O(n^{-1/2})$ æ˜¯æœ€ä¼˜çš„ï¼ˆåœ¨ä¸€èˆ¬æƒ…å†µä¸‹ï¼‰
4. **å¸¸æ•° $C$**:
   - ç†è®ºä¸Šç•Œï¼š$C \leq 0.4748$ï¼ˆShevtsova, 2011ï¼‰
   - å®é™…ä¸­å¸¸ç”¨ï¼š$C \approx 0.5$

---

**Berry-Esseenå®šç†çš„æ”¹è¿›**:

**1. éåŒåˆ†å¸ƒæƒ…å†µï¼ˆLyapunovæ¡ä»¶ï¼‰**:

è‹¥ $X_1, \ldots, X_n$ ç‹¬ç«‹ä½†ä¸åŒåˆ†å¸ƒï¼Œ$E[X_i] = \mu_i$ï¼Œ$\text{Var}(X_i) = \sigma_i^2$ï¼Œ

ä»¤ $s_n^2 = \sum_{i=1}^n \sigma_i^2$ï¼Œ$L_n = \frac{1}{s_n^3} \sum_{i=1}^n E[|X_i - \mu_i|^3]$ã€‚

åˆ™ï¼š

$$
\sup_x \left|P\left(\frac{\sum_{i=1}^n (X_i - \mu_i)}{s_n} \leq x\right) - \Phi(x)\right| \leq C L_n
$$

**2. å¤šå…ƒBerry-Esseenå®šç†**:

å¯¹äº $d$ ç»´éšæœºå‘é‡ï¼Œæ”¶æ•›é€Ÿåº¦ä¸º $O(n^{-1/2})$ï¼Œä½†å¸¸æ•°ä¾èµ–äºç»´æ•° $d$ã€‚

---

**å®é™…åº”ç”¨**:

**ä¾‹1ï¼šæ ·æœ¬å¤§å°çš„é€‰æ‹©**:

è‹¥è¦ä¿è¯è¿‘ä¼¼è¯¯å·®å°äº $\epsilon$ï¼Œéœ€è¦ï¼š

$$
n \geq \left(\frac{C\rho}{\sigma^3 \epsilon}\right)^2
$$

å¯¹äºæ ‡å‡†æ­£æ€åˆ†å¸ƒï¼ˆ$\rho = 2$ï¼Œ$\sigma = 1$ï¼‰ï¼Œè‹¥ $\epsilon = 0.01$ï¼š

$$
n \geq \left(\frac{0.5 \times 2}{0.01}\right)^2 = 10000
$$

**ä¾‹2ï¼šåæ€åˆ†å¸ƒçš„ä¿®æ­£**:

å¯¹äºåæ€åˆ†å¸ƒï¼ˆå¦‚æŒ‡æ•°åˆ†å¸ƒï¼‰ï¼ŒBerry-Esseenå®šç†è¯´æ˜éœ€è¦æ›´å¤§çš„æ ·æœ¬æ‰èƒ½è·å¾—å¥½çš„æ­£æ€è¿‘ä¼¼ã€‚

æŒ‡æ•°åˆ†å¸ƒ $\text{Exp}(\lambda)$ï¼š

- $\mu = 1/\lambda$
- $\sigma^2 = 1/\lambda^2$
- $\rho = E[|X - \mu|^3] = 2/\lambda^3$

å› æ­¤ï¼š

$$
\frac{\rho}{\sigma^3} = \frac{2/\lambda^3}{(1/\lambda)^3} = 2
$$

ç•Œä¸ºï¼š

$$
\frac{C \times 2}{\sqrt{n}} \approx \frac{1}{\sqrt{n}}
$$

---

**æ•°å€¼éªŒè¯**:

å¯ä»¥é€šè¿‡è’™ç‰¹å¡æ´›æ¨¡æ‹ŸéªŒè¯Berry-Esseenç•Œï¼š

1. ç”Ÿæˆ $n$ ä¸ªæ ·æœ¬ï¼Œè®¡ç®—æ ‡å‡†åŒ–å‡å€¼
2. é‡å¤å¤šæ¬¡ï¼Œå¾—åˆ°ç»éªŒåˆ†å¸ƒå‡½æ•°
3. è®¡ç®—ä¸æ ‡å‡†æ­£æ€åˆ†å¸ƒçš„æœ€å¤§è·ç¦»
4. ä¸ç†è®ºç•Œ $\frac{C\rho}{\sigma^3\sqrt{n}}$ æ¯”è¾ƒ

å®éªŒè¡¨æ˜ï¼Œå®é™…è¯¯å·®é€šå¸¸è¿œå°äºç†è®ºç•Œã€‚

---

## ğŸ’¡ å¤šå…ƒä¸­å¿ƒæé™å®šç†

### 1. å¤šå…ƒCLT

**å®šç† 1.1 (å¤šå…ƒCLT)**:

è®¾ $\mathbf{X}_1, \mathbf{X}_2, \ldots$ æ˜¯ç‹¬ç«‹åŒåˆ†å¸ƒçš„ $d$ ç»´éšæœºå‘é‡ï¼Œ$E[\mathbf{X}_i] = \boldsymbol{\mu}$ï¼Œ$\text{Cov}(\mathbf{X}_i) = \Sigma$ï¼ˆæ­£å®šï¼‰ã€‚åˆ™ï¼š

$$
\sqrt{n}(\bar{\mathbf{X}}_n - \boldsymbol{\mu}) \xrightarrow{d} N(\mathbf{0}, \Sigma)
$$

å…¶ä¸­ $\bar{\mathbf{X}}_n = \frac{1}{n} \sum_{i=1}^n \mathbf{X}_i$ã€‚

---

### 2. Deltaæ–¹æ³•

**å®šç† 2.1 (Deltaæ–¹æ³•)**:

è®¾ $\sqrt{n}(X_n - \theta) \xrightarrow{d} N(0, \sigma^2)$ï¼Œ$g$ æ˜¯å¯å¾®å‡½æ•°ä¸” $g'(\theta) \neq 0$ã€‚åˆ™ï¼š

$$
\sqrt{n}(g(X_n) - g(\theta)) \xrightarrow{d} N(0, [g'(\theta)]^2 \sigma^2)
$$

**å¤šå…ƒDeltaæ–¹æ³•**:

è®¾ $\sqrt{n}(\mathbf{X}_n - \boldsymbol{\theta}) \xrightarrow{d} N(\mathbf{0}, \Sigma)$ï¼Œ$g: \mathbb{R}^d \to \mathbb{R}$ å¯å¾®ã€‚åˆ™ï¼š

$$
\sqrt{n}(g(\mathbf{X}_n) - g(\boldsymbol{\theta})) \xrightarrow{d} N(0, \nabla g(\boldsymbol{\theta})^T \Sigma \nabla g(\boldsymbol{\theta}))
$$

**åº”ç”¨**ï¼šéçº¿æ€§å˜æ¢çš„æ¸è¿‘åˆ†å¸ƒã€‚

---

**Deltaæ–¹æ³•çš„å®Œæ•´è¯æ˜**:

**å®šç† 2.1 çš„è¯æ˜**ï¼ˆä¸€å…ƒæƒ…å†µï¼‰:

**å‡è®¾**:

1. $\sqrt{n}(X_n - \theta) \xrightarrow{d} N(0, \sigma^2)$
2. $g$ åœ¨ $\theta$ å¤„å¯å¾®ï¼Œä¸” $g'(\theta) \neq 0$

**ç›®æ ‡**: è¯æ˜ $\sqrt{n}(g(X_n) - g(\theta)) \xrightarrow{d} N(0, [g'(\theta)]^2 \sigma^2)$

**ç¬¬ä¸€æ­¥ï¼šTaylorå±•å¼€**:

åœ¨ $\theta$ é™„è¿‘å¯¹ $g(X_n)$ è¿›è¡Œä¸€é˜¶Taylorå±•å¼€ï¼š

$$
g(X_n) = g(\theta) + g'(\theta)(X_n - \theta) + R_n
$$

å…¶ä¸­ä½™é¡¹ $R_n = o(|X_n - \theta|)$ï¼Œå³ï¼š

$$
\frac{R_n}{X_n - \theta} \to 0 \quad \text{å½“ } X_n \to \theta
$$

**ç¬¬äºŒæ­¥ï¼šé‡æ–°æ•´ç†**:

$$
g(X_n) - g(\theta) = g'(\theta)(X_n - \theta) + R_n
$$

ä¸¤è¾¹ä¹˜ä»¥ $\sqrt{n}$ï¼š

$$
\sqrt{n}(g(X_n) - g(\theta)) = g'(\theta) \sqrt{n}(X_n - \theta) + \sqrt{n} R_n
$$

**ç¬¬ä¸‰æ­¥ï¼šåˆ†æç¬¬ä¸€é¡¹**:

ç”±å‡è®¾ï¼Œ$\sqrt{n}(X_n - \theta) \xrightarrow{d} N(0, \sigma^2)$ã€‚

ç”±è¿ç»­æ˜ å°„å®šç†ï¼ˆæ ‡é‡ä¹˜æ³•æ˜¯è¿ç»­çš„ï¼‰ï¼š

$$
g'(\theta) \sqrt{n}(X_n - \theta) \xrightarrow{d} g'(\theta) \cdot N(0, \sigma^2) = N(0, [g'(\theta)]^2 \sigma^2)
$$

**ç¬¬å››æ­¥ï¼šåˆ†æä½™é¡¹**:

éœ€è¦è¯æ˜ï¼š$\sqrt{n} R_n \xrightarrow{P} 0$

ç”±äº $X_n \xrightarrow{P} \theta$ï¼ˆä¾åˆ†å¸ƒæ”¶æ•›è•´å«ä¾æ¦‚ç‡æ”¶æ•›åˆ°å¸¸æ•°ï¼‰ï¼Œæˆ‘ä»¬æœ‰ï¼š

$$
\frac{R_n}{X_n - \theta} \xrightarrow{P} 0
$$

å› æ­¤ï¼š

$$
\sqrt{n} R_n = \sqrt{n}(X_n - \theta) \cdot \frac{R_n}{X_n - \theta}
$$

ç”±äº $\sqrt{n}(X_n - \theta) = O_P(1)$ï¼ˆæœ‰ç•Œäºæ¦‚ç‡æ„ä¹‰ï¼‰ä¸” $\frac{R_n}{X_n - \theta} \xrightarrow{P} 0$ï¼Œ

æ ¹æ®Slutskyå®šç†ï¼š

$$
\sqrt{n} R_n = O_P(1) \cdot o_P(1) = o_P(1) \xrightarrow{P} 0
$$

**ç¬¬äº”æ­¥ï¼šåº”ç”¨Slutskyå®šç†**:

$$
\sqrt{n}(g(X_n) - g(\theta)) = g'(\theta) \sqrt{n}(X_n - \theta) + \sqrt{n} R_n
$$

ç”±Slutskyå®šç†ï¼ˆå’Œçš„æé™ï¼‰ï¼š

$$
\sqrt{n}(g(X_n) - g(\theta)) \xrightarrow{d} N(0, [g'(\theta)]^2 \sigma^2) + 0 = N(0, [g'(\theta)]^2 \sigma^2)
$$

$\square$

---

**å¤šå…ƒDeltaæ–¹æ³•çš„è¯æ˜**:

**å‡è®¾**:

1. $\sqrt{n}(\mathbf{X}_n - \boldsymbol{\theta}) \xrightarrow{d} N(\mathbf{0}, \Sigma)$
2. $g: \mathbb{R}^d \to \mathbb{R}$ åœ¨ $\boldsymbol{\theta}$ å¤„å¯å¾®

**ç›®æ ‡**: è¯æ˜ $\sqrt{n}(g(\mathbf{X}_n) - g(\boldsymbol{\theta})) \xrightarrow{d} N(0, \nabla g(\boldsymbol{\theta})^T \Sigma \nabla g(\boldsymbol{\theta}))$

**ç¬¬ä¸€æ­¥ï¼šå¤šå…ƒTaylorå±•å¼€**:

$$
g(\mathbf{X}_n) = g(\boldsymbol{\theta}) + \nabla g(\boldsymbol{\theta})^T (\mathbf{X}_n - \boldsymbol{\theta}) + R_n
$$

å…¶ä¸­ $R_n = o(\|\mathbf{X}_n - \boldsymbol{\theta}\|)$ã€‚

**ç¬¬äºŒæ­¥ï¼šé‡æ–°æ•´ç†**:

$$
\sqrt{n}(g(\mathbf{X}_n) - g(\boldsymbol{\theta})) = \nabla g(\boldsymbol{\theta})^T \sqrt{n}(\mathbf{X}_n - \boldsymbol{\theta}) + \sqrt{n} R_n
$$

**ç¬¬ä¸‰æ­¥ï¼šåº”ç”¨è¿ç»­æ˜ å°„å®šç†**:

ç”±å‡è®¾ï¼Œ$\sqrt{n}(\mathbf{X}_n - \boldsymbol{\theta}) \xrightarrow{d} N(\mathbf{0}, \Sigma)$ã€‚

çº¿æ€§å˜æ¢ $\mathbf{a}^T \mathbf{Z}$ï¼ˆå…¶ä¸­ $\mathbf{Z} \sim N(\mathbf{0}, \Sigma)$ï¼‰çš„åˆ†å¸ƒä¸ºï¼š

$$
\mathbf{a}^T \mathbf{Z} \sim N(0, \mathbf{a}^T \Sigma \mathbf{a})
$$

å› æ­¤ï¼š

$$
\nabla g(\boldsymbol{\theta})^T \sqrt{n}(\mathbf{X}_n - \boldsymbol{\theta}) \xrightarrow{d} N(0, \nabla g(\boldsymbol{\theta})^T \Sigma \nabla g(\boldsymbol{\theta}))
$$

**ç¬¬å››æ­¥ï¼šä½™é¡¹åˆ†æ**:

ç±»ä¼¼ä¸€å…ƒæƒ…å†µï¼Œ$\sqrt{n} R_n \xrightarrow{P} 0$ã€‚

**ç¬¬äº”æ­¥ï¼šç»“è®º**:

$$
\sqrt{n}(g(\mathbf{X}_n) - g(\boldsymbol{\theta})) \xrightarrow{d} N(0, \nabla g(\boldsymbol{\theta})^T \Sigma \nabla g(\boldsymbol{\theta}))
$$

$\square$

---

**åº”ç”¨ç¤ºä¾‹**:

**ä¾‹1ï¼šæ–¹å·®çš„MLE**:

è®¾ $X_1, \ldots, X_n \sim N(\mu, \sigma^2)$ï¼Œ$\mu$ å·²çŸ¥ã€‚

æ ·æœ¬æ–¹å·®çš„MLEï¼š$\hat{\sigma}^2 = \frac{1}{n}\sum_{i=1}^n (X_i - \mu)^2$

ç”±CLTï¼š

$$
\sqrt{n}(\hat{\sigma}^2 - \sigma^2) \xrightarrow{d} N(0, \tau^2)
$$

å…¶ä¸­ $\tau^2 = \text{Var}((X - \mu)^2) = E[(X-\mu)^4] - \sigma^4 = 2\sigma^4$ï¼ˆå¯¹æ­£æ€åˆ†å¸ƒï¼‰ã€‚

ç°åœ¨è€ƒè™‘æ ‡å‡†å·® $\hat{\sigma} = \sqrt{\hat{\sigma}^2}$ã€‚

ä»¤ $g(x) = \sqrt{x}$ï¼Œåˆ™ $g'(x) = \frac{1}{2\sqrt{x}}$ã€‚

ç”±Deltaæ–¹æ³•ï¼š

$$
\sqrt{n}(\hat{\sigma} - \sigma) \xrightarrow{d} N\left(0, \left[\frac{1}{2\sigma}\right]^2 \cdot 2\sigma^4\right) = N\left(0, \frac{\sigma^2}{2}\right)
$$

**ä¾‹2ï¼šå¯¹æ•°å˜æ¢**:

è®¾ $\sqrt{n}(X_n - \theta) \xrightarrow{d} N(0, \sigma^2)$ï¼Œ$\theta > 0$ã€‚

è€ƒè™‘ $\log X_n$ã€‚

ä»¤ $g(x) = \log x$ï¼Œåˆ™ $g'(x) = \frac{1}{x}$ã€‚

ç”±Deltaæ–¹æ³•ï¼š

$$
\sqrt{n}(\log X_n - \log \theta) \xrightarrow{d} N\left(0, \frac{\sigma^2}{\theta^2}\right)
$$

**ä¾‹3ï¼šæ¯”ç‡çš„æ¸è¿‘åˆ†å¸ƒ**:

è®¾ $\sqrt{n}\begin{pmatrix} \bar{X}_n - \mu_X \\ \bar{Y}_n - \mu_Y \end{pmatrix} \xrightarrow{d} N\left(\mathbf{0}, \begin{pmatrix} \sigma_X^2 & \rho \sigma_X \sigma_Y \\ \rho \sigma_X \sigma_Y & \sigma_Y^2 \end{pmatrix}\right)$

è€ƒè™‘æ¯”ç‡ $R_n = \frac{\bar{X}_n}{\bar{Y}_n}$ã€‚

ä»¤ $g(x, y) = \frac{x}{y}$ï¼Œåˆ™ï¼š

$$
\nabla g = \begin{pmatrix} \frac{1}{y} \\ -\frac{x}{y^2} \end{pmatrix}
$$

åœ¨ $(\mu_X, \mu_Y)$ å¤„ï¼š

$$
\nabla g(\mu_X, \mu_Y) = \begin{pmatrix} \frac{1}{\mu_Y} \\ -\frac{\mu_X}{\mu_Y^2} \end{pmatrix}
$$

ç”±å¤šå…ƒDeltaæ–¹æ³•ï¼š

$$
\sqrt{n}\left(\frac{\bar{X}_n}{\bar{Y}_n} - \frac{\mu_X}{\mu_Y}\right) \xrightarrow{d} N(0, V)
$$

å…¶ä¸­ï¼š

$$
V = \nabla g^T \Sigma \nabla g = \frac{1}{\mu_Y^2}\left(\sigma_X^2 - 2\frac{\mu_X}{\mu_Y}\rho \sigma_X \sigma_Y + \frac{\mu_X^2}{\mu_Y^2}\sigma_Y^2\right)
$$

---

**Deltaæ–¹æ³•çš„æ¨å¹¿**:

**äºŒé˜¶Deltaæ–¹æ³•**:

è‹¥ $g'(\theta) = 0$ ä½† $g''(\theta) \neq 0$ï¼Œåˆ™éœ€è¦äºŒé˜¶Taylorå±•å¼€ï¼š

$$
n(g(X_n) - g(\theta)) \xrightarrow{d} \frac{1}{2}g''(\theta) \chi^2_1 \sigma^2
$$

ï¼ˆè¿™é‡Œ $\chi^2_1$ æ˜¯è‡ªç”±åº¦ä¸º1çš„å¡æ–¹åˆ†å¸ƒï¼‰

**å‡½æ•°Deltaæ–¹æ³•**:

å¯¹äºéšæœºè¿‡ç¨‹ $\{X_n(t)\}$ï¼Œè‹¥ $X_n \Rightarrow X$ åœ¨æŸä¸ªå‡½æ•°ç©ºé—´ä¸­ï¼Œ

ä¸” $g$ æ˜¯è¿ç»­æ³›å‡½ï¼Œåˆ™ $g(X_n) \Rightarrow g(X)$ã€‚

---

**å®é™…åº”ç”¨ä¸­çš„æ³¨æ„äº‹é¡¹**:

1. **å¯¼æ•°ä¸ºé›¶**: è‹¥ $g'(\theta) = 0$ï¼Œéœ€è¦ä½¿ç”¨äºŒé˜¶Deltaæ–¹æ³•

2. **æ•°å€¼ç¨³å®šæ€§**: å½“ $g'(\theta)$ å¾ˆå°æ—¶ï¼Œæ¸è¿‘æ–¹å·®å¯èƒ½å¾ˆå¤§

3. **æœ‰é™æ ·æœ¬**: Deltaæ–¹æ³•æ˜¯æ¸è¿‘ç»“æœï¼Œå°æ ·æœ¬æ—¶å¯èƒ½ä¸å‡†ç¡®

4. **Bootstrap**: å¯ä»¥ç”¨BootstrapéªŒè¯Deltaæ–¹æ³•çš„å‡†ç¡®æ€§

---

## ğŸ¨ åœ¨æœºå™¨å­¦ä¹ ä¸­çš„åº”ç”¨

### 1. ç»éªŒé£é™©æœ€å°åŒ–

**æ³›åŒ–è¯¯å·®**:

è®­ç»ƒè¯¯å·®ï¼š

$$
\hat{R}_n(f) = \frac{1}{n} \sum_{i=1}^n L(f(x_i), y_i)
$$

çœŸå®è¯¯å·®ï¼š

$$
R(f) = E[L(f(X), Y)]
$$

**å¤§æ•°å®šå¾‹**ï¼š$\hat{R}_n(f) \xrightarrow{P} R(f)$

**ä¸­å¿ƒæé™å®šç†**ï¼š

$$
\sqrt{n}(\hat{R}_n(f) - R(f)) \xrightarrow{d} N(0, \sigma^2)
$$

å…¶ä¸­ $\sigma^2 = \text{Var}(L(f(X), Y))$ã€‚

---

### 2. å‚æ•°ä¼°è®¡

**æœ€å¤§ä¼¼ç„¶ä¼°è®¡ (MLE)**:

$$
\hat{\theta}_n = \arg\max_{\theta} \frac{1}{n} \sum_{i=1}^n \log p(x_i; \theta)
$$

**æ¸è¿‘æ­£æ€æ€§**:

åœ¨æ­£åˆ™æ¡ä»¶ä¸‹ï¼š

$$
\sqrt{n}(\hat{\theta}_n - \theta_0) \xrightarrow{d} N(0, I(\theta_0)^{-1})
$$

å…¶ä¸­ $I(\theta)$ æ˜¯Fisherä¿¡æ¯çŸ©é˜µã€‚

---

### 3. ç½®ä¿¡åŒºé—´

**æ„é€ ç½®ä¿¡åŒºé—´**:

ç”±CLTï¼Œå¯¹äºæ ·æœ¬å‡å€¼ï¼š

$$
P\left(\mu - z_{\alpha/2} \frac{\sigma}{\sqrt{n}} \leq \bar{X}_n \leq \mu + z_{\alpha/2} \frac{\sigma}{\sqrt{n}}\right) \approx 1 - \alpha
$$

**95%ç½®ä¿¡åŒºé—´**:

$$
\bar{X}_n \pm 1.96 \frac{\sigma}{\sqrt{n}}
$$

**å®è·µä¸­**ï¼šç”¨æ ·æœ¬æ ‡å‡†å·® $s$ ä¼°è®¡ $\sigma$ã€‚

---

### 4. å‡è®¾æ£€éªŒ

**Zæ£€éªŒ**:

æ£€éªŒ $H_0: \mu = \mu_0$ vs $H_1: \mu \neq \mu_0$ã€‚

æ£€éªŒç»Ÿè®¡é‡ï¼š

$$
Z = \frac{\bar{X}_n - \mu_0}{\sigma / \sqrt{n}}
$$

åœ¨ $H_0$ ä¸‹ï¼Œ$Z \sim N(0, 1)$ï¼ˆæ¸è¿‘åœ°ï¼‰ã€‚

**æ‹’ç»åŸŸ**ï¼š$|Z| > z_{\alpha/2}$ã€‚

---

### 5. Bootstrapæ–¹æ³•

**BootstrapåŸç†**:

ä»æ ·æœ¬ $\{x_1, \ldots, x_n\}$ ä¸­æœ‰æ”¾å›åœ°æŠ½å– $n$ ä¸ªæ ·æœ¬ï¼Œé‡å¤ $B$ æ¬¡ã€‚

**Bootstrapåˆ†å¸ƒ**:

$$
\hat{F}_n^* \approx F
$$

**åº”ç”¨**ï¼šä¼°è®¡ç»Ÿè®¡é‡çš„åˆ†å¸ƒã€æ„é€ ç½®ä¿¡åŒºé—´ã€‚

---

## ğŸ”§ é«˜çº§ä¸»é¢˜

### 1. å¤§åå·®ç†è®º

**CramÃ©rå®šç†**:

è®¾ $X_1, X_2, \ldots$ ç‹¬ç«‹åŒåˆ†å¸ƒï¼ŒçŸ©æ¯å‡½æ•° $M(t) = E[e^{tX_i}]$ å­˜åœ¨ã€‚åˆ™å¯¹äº $a > \mu$ï¼š

$$
\lim_{n \to \infty} \frac{1}{n} \log P(\bar{X}_n \geq a) = -I(a)
$$

å…¶ä¸­ $I(a) = \sup_t \{ta - \log M(t)\}$ æ˜¯**é€Ÿç‡å‡½æ•°**ã€‚

**æ„ä¹‰**ï¼šæè¿°å°¾éƒ¨æ¦‚ç‡çš„æŒ‡æ•°è¡°å‡é€Ÿç‡ã€‚

---

### 2. å‡½æ•°å‹ä¸­å¿ƒæé™å®šç†

**Donskerå®šç†**:

ç»éªŒè¿‡ç¨‹ï¼š

$$
G_n(t) = \sqrt{n}(\hat{F}_n(t) - F(t))
$$

å…¶ä¸­ $\hat{F}_n$ æ˜¯ç»éªŒåˆ†å¸ƒå‡½æ•°ã€‚

**Donskerå®šç†**ï¼š

$$
G_n \Rightarrow B \circ F
$$

å…¶ä¸­ $B$ æ˜¯å¸ƒæœ—æ¡¥ï¼ˆBrownian bridgeï¼‰ã€‚

---

### 3. ä¾èµ–æ•°æ®çš„æé™å®šç†

**æ—¶é—´åºåˆ—**:

å¯¹äºå¼±ä¾èµ–çš„æ—¶é—´åºåˆ—ï¼ˆå¦‚æ··åˆåºåˆ—ï¼‰ï¼Œåœ¨é€‚å½“æ¡ä»¶ä¸‹ï¼ŒCLTä»ç„¶æˆç«‹ï¼Œä½†æ–¹å·®éœ€è¦è°ƒæ•´ï¼š

$$
\sqrt{n}(\bar{X}_n - \mu) \xrightarrow{d} N(0, \sigma^2 + 2\sum_{k=1}^\infty \gamma(k))
$$

å…¶ä¸­ $\gamma(k) = \text{Cov}(X_0, X_k)$ æ˜¯è‡ªåæ–¹å·®å‡½æ•°ã€‚

---

## ğŸ’» Pythonå®ç°

```python
import numpy as np
import matplotlib.pyplot as plt
from scipy import stats
from scipy.stats import norm, expon, uniform, chi2

# 1. å¤§æ•°å®šå¾‹æ¼”ç¤º
def law_of_large_numbers_demo():
    """å¤§æ•°å®šå¾‹æ¼”ç¤º"""
    print("=== å¤§æ•°å®šå¾‹ ===\n")
    
    # å‚æ•°
    mu = 5  # çœŸå®å‡å€¼
    n_max = 10000
    n_trials = 5
    
    plt.figure(figsize=(12, 5))
    
    # ä¸åŒåˆ†å¸ƒ
    distributions = {
        'Uniform(0, 10)': lambda n: np.random.uniform(0, 10, n),
        'Exponential(Î»=0.2)': lambda n: np.random.exponential(5, n),
        'Normal(5, 2)': lambda n: np.random.normal(5, 2, n)
    }
    
    for idx, (name, dist) in enumerate(distributions.items(), 1):
        plt.subplot(1, 3, idx)
        
        for _ in range(n_trials):
            samples = dist(n_max)
            cumulative_mean = np.cumsum(samples) / np.arange(1, n_max + 1)
            plt.plot(cumulative_mean, alpha=0.5, linewidth=0.8)
        
        plt.axhline(y=mu, color='r', linestyle='--', linewidth=2, label=f'True mean = {mu}')
        plt.xlabel('Sample size n')
        plt.ylabel('Sample mean')
        plt.title(f'LLN: {name}')
        plt.xscale('log')
        plt.grid(True, alpha=0.3)
        plt.legend()
    
    plt.tight_layout()
    # plt.show()
    
    print("å¤§æ•°å®šå¾‹ï¼šæ ·æœ¬å‡å€¼æ”¶æ•›åˆ°çœŸå®å‡å€¼\n")


# 2. ä¸­å¿ƒæé™å®šç†æ¼”ç¤º
def central_limit_theorem_demo():
    """ä¸­å¿ƒæé™å®šç†æ¼”ç¤º"""
    print("=== ä¸­å¿ƒæé™å®šç† ===\n")
    
    # ä¸åŒåˆ†å¸ƒ
    distributions = {
        'Uniform(0, 1)': (lambda n: np.random.uniform(0, 1, n), 0.5, 1/12),
        'Exponential(Î»=1)': (lambda n: np.random.exponential(1, n), 1, 1),
        'Chi-square(df=2)': (lambda n: np.random.chisquare(2, n), 2, 4)
    }
    
    sample_sizes = [1, 5, 30, 100]
    n_samples = 10000
    
    fig, axes = plt.subplots(len(distributions), len(sample_sizes), 
                             figsize=(16, 10))
    
    for i, (dist_name, (dist_func, mu, var)) in enumerate(distributions.items()):
        for j, n in enumerate(sample_sizes):
            # ç”Ÿæˆæ ·æœ¬å‡å€¼
            sample_means = np.array([
                np.mean(dist_func(n)) for _ in range(n_samples)
            ])
            
            # æ ‡å‡†åŒ–
            z_scores = (sample_means - mu) / np.sqrt(var / n)
            
            # ç»˜åˆ¶ç›´æ–¹å›¾
            ax = axes[i, j]
            ax.hist(z_scores, bins=50, density=True, alpha=0.7, 
                   edgecolor='black', label='Sample')
            
            # å åŠ æ ‡å‡†æ­£æ€åˆ†å¸ƒ
            x = np.linspace(-4, 4, 100)
            ax.plot(x, norm.pdf(x), 'r-', linewidth=2, label='N(0,1)')
            
            ax.set_xlim(-4, 4)
            ax.set_title(f'{dist_name}\nn={n}')
            ax.grid(True, alpha=0.3)
            
            if j == 0:
                ax.set_ylabel('Density')
            if i == len(distributions) - 1:
                ax.set_xlabel('Standardized mean')
            if i == 0 and j == 0:
                ax.legend()
    
    plt.tight_layout()
    # plt.show()
    
    print("ä¸­å¿ƒæé™å®šç†ï¼šæ ‡å‡†åŒ–çš„æ ·æœ¬å‡å€¼è¶‹äºæ ‡å‡†æ­£æ€åˆ†å¸ƒ\n")


# 3. æ”¶æ•›é€Ÿåº¦ - Berry-Esseen
def berry_esseen_demo():
    """Berry-Esseenå®šç†ï¼šæ”¶æ•›é€Ÿåº¦"""
    print("=== Berry-Esseenå®šç† ===\n")
    
    sample_sizes = [10, 30, 100, 300, 1000]
    n_samples = 10000
    
    # ä½¿ç”¨æŒ‡æ•°åˆ†å¸ƒ
    mu = 1
    sigma = 1
    
    max_errors = []
    theoretical_bounds = []
    
    for n in sample_sizes:
        # ç”Ÿæˆæ ·æœ¬å‡å€¼
        sample_means = np.array([
            np.mean(np.random.exponential(1, n)) for _ in range(n_samples)
        ])
        
        # æ ‡å‡†åŒ–
        z_scores = (sample_means - mu) / (sigma / np.sqrt(n))
        
        # è®¡ç®—ç»éªŒCDF
        z_sorted = np.sort(z_scores)
        empirical_cdf = np.arange(1, len(z_sorted) + 1) / len(z_sorted)
        
        # ç†è®ºCDF
        theoretical_cdf = norm.cdf(z_sorted)
        
        # æœ€å¤§è¯¯å·®
        max_error = np.max(np.abs(empirical_cdf - theoretical_cdf))
        max_errors.append(max_error)
        
        # Berry-Esseenç•Œ
        rho = 2  # E[|X - mu|^3] for Exp(1)
        C = 0.4748
        bound = C * rho / (sigma**3 * np.sqrt(n))
        theoretical_bounds.append(bound)
        
        print(f"n={n:4d}: æœ€å¤§è¯¯å·®={max_error:.4f}, Berry-Esseenç•Œ={bound:.4f}")
    
    # ç»˜å›¾
    plt.figure(figsize=(10, 6))
    plt.loglog(sample_sizes, max_errors, 'bo-', linewidth=2, 
              markersize=8, label='Observed error')
    plt.loglog(sample_sizes, theoretical_bounds, 'r--', linewidth=2, 
              label='Berry-Esseen bound')
    plt.loglog(sample_sizes, [1/np.sqrt(n) for n in sample_sizes], 
              'g:', linewidth=2, label='O(1/âˆšn)')
    plt.xlabel('Sample size n')
    plt.ylabel('Maximum error')
    plt.title('Berry-Esseen Theorem: Convergence Rate')
    plt.legend()
    plt.grid(True, alpha=0.3)
    # plt.show()
    
    print()


# 4. ç½®ä¿¡åŒºé—´
def confidence_interval_demo():
    """ç½®ä¿¡åŒºé—´æ¼”ç¤º"""
    print("=== ç½®ä¿¡åŒºé—´ ===\n")
    
    # çœŸå®å‚æ•°
    mu_true = 10
    sigma_true = 2
    
    # æ ·æœ¬å¤§å°
    n = 30
    
    # ç½®ä¿¡æ°´å¹³
    confidence_level = 0.95
    alpha = 1 - confidence_level
    z_critical = norm.ppf(1 - alpha/2)
    
    # ç”Ÿæˆå¤šä¸ªæ ·æœ¬å¹¶è®¡ç®—ç½®ä¿¡åŒºé—´
    n_experiments = 100
    coverage = 0
    
    plt.figure(figsize=(12, 8))
    
    for i in range(n_experiments):
        # ç”Ÿæˆæ ·æœ¬
        sample = np.random.normal(mu_true, sigma_true, n)
        
        # æ ·æœ¬ç»Ÿè®¡é‡
        x_bar = np.mean(sample)
        s = np.std(sample, ddof=1)
        
        # ç½®ä¿¡åŒºé—´
        margin = z_critical * s / np.sqrt(n)
        ci_lower = x_bar - margin
        ci_upper = x_bar + margin
        
        # æ£€æŸ¥æ˜¯å¦è¦†ç›–çœŸå®å€¼
        covers = ci_lower <= mu_true <= ci_upper
        coverage += covers
        
        # ç»˜åˆ¶
        color = 'green' if covers else 'red'
        plt.plot([ci_lower, ci_upper], [i, i], color=color, alpha=0.6)
        plt.plot(x_bar, i, 'o', color=color, markersize=3)
    
    # çœŸå®å‡å€¼
    plt.axvline(mu_true, color='blue', linestyle='--', linewidth=2, 
               label=f'True mean = {mu_true}')
    
    plt.xlabel('Value')
    plt.ylabel('Experiment')
    plt.title(f'95% Confidence Intervals\nCoverage: {coverage}/{n_experiments} = {coverage/n_experiments:.2%}')
    plt.legend()
    plt.grid(True, alpha=0.3, axis='x')
    # plt.show()
    
    print(f"ç†è®ºè¦†ç›–ç‡: {confidence_level:.2%}")
    print(f"å®é™…è¦†ç›–ç‡: {coverage/n_experiments:.2%}\n")


# 5. Bootstrapæ–¹æ³•
def bootstrap_demo():
    """Bootstrapæ–¹æ³•æ¼”ç¤º"""
    print("=== Bootstrapæ–¹æ³• ===\n")
    
    # åŸå§‹æ ·æœ¬
    np.random.seed(42)
    n = 50
    original_sample = np.random.exponential(2, n)
    
    # ç»Ÿè®¡é‡ï¼šä¸­ä½æ•°
    def statistic(data):
        return np.median(data)
    
    observed_stat = statistic(original_sample)
    
    # Bootstrap
    n_bootstrap = 10000
    bootstrap_stats = []
    
    for _ in range(n_bootstrap):
        # æœ‰æ”¾å›æŠ½æ ·
        bootstrap_sample = np.random.choice(original_sample, size=n, replace=True)
        bootstrap_stats.append(statistic(bootstrap_sample))
    
    bootstrap_stats = np.array(bootstrap_stats)
    
    # Bootstrapç½®ä¿¡åŒºé—´
    ci_lower = np.percentile(bootstrap_stats, 2.5)
    ci_upper = np.percentile(bootstrap_stats, 97.5)
    
    # ç»˜å›¾
    plt.figure(figsize=(12, 5))
    
    # åŸå§‹æ ·æœ¬
    plt.subplot(1, 2, 1)
    plt.hist(original_sample, bins=20, edgecolor='black', alpha=0.7)
    plt.axvline(observed_stat, color='r', linestyle='--', linewidth=2,
               label=f'Median = {observed_stat:.2f}')
    plt.xlabel('Value')
    plt.ylabel('Frequency')
    plt.title('Original Sample')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    # Bootstrapåˆ†å¸ƒ
    plt.subplot(1, 2, 2)
    plt.hist(bootstrap_stats, bins=50, edgecolor='black', alpha=0.7, density=True)
    plt.axvline(observed_stat, color='r', linestyle='--', linewidth=2,
               label=f'Observed = {observed_stat:.2f}')
    plt.axvline(ci_lower, color='g', linestyle=':', linewidth=2,
               label=f'95% CI: [{ci_lower:.2f}, {ci_upper:.2f}]')
    plt.axvline(ci_upper, color='g', linestyle=':', linewidth=2)
    plt.xlabel('Median')
    plt.ylabel('Density')
    plt.title('Bootstrap Distribution of Median')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    plt.tight_layout()
    # plt.show()
    
    print(f"è§‚æµ‹ä¸­ä½æ•°: {observed_stat:.2f}")
    print(f"Bootstrapå‡å€¼: {np.mean(bootstrap_stats):.2f}")
    print(f"Bootstrapæ ‡å‡†è¯¯: {np.std(bootstrap_stats):.2f}")
    print(f"95% Bootstrap CI: [{ci_lower:.2f}, {ci_upper:.2f}]\n")


# 6. Deltaæ–¹æ³•
def delta_method_demo():
    """Deltaæ–¹æ³•æ¼”ç¤º"""
    print("=== Deltaæ–¹æ³• ===\n")
    
    # å‚æ•°
    n = 100
    n_samples = 10000
    mu = 2
    sigma = 1
    
    # éçº¿æ€§å˜æ¢: g(x) = x^2
    def g(x):
        return x**2
    
    def g_prime(x):
        return 2*x
    
    # ç”Ÿæˆæ ·æœ¬å‡å€¼
    sample_means = np.array([
        np.mean(np.random.normal(mu, sigma, n)) for _ in range(n_samples)
    ])
    
    # å˜æ¢åçš„ç»Ÿè®¡é‡
    transformed = g(sample_means)
    
    # Deltaæ–¹æ³•çš„æ¸è¿‘åˆ†å¸ƒ
    asymptotic_mean = g(mu)
    asymptotic_var = (g_prime(mu)**2) * (sigma**2 / n)
    
    # ç»˜å›¾
    plt.figure(figsize=(12, 5))
    
    # æ ·æœ¬å‡å€¼åˆ†å¸ƒ
    plt.subplot(1, 2, 1)
    plt.hist(sample_means, bins=50, density=True, alpha=0.7, 
            edgecolor='black', label='Sample')
    x = np.linspace(sample_means.min(), sample_means.max(), 100)
    plt.plot(x, norm.pdf(x, mu, sigma/np.sqrt(n)), 'r-', 
            linewidth=2, label='Theoretical')
    plt.xlabel('Sample mean')
    plt.ylabel('Density')
    plt.title('Distribution of Sample Mean')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    # å˜æ¢åçš„åˆ†å¸ƒ
    plt.subplot(1, 2, 2)
    plt.hist(transformed, bins=50, density=True, alpha=0.7, 
            edgecolor='black', label='Sample')
    x = np.linspace(transformed.min(), transformed.max(), 100)
    plt.plot(x, norm.pdf(x, asymptotic_mean, np.sqrt(asymptotic_var)), 
            'r-', linewidth=2, label='Delta method')
    plt.xlabel('g(Sample mean)')
    plt.ylabel('Density')
    plt.title('Distribution of g(Sample Mean)\ng(x) = xÂ²')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    plt.tight_layout()
    # plt.show()
    
    print(f"å˜æ¢åçš„å‡å€¼:")
    print(f"  è§‚æµ‹: {np.mean(transformed):.4f}")
    print(f"  ç†è®º: {asymptotic_mean:.4f}")
    print(f"\nå˜æ¢åçš„æ–¹å·®:")
    print(f"  è§‚æµ‹: {np.var(transformed):.4f}")
    print(f"  Deltaæ–¹æ³•: {asymptotic_var:.4f}\n")


if __name__ == "__main__":
    print("=" * 60)
    print("æé™å®šç†ç¤ºä¾‹")
    print("=" * 60 + "\n")
    
    law_of_large_numbers_demo()
    central_limit_theorem_demo()
    berry_esseen_demo()
    confidence_interval_demo()
    bootstrap_demo()
    delta_method_demo()
    
    print("\næ‰€æœ‰ç¤ºä¾‹å®Œæˆï¼")
```

---

## ğŸ“š ç»ƒä¹ é¢˜

### ç»ƒä¹ 1ï¼šå¤§æ•°å®šå¾‹éªŒè¯

ä½¿ç”¨è’™ç‰¹å¡æ´›æ–¹æ³•ä¼°è®¡ $\pi$ï¼ŒéªŒè¯å¤§æ•°å®šå¾‹ã€‚

### ç»ƒä¹ 2ï¼šä¸­å¿ƒæé™å®šç†

å¯¹äº $\text{Uniform}(0, 1)$ åˆ†å¸ƒï¼ŒéªŒè¯ä¸åŒæ ·æœ¬å¤§å°ä¸‹çš„CLTã€‚

### ç»ƒä¹ 3ï¼šç½®ä¿¡åŒºé—´

æ„é€ æ€»ä½“å‡å€¼çš„95%ç½®ä¿¡åŒºé—´ï¼ŒéªŒè¯è¦†ç›–ç‡ã€‚

### ç»ƒä¹ 4ï¼šBootstrap

ä½¿ç”¨Bootstrapæ–¹æ³•ä¼°è®¡æ ·æœ¬ä¸­ä½æ•°çš„æ ‡å‡†è¯¯å’Œç½®ä¿¡åŒºé—´ã€‚

---

## ğŸ“ ç›¸å…³è¯¾ç¨‹

| å¤§å­¦ | è¯¾ç¨‹ |
|------|------|
| **MIT** | 18.650 - Statistics for Applications |
| **Stanford** | STATS200 - Introduction to Statistical Inference |
| **UC Berkeley** | STAT134 - Concepts of Probability |
| **CMU** | 36-705 - Intermediate Statistics |

---

## ğŸ“– å‚è€ƒæ–‡çŒ®

1. **Billingsley, P. (1995)**. *Probability and Measure*. Wiley.

2. **Durrett, R. (2019)**. *Probability: Theory and Examples*. Cambridge University Press.

3. **Van der Vaart, A. W. (1998)**. *Asymptotic Statistics*. Cambridge University Press.

4. **Casella & Berger (2002)**. *Statistical Inference*. Duxbury Press.

5. **Efron & Tibshirani (1994)**. *An Introduction to the Bootstrap*. Chapman & Hall.

---

*æœ€åæ›´æ–°ï¼š2025å¹´10æœˆ*:
