# æœ€ä¼˜ä¼ è¾“ç†è®º (Optimal Transport Theory)

> **Moving Probability Distributions Optimally**
>
> æ¦‚ç‡åˆ†å¸ƒçš„æœ€ä¼˜ç§»åŠ¨

---

## ç›®å½•

- [æœ€ä¼˜ä¼ è¾“ç†è®º (Optimal Transport Theory)](#æœ€ä¼˜ä¼ è¾“ç†è®º-optimal-transport-theory)
  - [ç›®å½•](#ç›®å½•)
  - [ğŸ“‹ æ ¸å¿ƒæ€æƒ³](#-æ ¸å¿ƒæ€æƒ³)
  - [ğŸ¯ Mongeé—®é¢˜](#-mongeé—®é¢˜)
    - [1. ç»å…¸Mongeé—®é¢˜](#1-ç»å…¸mongeé—®é¢˜)
    - [2. Mongeé—®é¢˜çš„å›°éš¾](#2-mongeé—®é¢˜çš„å›°éš¾)
  - [ğŸ“Š Kantorovichæ¾å¼›](#-kantorovichæ¾å¼›)
    - [1. Kantoroviché—®é¢˜](#1-kantoroviché—®é¢˜)
    - [2. å¯¹å¶é—®é¢˜](#2-å¯¹å¶é—®é¢˜)
    - [3. Kantorovich-Rubinsteinå®šç†](#3-kantorovich-rubinsteinå®šç†)
  - [ğŸ”¬ Wassersteinè·ç¦»](#-wassersteinè·ç¦»)
    - [1. Wasserstein-pè·ç¦»](#1-wasserstein-pè·ç¦»)
    - [2. Wasserstein-1è·ç¦»](#2-wasserstein-1è·ç¦»)
    - [3. Wasserstein-2è·ç¦»](#3-wasserstein-2è·ç¦»)
  - [ğŸ’¡ æœ€ä¼˜ä¼ è¾“æ˜ å°„](#-æœ€ä¼˜ä¼ è¾“æ˜ å°„)
    - [1. Brenierå®šç†](#1-brenierå®šç†)
    - [2. å‡¸åŠ¿å‡½æ•°](#2-å‡¸åŠ¿å‡½æ•°)
    - [3. McCannæ’å€¼](#3-mccannæ’å€¼)
  - [ğŸ¨ Wassersteinæ¢¯åº¦æµ](#-wassersteinæ¢¯åº¦æµ)
    - [1. æ¦‚ç‡æµ‹åº¦ç©ºé—´ä¸Šçš„æ¢¯åº¦æµ](#1-æ¦‚ç‡æµ‹åº¦ç©ºé—´ä¸Šçš„æ¢¯åº¦æµ)
    - [2. JKOæ ¼å¼](#2-jkoæ ¼å¼)
    - [3. åå¾®åˆ†æ–¹ç¨‹ä¸æ¢¯åº¦æµ](#3-åå¾®åˆ†æ–¹ç¨‹ä¸æ¢¯åº¦æµ)
  - [ğŸ”§ è®¡ç®—æ–¹æ³•](#-è®¡ç®—æ–¹æ³•)
    - [1. Sinkhornç®—æ³•](#1-sinkhornç®—æ³•)
    - [2. ç†µæ­£åˆ™åŒ–](#2-ç†µæ­£åˆ™åŒ–)
    - [3. ç¦»æ•£æœ€ä¼˜ä¼ è¾“](#3-ç¦»æ•£æœ€ä¼˜ä¼ è¾“)
  - [ğŸ’» Pythonå®ç°](#-pythonå®ç°)
  - [ğŸ“ åœ¨AIä¸­çš„åº”ç”¨](#-åœ¨aiä¸­çš„åº”ç”¨)
    - [1. Wasserstein GAN](#1-wasserstein-gan)
    - [2. åŸŸé€‚åº”](#2-åŸŸé€‚åº”)
    - [3. ç”Ÿæˆæ¨¡å‹è¯„ä¼°](#3-ç”Ÿæˆæ¨¡å‹è¯„ä¼°)
  - [ğŸ“š ç»ƒä¹ é¢˜](#-ç»ƒä¹ é¢˜)
  - [ğŸ“ ç›¸å…³è¯¾ç¨‹](#-ç›¸å…³è¯¾ç¨‹)
  - [ğŸ“– å‚è€ƒæ–‡çŒ®](#-å‚è€ƒæ–‡çŒ®)

---

## ğŸ“‹ æ ¸å¿ƒæ€æƒ³

**æœ€ä¼˜ä¼ è¾“ç†è®º**ç ”ç©¶å¦‚ä½•ä»¥æœ€å°ä»£ä»·å°†ä¸€ä¸ªæ¦‚ç‡åˆ†å¸ƒè½¬æ¢ä¸ºå¦ä¸€ä¸ªã€‚

**æ ¸å¿ƒé—®é¢˜**:

```text
ç»™å®šä¸¤ä¸ªæ¦‚ç‡åˆ†å¸ƒ Î¼ å’Œ Î½ï¼Œå¦‚ä½•ä»¥æœ€ä¼˜æ–¹å¼å°† Î¼ è½¬æ¢ä¸º Î½ï¼Ÿ

å…³é”®è¦ç´ :
â”œâ”€ æºåˆ†å¸ƒ: Î¼ (åˆå§‹åˆ†å¸ƒ)
â”œâ”€ ç›®æ ‡åˆ†å¸ƒ: Î½ (ç›®æ ‡åˆ†å¸ƒ)
â”œâ”€ ä»£ä»·å‡½æ•°: c(x, y) (ä»xç§»åŠ¨åˆ°yçš„ä»£ä»·)
â””â”€ ä¼ è¾“æ–¹æ¡ˆ: Ï€ æˆ– T (å¦‚ä½•ç§»åŠ¨)

åº”ç”¨:
â”œâ”€ æœºå™¨å­¦ä¹ : Wasserstein GAN, åŸŸé€‚åº”
â”œâ”€ è®¡ç®—æœºè§†è§‰: å›¾åƒå¤„ç†, å½¢çŠ¶åŒ¹é…
â”œâ”€ ç»æµå­¦: èµ„æºåˆ†é…
â””â”€ ç‰©ç†å­¦: æµä½“åŠ›å­¦, çƒ­ä¼ å¯¼
```

---

## ğŸ¯ Mongeé—®é¢˜

### 1. ç»å…¸Mongeé—®é¢˜

**é—®é¢˜** (Monge, 1781):

ç»™å®šä¸¤ä¸ªæ¦‚ç‡æµ‹åº¦ $\mu, \nu$ åœ¨ $\mathbb{R}^d$ ä¸Šï¼Œä»¥åŠä»£ä»·å‡½æ•° $c: \mathbb{R}^d \times \mathbb{R}^d \to [0, \infty)$ã€‚

æ‰¾ä¼ è¾“æ˜ å°„ $T: \mathbb{R}^d \to \mathbb{R}^d$ ä½¿å¾—ï¼š

$$
T_\# \mu = \nu
$$

å³ $\mu(T^{-1}(B)) = \nu(B)$ å¯¹æ‰€æœ‰å¯æµ‹é›† $B$ã€‚

**ç›®æ ‡**: æœ€å°åŒ–æ€»ä»£ä»·

$$
\min_{T: T_\# \mu = \nu} \int_{\mathbb{R}^d} c(x, T(x)) d\mu(x)
$$

---

**ä¾‹ 1.1 (ä¸€ç»´æƒ…å†µ)**:

è®¾ $\mu, \nu$ æ˜¯ $\mathbb{R}$ ä¸Šçš„æ¦‚ç‡æµ‹åº¦ï¼Œ$c(x, y) = |x - y|$ã€‚

**æœ€ä¼˜ä¼ è¾“æ˜ å°„**: $T(x) = F_\nu^{-1}(F_\mu(x))$

å…¶ä¸­ $F_\mu, F_\nu$ æ˜¯ç´¯ç§¯åˆ†å¸ƒå‡½æ•°ã€‚

---

### 2. Mongeé—®é¢˜çš„å›°éš¾

**é—®é¢˜**:

1. **å­˜åœ¨æ€§**: ä¼ è¾“æ˜ å°„ $T$ å¯èƒ½ä¸å­˜åœ¨
   - ä¾‹å¦‚: $\mu = \delta_0$ (ç‚¹è´¨é‡), $\nu = \frac{1}{2}(\delta_{-1} + \delta_1)$

2. **å”¯ä¸€æ€§**: å³ä½¿å­˜åœ¨ï¼Œä¹Ÿå¯èƒ½ä¸å”¯ä¸€

3. **éå‡¸æ€§**: å¯è¡Œé›†ä¸æ˜¯å‡¸é›†

---

## ğŸ“Š Kantorovichæ¾å¼›

### 1. Kantoroviché—®é¢˜

**Kantorovichæ¾å¼›** (1942):

ä¸è¦æ±‚ä¼ è¾“ç”±æ˜ å°„ç»™å‡ºï¼Œè€Œæ˜¯è€ƒè™‘**ä¼ è¾“è®¡åˆ’** $\pi \in \Pi(\mu, \nu)$ï¼Œå…¶ä¸­

$$
\Pi(\mu, \nu) = \{\pi \in \mathcal{P}(\mathbb{R}^d \times \mathbb{R}^d): \pi_1 = \mu, \pi_2 = \nu\}
$$

è¿™é‡Œ $\pi_1, \pi_2$ æ˜¯è¾¹ç¼˜åˆ†å¸ƒã€‚

**Kantoroviché—®é¢˜**:

$$
\min_{\pi \in \Pi(\mu, \nu)} \int_{\mathbb{R}^d \times \mathbb{R}^d} c(x, y) d\pi(x, y)
$$

---

**ä¼˜åŠ¿**:

1. **å­˜åœ¨æ€§**: åœ¨æ¸©å’Œæ¡ä»¶ä¸‹ï¼Œæœ€ä¼˜ $\pi$ æ€»æ˜¯å­˜åœ¨
2. **å‡¸æ€§**: $\Pi(\mu, \nu)$ æ˜¯å‡¸é›†
3. **åŒ…å«Monge**: å¦‚æœ $T$ æ˜¯Mongeæœ€ä¼˜ï¼Œåˆ™ $\pi = (id \times T)_\# \mu$ æ˜¯Kantorovichæœ€ä¼˜

---

### 2. å¯¹å¶é—®é¢˜

**Kantorovichå¯¹å¶**:

$$
\sup_{\phi, \psi} \left\{\int \phi d\mu + \int \psi d\nu: \phi(x) + \psi(y) \leq c(x, y)\right\}
$$

**å®šç† 2.1 (å¼ºå¯¹å¶æ€§)**:

åœ¨æ¸©å’Œæ¡ä»¶ä¸‹ï¼Œ

$$
\min_{\pi \in \Pi(\mu, \nu)} \int c d\pi = \sup_{\phi, \psi} \left\{\int \phi d\mu + \int \psi d\nu: \phi \oplus \psi \leq c\right\}
$$

---

**c-å˜æ¢**:

å¯¹äº $\phi: \mathbb{R}^d \to \mathbb{R}$ï¼Œå®šä¹‰ **c-å˜æ¢**:

$$
\phi^c(y) = \inf_{x} \{c(x, y) - \phi(x)\}
$$

**æ€§è´¨**: $(\phi^c)^c \geq \phi$ï¼Œä¸” $\phi^c \oplus \phi \leq c$ã€‚

---

### 3. Kantorovich-Rubinsteinå®šç†

**å®šç† 2.2 (Kantorovich-Rubinstein)**:

å¯¹äº $c(x, y) = \|x - y\|$ï¼Œ

$$
W_1(\mu, \nu) = \sup_{\|f\|_L \leq 1} \left\{\int f d\mu - \int f d\nu\right\}
$$

å…¶ä¸­ $\|f\|_L = \sup_{x \neq y} \frac{|f(x) - f(y)|}{\|x - y\|}$ æ˜¯Lipschitzå¸¸æ•°ã€‚

**æ„ä¹‰**: Wasserstein-1è·ç¦»å¯ä»¥é€šè¿‡Lipschitzå‡½æ•°è®¡ç®—ã€‚

---

## ğŸ”¬ Wassersteinè·ç¦»

### 1. Wasserstein-pè·ç¦»

**å®šä¹‰ 3.1 (Wasserstein-pè·ç¦»)**:

å¯¹äº $p \geq 1$ï¼Œ

$$
W_p(\mu, \nu) = \left(\inf_{\pi \in \Pi(\mu, \nu)} \int \|x - y\|^p d\pi(x, y)\right)^{1/p}
$$

**æ€§è´¨**:

1. **åº¦é‡**: $W_p$ æ˜¯ $\mathcal{P}_p(\mathbb{R}^d)$ ä¸Šçš„åº¦é‡
2. **å¼±æ”¶æ•›**: $W_p(\mu_n, \mu) \to 0 \Leftrightarrow \mu_n \rightharpoonup \mu$ ä¸” $\int \|x\|^p d\mu_n \to \int \|x\|^p d\mu$

---

### 2. Wasserstein-1è·ç¦»

**Earth Mover's Distance (EMD)**:

$$
W_1(\mu, \nu) = \inf_{\pi \in \Pi(\mu, \nu)} \int \|x - y\| d\pi(x, y)
$$

**å¯¹å¶å½¢å¼** (Kantorovich-Rubinstein):

$$
W_1(\mu, \nu) = \sup_{\|f\|_L \leq 1} \left|\int f d\mu - \int f d\nu\right|
$$

---

**ä¾‹ 3.1 (ç¦»æ•£åˆ†å¸ƒ)**:

è®¾ $\mu = \sum_{i=1}^n a_i \delta_{x_i}$, $\nu = \sum_{j=1}^m b_j \delta_{y_j}$ï¼Œå…¶ä¸­ $\sum a_i = \sum b_j = 1$ã€‚

$$
W_1(\mu, \nu) = \min_{\pi_{ij}} \sum_{i,j} \pi_{ij} \|x_i - y_j\|
$$

çº¦æŸ: $\sum_j \pi_{ij} = a_i$, $\sum_i \pi_{ij} = b_j$, $\pi_{ij} \geq 0$ã€‚

è¿™æ˜¯**çº¿æ€§è§„åˆ’**é—®é¢˜ã€‚

---

### 3. Wasserstein-2è·ç¦»

**å®šä¹‰**:

$$
W_2(\mu, \nu) = \left(\inf_{\pi \in \Pi(\mu, \nu)} \int \|x - y\|^2 d\pi(x, y)\right)^{1/2}
$$

**ç‰¹æ®Šæ€§è´¨**:

- ä¸**é»æ›¼å‡ ä½•**è”ç³»ç´§å¯†
- å­˜åœ¨å”¯ä¸€æœ€ä¼˜ä¼ è¾“æ˜ å°„ (åœ¨ç»å¯¹è¿ç»­æƒ…å†µä¸‹)

---

**å®šç† 3.1 (Wasserstein-2çš„æ€§è´¨)**:

1. **ä¸‰è§’ä¸ç­‰å¼**: $W_2(\mu, \nu) \leq W_2(\mu, \rho) + W_2(\rho, \nu)$

2. **ä½ç§»å‡¸æ€§**: æ³›å‡½ $F[\mu] = \int f d\mu$ åœ¨ $W_2$ æ„ä¹‰ä¸‹æ˜¯å‡¸çš„ï¼Œå¦‚æœ $f$ æ˜¯å‡¸çš„

3. **æµ‹åœ°çº¿**: $\mu_t = ((1-t)id + tT)_\# \mu$ æ˜¯ $\mu$ åˆ° $\nu = T_\# \mu$ çš„æµ‹åœ°çº¿

---

## ğŸ’¡ æœ€ä¼˜ä¼ è¾“æ˜ å°„

### 1. Brenierå®šç†

**å®šç† 4.1 (Brenierå®šç†)**:

è®¾ $\mu, \nu$ æ˜¯ $\mathbb{R}^d$ ä¸Šçš„æ¦‚ç‡æµ‹åº¦ï¼Œ$\mu$ ç»å¯¹è¿ç»­ã€‚

åˆ™å­˜åœ¨å”¯ä¸€çš„å‡¸å‡½æ•° $\phi: \mathbb{R}^d \to \mathbb{R}$ (å·®ä¸€ä¸ªå¸¸æ•°) ä½¿å¾—ï¼š

$$
T(x) = \nabla \phi(x)
$$

æ˜¯ä» $\mu$ åˆ° $\nu$ çš„æœ€ä¼˜ä¼ è¾“æ˜ å°„ (å¯¹äºä»£ä»· $c(x, y) = \|x - y\|^2$)ã€‚

**æ„ä¹‰**: æœ€ä¼˜ä¼ è¾“æ˜ å°„æ˜¯æ¢¯åº¦æ˜ å°„ï¼

---

**è¯æ˜æ€è·¯**:

1. **å­˜åœ¨æ€§**: é€šè¿‡å¯¹å¶é—®é¢˜
2. **å”¯ä¸€æ€§**: åˆ©ç”¨ä¸¥æ ¼å‡¸æ€§
3. **æ¢¯åº¦ç»“æ„**: åˆ©ç”¨æœ€ä¼˜æ€§æ¡ä»¶

---

### 2. å‡¸åŠ¿å‡½æ•°

**Monge-AmpÃ¨reæ–¹ç¨‹**:

è®¾ $\mu = \rho dx$, $\nu = \sigma dy$ï¼Œ$T = \nabla \phi$ã€‚

åˆ™ $T_\# \mu = \nu$ ç­‰ä»·äºï¼š

$$
\rho(x) = \sigma(\nabla \phi(x)) \det(D^2 \phi(x))
$$

è¿™æ˜¯**Monge-AmpÃ¨reæ–¹ç¨‹**ã€‚

---

### 3. McCannæ’å€¼

**å®šä¹‰ 4.2 (ä½ç§»æ’å€¼)**:

è®¾ $T$ æ˜¯ä» $\mu$ åˆ° $\nu$ çš„æœ€ä¼˜ä¼ è¾“æ˜ å°„ã€‚

**McCannæ’å€¼**:

$$
\mu_t = ((1-t)id + tT)_\# \mu, \quad t \in [0, 1]
$$

**æ€§è´¨**:

- $\mu_0 = \mu$, $\mu_1 = \nu$
- $W_2(\mu_t, \mu_s) = |t - s| W_2(\mu, \nu)$
- $\mu_t$ æ˜¯ $\mu$ åˆ° $\nu$ çš„æµ‹åœ°çº¿

---

## ğŸ¨ Wassersteinæ¢¯åº¦æµ

### 1. æ¦‚ç‡æµ‹åº¦ç©ºé—´ä¸Šçš„æ¢¯åº¦æµ

**æ³›å‡½çš„æ¢¯åº¦æµ**:

è€ƒè™‘æ³›å‡½ $F: \mathcal{P}_2(\mathbb{R}^d) \to \mathbb{R}$ã€‚

**Wassersteinæ¢¯åº¦æµ**:

$$
\frac{\partial \mu_t}{\partial t} = -\nabla_{W_2} F[\mu_t]
$$

**å½¢å¼åŒ–**:

$$
\mu_t = \lim_{h \to 0} \frac{1}{h} \arg\min_{\nu} \left\{W_2^2(\mu_t, \nu) + 2h F[\nu]\right\}
$$

---

### 2. JKOæ ¼å¼

**Jordan-Kinderlehrer-Otto (JKO) æ ¼å¼**:

ç¦»æ•£åŒ–Wassersteinæ¢¯åº¦æµï¼š

$$
\mu^{k+1} = \arg\min_{\nu} \left\{\frac{1}{2\tau} W_2^2(\mu^k, \nu) + F[\nu]\right\}
$$

å…¶ä¸­ $\tau > 0$ æ˜¯æ—¶é—´æ­¥é•¿ã€‚

**æ”¶æ•›æ€§**: å½“ $\tau \to 0$ æ—¶ï¼Œ$\mu^k$ æ”¶æ•›åˆ°æ¢¯åº¦æµã€‚

---

### 3. åå¾®åˆ†æ–¹ç¨‹ä¸æ¢¯åº¦æµ

**ä¾‹ 5.1 (çƒ­æ–¹ç¨‹)**:

$$
\frac{\partial \rho}{\partial t} = \Delta \rho
$$

æ˜¯æ³›å‡½ $F[\rho] = \int \rho \log \rho dx$ (ç†µ) çš„Wassersteinæ¢¯åº¦æµã€‚

---

**ä¾‹ 5.2 (Fokker-Planckæ–¹ç¨‹)**:

$$
\frac{\partial \rho}{\partial t} = \Delta \rho + \nabla \cdot (\rho \nabla V)
$$

æ˜¯æ³›å‡½ $F[\rho] = \int (\rho \log \rho + \rho V) dx$ çš„Wassersteinæ¢¯åº¦æµã€‚

---

**ä¾‹ 5.3 (å¤šå­”ä»‹è´¨æ–¹ç¨‹)**:

$$
\frac{\partial \rho}{\partial t} = \Delta \rho^m
$$

æ˜¯æ³›å‡½ $F[\rho] = \int \frac{\rho^m}{m-1} dx$ çš„Wassersteinæ¢¯åº¦æµã€‚

---

## ğŸ”§ è®¡ç®—æ–¹æ³•

### 1. Sinkhornç®—æ³•

**ç†µæ­£åˆ™åŒ–æœ€ä¼˜ä¼ è¾“**:

$$
\min_{\pi \in \Pi(\mu, \nu)} \left\{\int c d\pi + \epsilon H(\pi | \mu \otimes \nu)\right\}
$$

å…¶ä¸­ $H(\pi | \mu \otimes \nu) = \int \log \frac{d\pi}{d(\mu \otimes \nu)} d\pi$ æ˜¯ç›¸å¯¹ç†µã€‚

---

**Sinkhornç®—æ³•**:

å¯¹äºç¦»æ•£åˆ†å¸ƒ $\mu = \sum a_i \delta_{x_i}$, $\nu = \sum b_j \delta_{y_j}$ï¼š

1. åˆå§‹åŒ– $u^{(0)} = \mathbf{1}$, $v^{(0)} = \mathbf{1}$
2. è¿­ä»£:
   $$
   u^{(k+1)}_i = \frac{a_i}{\sum_j K_{ij} v^{(k)}_j}
   $$
   $$
   v^{(k+1)}_j = \frac{b_j}{\sum_i K_{ij} u^{(k+1)}_i}
   $$

å…¶ä¸­ $K_{ij} = e^{-c(x_i, y_j)/\epsilon}$ã€‚

**æ”¶æ•›æ€§**: æŒ‡æ•°æ”¶æ•›åˆ°æœ€ä¼˜è§£ã€‚

---

### 2. ç†µæ­£åˆ™åŒ–

**ä¼˜åŠ¿**:

1. **å¹³æ»‘æ€§**: æœ€ä¼˜ $\pi$ ç»å¯¹è¿ç»­
2. **è®¡ç®—æ•ˆç‡**: Sinkhornç®—æ³•å¿«é€Ÿ
3. **å¯å¾®æ€§**: å¯¹å‚æ•°å¯å¾®

**åŠ£åŠ¿**:

- å¼•å…¥åå·® (bias)
- éœ€è¦é€‰æ‹© $\epsilon$

---

### 3. ç¦»æ•£æœ€ä¼˜ä¼ è¾“

**çº¿æ€§è§„åˆ’**:

$$
\min_{\pi} \sum_{i,j} c_{ij} \pi_{ij}
$$

çº¦æŸ: $\sum_j \pi_{ij} = a_i$, $\sum_i \pi_{ij} = b_j$, $\pi_{ij} \geq 0$ã€‚

**æ±‚è§£å™¨**: ç½‘ç»œå•çº¯å½¢æ³•ã€å†…ç‚¹æ³•ã€‚

---

## ğŸ’» Pythonå®ç°

```python
import numpy as np
import matplotlib.pyplot as plt
from scipy.optimize import linprog
from scipy.spatial.distance import cdist

# 1. ç²¾ç¡®æœ€ä¼˜ä¼ è¾“ (çº¿æ€§è§„åˆ’)
def optimal_transport_lp(a, b, C):
    """
    ç²¾ç¡®æœ€ä¼˜ä¼ è¾“ (çº¿æ€§è§„åˆ’)

    a: æºåˆ†å¸ƒ (n,)
    b: ç›®æ ‡åˆ†å¸ƒ (m,)
    C: ä»£ä»·çŸ©é˜µ (n, m)
    """
    n, m = C.shape

    # çº¿æ€§è§„åˆ’: min c^T x, s.t. A_eq x = b_eq, x >= 0
    c = C.flatten()

    # çº¦æŸ: è¡Œå’Œ = a, åˆ—å’Œ = b
    A_eq = np.zeros((n + m, n * m))
    b_eq = np.concatenate([a, b])

    for i in range(n):
        A_eq[i, i*m:(i+1)*m] = 1

    for j in range(m):
        A_eq[n+j, j::m] = 1

    result = linprog(c, A_eq=A_eq, b_eq=b_eq, method='highs')

    if result.success:
        return result.x.reshape(n, m), result.fun
    else:
        raise ValueError("Optimization failed")


# 2. Sinkhornç®—æ³•
def sinkhorn(a, b, C, epsilon=0.1, max_iter=1000, tol=1e-9):
    """
    Sinkhornç®—æ³• (ç†µæ­£åˆ™åŒ–æœ€ä¼˜ä¼ è¾“)

    a: æºåˆ†å¸ƒ (n,)
    b: ç›®æ ‡åˆ†å¸ƒ (m,)
    C: ä»£ä»·çŸ©é˜µ (n, m)
    epsilon: ç†µæ­£åˆ™åŒ–å‚æ•°
    """
    n, m = C.shape

    # K = exp(-C/epsilon)
    K = np.exp(-C / epsilon)

    # åˆå§‹åŒ–
    u = np.ones(n)
    v = np.ones(m)

    for _ in range(max_iter):
        u_old = u.copy()

        # æ›´æ–° u
        u = a / (K @ v)

        # æ›´æ–° v
        v = b / (K.T @ u)

        # æ£€æŸ¥æ”¶æ•›
        if np.linalg.norm(u - u_old) < tol:
            break

    # è®¡ç®—ä¼ è¾“è®¡åˆ’
    pi = np.diag(u) @ K @ np.diag(v)

    # è®¡ç®—ä»£ä»·
    cost = np.sum(pi * C)

    return pi, cost


# 3. Wassersteinè·ç¦»è®¡ç®—
def wasserstein_distance(X, Y, a=None, b=None, p=2, method='sinkhorn', **kwargs):
    """
    è®¡ç®—Wassersteinè·ç¦»

    X: æºæ ·æœ¬ (n, d)
    Y: ç›®æ ‡æ ·æœ¬ (m, d)
    a: æºæƒé‡ (n,), é»˜è®¤å‡åŒ€
    b: ç›®æ ‡æƒé‡ (m,), é»˜è®¤å‡åŒ€
    p: Wasserstein-pè·ç¦»
    method: 'lp' æˆ– 'sinkhorn'
    """
    n, m = len(X), len(Y)

    if a is None:
        a = np.ones(n) / n
    if b is None:
        b = np.ones(m) / m

    # è®¡ç®—ä»£ä»·çŸ©é˜µ
    C = cdist(X, Y, metric='euclidean') ** p

    # æ±‚è§£æœ€ä¼˜ä¼ è¾“
    if method == 'lp':
        pi, cost = optimal_transport_lp(a, b, C)
    elif method == 'sinkhorn':
        pi, cost = sinkhorn(a, b, C, **kwargs)
    else:
        raise ValueError(f"Unknown method: {method}")

    return cost ** (1/p), pi


# 4. Wassersteiné‡å¿ƒ
def wasserstein_barycenter(distributions, weights=None, epsilon=0.1, max_iter=100):
    """
    è®¡ç®—Wassersteiné‡å¿ƒ

    distributions: åˆ†å¸ƒåˆ—è¡¨ [(X_1, a_1), (X_2, a_2), ...]
    weights: æƒé‡ (k,)
    """
    k = len(distributions)

    if weights is None:
        weights = np.ones(k) / k

    # åˆå§‹åŒ–é‡å¿ƒ (ä½¿ç”¨ç¬¬ä¸€ä¸ªåˆ†å¸ƒ)
    X_bar, a_bar = distributions[0]

    for _ in range(max_iter):
        # è®¡ç®—åˆ°æ¯ä¸ªåˆ†å¸ƒçš„ä¼ è¾“è®¡åˆ’
        plans = []
        for (X, a), w in zip(distributions, weights):
            _, pi = wasserstein_distance(X_bar, X, a_bar, a, method='sinkhorn', epsilon=epsilon)
            plans.append(pi)

        # æ›´æ–°é‡å¿ƒ
        # (ç®€åŒ–ç‰ˆ: è¿™é‡Œåº”è¯¥ç”¨æ›´å¤æ‚çš„ç®—æ³•)
        break

    return X_bar, a_bar


# 5. å¯è§†åŒ–
def visualize_optimal_transport():
    """å¯è§†åŒ–æœ€ä¼˜ä¼ è¾“"""
    np.random.seed(42)

    # ç”Ÿæˆä¸¤ä¸ª2Dåˆ†å¸ƒ
    n, m = 20, 30
    X = np.random.randn(n, 2)
    Y = np.random.randn(m, 2) + np.array([3, 0])

    a = np.ones(n) / n
    b = np.ones(m) / m

    # è®¡ç®—æœ€ä¼˜ä¼ è¾“
    C = cdist(X, Y, metric='euclidean') ** 2
    pi_lp, cost_lp = optimal_transport_lp(a, b, C)
    pi_sink, cost_sink = sinkhorn(a, b, C, epsilon=0.1)

    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))

    # ç²¾ç¡®æœ€ä¼˜ä¼ è¾“
    ax1.scatter(X[:, 0], X[:, 1], c='blue', s=100, alpha=0.6, label='Source')
    ax1.scatter(Y[:, 0], Y[:, 1], c='red', s=100, alpha=0.6, label='Target')

    for i in range(n):
        for j in range(m):
            if pi_lp[i, j] > 1e-6:
                ax1.plot([X[i, 0], Y[j, 0]], [X[i, 1], Y[j, 1]],
                        'k-', alpha=pi_lp[i, j] * n * 2, linewidth=1)

    ax1.set_title(f'Exact OT (LP)\nCost: {cost_lp:.4f}')
    ax1.legend()
    ax1.grid(True, alpha=0.3)

    # Sinkhornç®—æ³•
    ax2.scatter(X[:, 0], X[:, 1], c='blue', s=100, alpha=0.6, label='Source')
    ax2.scatter(Y[:, 0], Y[:, 1], c='red', s=100, alpha=0.6, label='Target')

    for i in range(n):
        for j in range(m):
            if pi_sink[i, j] > 1e-6:
                ax2.plot([X[i, 0], Y[j, 0]], [X[i, 1], Y[j, 1]],
                        'k-', alpha=pi_sink[i, j] * n * 2, linewidth=1)

    ax2.set_title(f'Sinkhorn OT (Îµ=0.1)\nCost: {cost_sink:.4f}')
    ax2.legend()
    ax2.grid(True, alpha=0.3)

    plt.tight_layout()
    # plt.show()


# 6. Wasserstein GANæŸå¤±
def wasserstein_gan_loss(real_samples, fake_samples, critic):
    """
    Wasserstein GANæŸå¤±

    real_samples: çœŸå®æ ·æœ¬
    fake_samples: ç”Ÿæˆæ ·æœ¬
    critic: åˆ¤åˆ«å™¨ (1-Lipschitzå‡½æ•°)
    """
    # W1è·ç¦»çš„å¯¹å¶å½¢å¼
    real_scores = critic(real_samples)
    fake_scores = critic(fake_samples)

    # Wassersteinè·ç¦»ä¼°è®¡
    w_distance = np.mean(real_scores) - np.mean(fake_scores)

    return w_distance


def demo_optimal_transport():
    """æœ€ä¼˜ä¼ è¾“ç¤ºä¾‹"""
    print("=" * 60)
    print("æœ€ä¼˜ä¼ è¾“ç†è®ºç¤ºä¾‹")
    print("=" * 60 + "\n")

    # 1. ä¸€ç»´æƒ…å†µ
    print("1. ä¸€ç»´Wassersteinè·ç¦»")
    X = np.array([[0], [1], [2]])
    Y = np.array([[0.5], [1.5], [2.5]])

    w_dist, _ = wasserstein_distance(X, Y, p=1, method='lp')
    print(f"   W1è·ç¦»: {w_dist:.4f}")

    # 2. äºŒç»´æƒ…å†µ
    print("\n2. äºŒç»´Wassersteinè·ç¦»")
    np.random.seed(42)
    X = np.random.randn(10, 2)
    Y = np.random.randn(10, 2) + 2

    w2_lp, _ = wasserstein_distance(X, Y, p=2, method='lp')
    w2_sink, _ = wasserstein_distance(X, Y, p=2, method='sinkhorn', epsilon=0.1)

    print(f"   W2è·ç¦» (LP): {w2_lp:.4f}")
    print(f"   W2è·ç¦» (Sinkhorn): {w2_sink:.4f}")

    # 3. å¯è§†åŒ–
    print("\n3. ç”Ÿæˆå¯è§†åŒ–...")
    visualize_optimal_transport()

    print("\næ‰€æœ‰ç¤ºä¾‹å®Œæˆï¼")


if __name__ == "__main__":
    demo_optimal_transport()
```

---

## ğŸ“ åœ¨AIä¸­çš„åº”ç”¨

### 1. Wasserstein GAN

**é—®é¢˜**: ä¼ ç»ŸGANè®­ç»ƒä¸ç¨³å®šã€‚

**Wasserstein GAN (WGAN)**:

**ç”Ÿæˆå™¨æŸå¤±**:

$$
\min_G -\mathbb{E}_{z \sim p_z}[D(G(z))]
$$

**åˆ¤åˆ«å™¨æŸå¤±**:

$$
\max_{D: \|D\|_L \leq 1} \mathbb{E}_{x \sim p_{data}}[D(x)] - \mathbb{E}_{z \sim p_z}[D(G(z))]
$$

**ä¼˜åŠ¿**:

- è®­ç»ƒç¨³å®š
- æœ‰æ„ä¹‰çš„æŸå¤±æ›²çº¿
- ä¸éœ€è¦å¹³è¡¡ç”Ÿæˆå™¨å’Œåˆ¤åˆ«å™¨

---

### 2. åŸŸé€‚åº”

**é—®é¢˜**: æºåŸŸå’Œç›®æ ‡åŸŸåˆ†å¸ƒä¸åŒã€‚

**æœ€ä¼˜ä¼ è¾“åŸŸé€‚åº”**:

æœ€å°åŒ–æºåŸŸå’Œç›®æ ‡åŸŸä¹‹é—´çš„Wassersteinè·ç¦»ï¼š

$$
\min_\theta W_2(p_{source}^{(f_\theta)}, p_{target}^{(f_\theta)})
$$

å…¶ä¸­ $f_\theta$ æ˜¯ç‰¹å¾æå–å™¨ã€‚

---

### 3. ç”Ÿæˆæ¨¡å‹è¯„ä¼°

**FrÃ©chet Inception Distance (FID)**:

$$
\text{FID} = \|\mu_r - \mu_g\|^2 + \text{Tr}(\Sigma_r + \Sigma_g - 2(\Sigma_r \Sigma_g)^{1/2})
$$

è¿™æ˜¯é«˜æ–¯åˆ†å¸ƒä¹‹é—´çš„Wasserstein-2è·ç¦»ã€‚

---

### 4. æœ€ä¼˜ä¼ è¾“åœ¨å›¾åƒå¤„ç†ä¸­çš„åº”ç”¨

**é¢œè‰²è¿ç§»**ï¼š

ä½¿ç”¨æœ€ä¼˜ä¼ è¾“å°†ä¸€å¹…å›¾åƒçš„é¢œè‰²åˆ†å¸ƒè¿ç§»åˆ°å¦ä¸€å¹…å›¾åƒï¼š

$$
T^* = \arg\min_T \int c(x, T(x)) d\mu(x) \quad \text{s.t.} \quad T_\# \mu = \nu
$$

å…¶ä¸­ $\mu$ æ˜¯æºå›¾åƒçš„é¢œè‰²åˆ†å¸ƒï¼Œ$\nu$ æ˜¯ç›®æ ‡é¢œè‰²åˆ†å¸ƒã€‚

**å›¾åƒä¿®å¤**ï¼š

ä½¿ç”¨æœ€ä¼˜ä¼ è¾“å¡«å……å›¾åƒç¼ºå¤±åŒºåŸŸï¼Œä¿æŒç»Ÿè®¡ä¸€è‡´æ€§ã€‚

**é£æ ¼è¿ç§»**ï¼š

å°†ä¸€å¹…å›¾åƒçš„é£æ ¼ï¼ˆçº¹ç†åˆ†å¸ƒï¼‰ä¼ è¾“åˆ°å¦ä¸€å¹…å›¾åƒï¼ŒåŒæ—¶ä¿æŒå†…å®¹ã€‚

**Pythonå®ç°ç¤ºä¾‹**ï¼š

```python
from scipy.spatial.distance import cdist
from scipy.optimize import linprog
import numpy as np

def optimal_transport_1d(source, target):
    """
    ä¸€ç»´æœ€ä¼˜ä¼ è¾“ï¼ˆç²¾ç¡®è§£ï¼‰

    å‚æ•°:
        source: æºåˆ†å¸ƒï¼ˆç›´æ–¹å›¾ï¼‰
        target: ç›®æ ‡åˆ†å¸ƒï¼ˆç›´æ–¹å›¾ï¼‰
    """
    n = len(source)
    m = len(target)

    # æˆæœ¬çŸ©é˜µï¼ˆL2è·ç¦»ï¼‰
    C = cdist(source.reshape(-1, 1), target.reshape(-1, 1))**2

    # çº¿æ€§è§„åˆ’ï¼šæœ€å°åŒ– <C, P>
    # çº¦æŸï¼šP 1 = source, P^T 1 = target
    c = C.flatten()

    # çº¦æŸçŸ©é˜µ
    A_eq = []
    b_eq = []

    # è¡Œçº¦æŸï¼šæ¯è¡Œå’Œä¸ºsource
    for i in range(n):
        row = np.zeros(n * m)
        row[i*m:(i+1)*m] = 1
        A_eq.append(row)
        b_eq.append(source[i])

    # åˆ—çº¦æŸï¼šæ¯åˆ—å’Œä¸ºtarget
    for j in range(m):
        col = np.zeros(n * m)
        col[j::m] = 1
        A_eq.append(col)
        b_eq.append(target[j])

    A_eq = np.array(A_eq)
    b_eq = np.array(b_eq)

    # æ±‚è§£
    result = linprog(c, A_eq=A_eq, b_eq=b_eq, method='highs')
    P = result.x.reshape(n, m)

    # è®¡ç®—Wassersteinè·ç¦»
    W2 = np.sum(P * C)

    return P, W2
```

---

### 5. æœ€ä¼˜ä¼ è¾“åœ¨å¼ºåŒ–å­¦ä¹ ä¸­çš„åº”ç”¨

**åˆ†å¸ƒå¼ºåŒ–å­¦ä¹ **ï¼š

åœ¨åˆ†å¸ƒå¼ºåŒ–å­¦ä¹ ä¸­ï¼Œå€¼å‡½æ•°ä¸å†æ˜¯æ ‡é‡ï¼Œè€Œæ˜¯åˆ†å¸ƒã€‚ä½¿ç”¨Wassersteinè·ç¦»æ¯”è¾ƒå€¼åˆ†å¸ƒï¼š

$$
Z(s, a) \sim \text{Value Distribution}
$$

**ç›®æ ‡**ï¼šæœ€å°åŒ–é¢„æµ‹åˆ†å¸ƒå’ŒçœŸå®åˆ†å¸ƒä¹‹é—´çš„Wassersteinè·ç¦»ã€‚

**ä¼˜åŠ¿**ï¼š

- **é£é™©æ•æ„Ÿ**ï¼šå¯ä»¥å»ºæ¨¡é£é™©åå¥½
- **ä¸ç¡®å®šæ€§é‡åŒ–**ï¼šåˆ†å¸ƒæä¾›ä¸ç¡®å®šæ€§ä¿¡æ¯
- **æ ·æœ¬æ•ˆç‡**ï¼šæ›´å¥½çš„æ ·æœ¬åˆ©ç”¨

**Pythonå®ç°ç¤ºä¾‹**ï¼š

```python
import torch
import torch.nn as nn

class DistributionalDQN(nn.Module):
    """åˆ†å¸ƒDQN"""
    def __init__(self, state_dim, action_dim, n_atoms=51, v_min=-10, v_max=10):
        super().__init__()
        self.n_atoms = n_atoms
        self.v_min = v_min
        self.v_max = v_max
        self.delta = (v_max - v_min) / (n_atoms - 1)

        self.network = nn.Sequential(
            nn.Linear(state_dim, 128),
            nn.ReLU(),
            nn.Linear(128, 128),
            nn.ReLU(),
            nn.Linear(128, action_dim * n_atoms)
        )

    def forward(self, state):
        logits = self.network(state)
        logits = logits.view(-1, self.action_dim, self.n_atoms)
        return torch.softmax(logits, dim=-1)

    def wasserstein_loss(self, pred_dist, target_dist, rewards, dones, gamma=0.99):
        """WassersteinæŸå¤±"""
        # æŠ•å½±ç›®æ ‡åˆ†å¸ƒ
        target_support = rewards + gamma * (1 - dones) * self.get_support()

        # è®¡ç®—Wassersteinè·ç¦»
        # è¿™é‡Œä½¿ç”¨ç®€åŒ–çš„1-Wassersteinè·ç¦»ï¼ˆç´¯ç§¯åˆ†å¸ƒå‡½æ•°å·®ï¼‰
        loss = 0
        for i in range(self.n_atoms):
            cdf_pred = torch.cumsum(pred_dist, dim=-1)
            cdf_target = torch.cumsum(target_dist, dim=-1)
            loss += torch.abs(cdf_pred - cdf_target).mean()

        return loss

    def get_support(self):
        """è·å–æ”¯æŒç‚¹"""
        return torch.linspace(self.v_min, self.v_max, self.n_atoms)
```

---

### 6. æœ€ä¼˜ä¼ è¾“åœ¨æ•°æ®å¢å¼ºä¸­çš„åº”ç”¨

**è¯­ä¹‰æ•°æ®å¢å¼º**ï¼š

ä½¿ç”¨æœ€ä¼˜ä¼ è¾“ç”Ÿæˆè¯­ä¹‰ä¸€è‡´çš„æ•°æ®å¢å¼ºæ ·æœ¬ï¼š

$$
\min_T \int c(x, T(x)) d\mu(x) + \lambda \mathcal{L}_{\text{task}}(T_\# \mu)
$$

å…¶ä¸­ $\mathcal{L}_{\text{task}}$ æ˜¯ä»»åŠ¡æŸå¤±ï¼ˆå¦‚åˆ†ç±»æŸå¤±ï¼‰ã€‚

**ä¼˜åŠ¿**ï¼š

- **ä¿æŒè¯­ä¹‰**ï¼šå¢å¼ºæ ·æœ¬ä¿æŒåŸå§‹è¯­ä¹‰
- **å¤šæ ·æ€§**ï¼šç”Ÿæˆå¤šæ ·åŒ–çš„è®­ç»ƒæ ·æœ¬
- **å¯æ§æ€§**ï¼šé€šè¿‡æˆæœ¬å‡½æ•°æ§åˆ¶å¢å¼ºç¨‹åº¦

**åº”ç”¨åœºæ™¯**ï¼š

- **å°æ ·æœ¬å­¦ä¹ **ï¼šåœ¨æ•°æ®ç¨€ç¼ºæ—¶ç”Ÿæˆæ›´å¤šæ ·æœ¬
- **åŸŸé€‚åº”**ï¼šç”Ÿæˆç›®æ ‡åŸŸé£æ ¼çš„æ ·æœ¬
- **å¯¹æŠ—è®­ç»ƒ**ï¼šç”Ÿæˆå¯¹æŠ—æ ·æœ¬

---

### 7. æœ€ä¼˜ä¼ è¾“åœ¨å…¬å¹³æœºå™¨å­¦ä¹ ä¸­çš„åº”ç”¨

**å…¬å¹³æ€§çº¦æŸ**ï¼š

ä½¿ç”¨æœ€ä¼˜ä¼ è¾“ç¡®ä¿ä¸åŒç¾¤ä½“çš„é¢„æµ‹åˆ†å¸ƒç›¸ä¼¼ï¼š

$$
\min_f \mathcal{L}(f) \quad \text{s.t.} \quad W_1(P_{Y|A=a}, P_{Y|A=b}) \leq \epsilon
$$

å…¶ä¸­ $A$ æ˜¯æ•æ„Ÿå±æ€§ï¼ˆå¦‚æ€§åˆ«ã€ç§æ—ï¼‰ï¼Œ$\epsilon$ æ˜¯å…¬å¹³æ€§å®¹å¿åº¦ã€‚

**ä¼˜åŠ¿**ï¼š

- **å½¢å¼åŒ–å…¬å¹³æ€§**ï¼šå°†å…¬å¹³æ€§è½¬åŒ–ä¸ºæ•°å­¦çº¦æŸ
- **å¯è§£é‡Šæ€§**ï¼šWassersteinè·ç¦»æœ‰æ˜ç¡®çš„å‡ ä½•æ„ä¹‰
- **çµæ´»æ€§**ï¼šå¯ä»¥æ§åˆ¶ä¸åŒå…¬å¹³æ€§å®šä¹‰

**å®ç°æ–¹æ³•**ï¼š

1. **åå¤„ç†**ï¼šè®­ç»ƒåè°ƒæ•´é¢„æµ‹åˆ†å¸ƒ
2. **è®­ç»ƒæ—¶çº¦æŸ**ï¼šåœ¨æŸå¤±å‡½æ•°ä¸­åŠ å…¥Wassersteinæƒ©ç½šé¡¹
3. **é¢„å¤„ç†**ï¼šä½¿ç”¨æœ€ä¼˜ä¼ è¾“é¢„å¤„ç†æ•°æ®

**Pythonå®ç°ç¤ºä¾‹**ï¼š

```python
def fair_classification_loss(predictions, labels, sensitive_attr, lambda_fair=0.1):
    """
    å…¬å¹³åˆ†ç±»æŸå¤±

    å‚æ•°:
        predictions: æ¨¡å‹é¢„æµ‹
        labels: çœŸå®æ ‡ç­¾
        sensitive_attr: æ•æ„Ÿå±æ€§
        lambda_fair: å…¬å¹³æ€§æƒé‡
    """
    # æ ‡å‡†åˆ†ç±»æŸå¤±
    classification_loss = F.cross_entropy(predictions, labels)

    # å…¬å¹³æ€§æŸå¤±ï¼ˆWassersteinè·ç¦»ï¼‰
    group_0 = predictions[sensitive_attr == 0]
    group_1 = predictions[sensitive_attr == 1]

    # è®¡ç®—é¢„æµ‹åˆ†å¸ƒ
    dist_0 = torch.softmax(group_0, dim=-1).mean(dim=0)
    dist_1 = torch.softmax(group_1, dim=-1).mean(dim=0)

    # Wasserstein-1è·ç¦»ï¼ˆç®€åŒ–ç‰ˆï¼šL1è·ç¦»ï¼‰
    wasserstein_dist = torch.abs(dist_0 - dist_1).sum()

    # æ€»æŸå¤±
    total_loss = classification_loss + lambda_fair * wasserstein_dist

    return total_loss
```

---

### 8. æœ€ä¼˜ä¼ è¾“åœ¨æ¨èç³»ç»Ÿä¸­çš„åº”ç”¨

**ç”¨æˆ·-ç‰©å“åˆ†å¸ƒå¯¹é½**ï¼š

ä½¿ç”¨æœ€ä¼˜ä¼ è¾“å¯¹é½ä¸åŒç”¨æˆ·ç¾¤ä½“çš„ç‰©å“åˆ†å¸ƒï¼Œæé«˜æ¨èå…¬å¹³æ€§ã€‚

**å†·å¯åŠ¨é—®é¢˜**ï¼š

å¯¹äºæ–°ç”¨æˆ·ï¼Œä½¿ç”¨æœ€ä¼˜ä¼ è¾“å°†ç›¸ä¼¼ç”¨æˆ·çš„åå¥½åˆ†å¸ƒä¼ è¾“è¿‡æ¥ã€‚

**å¤šæ ·æ€§æ¨è**ï¼š

ä½¿ç”¨æœ€ä¼˜ä¼ è¾“ç¡®ä¿æ¨èç»“æœçš„å¤šæ ·æ€§ï¼Œé¿å…æ¨èè¿‡äºé›†ä¸­ã€‚

**Pythonå®ç°ç¤ºä¾‹**ï¼š

```python
def optimal_transport_recommendation(user_embeddings, item_embeddings,
                                     user_distribution, item_distribution):
    """
    ä½¿ç”¨æœ€ä¼˜ä¼ è¾“è¿›è¡Œæ¨è

    å‚æ•°:
        user_embeddings: ç”¨æˆ·åµŒå…¥
        item_embeddings: ç‰©å“åµŒå…¥
        user_distribution: ç”¨æˆ·åˆ†å¸ƒï¼ˆåå¥½ï¼‰
        item_distribution: ç‰©å“åˆ†å¸ƒï¼ˆæµè¡Œåº¦ï¼‰
    """
    # è®¡ç®—æˆæœ¬çŸ©é˜µï¼ˆç”¨æˆ·-ç‰©å“ç›¸ä¼¼åº¦ï¼‰
    cost_matrix = cdist(user_embeddings, item_embeddings, metric='cosine')

    # æ±‚è§£æœ€ä¼˜ä¼ è¾“
    from scipy.optimize import linprog

    # è¿™é‡Œä½¿ç”¨Sinkhornç®—æ³•ï¼ˆæ›´é«˜æ•ˆï¼‰
    from ot import sinkhorn

    # ç†µæ­£åˆ™åŒ–æœ€ä¼˜ä¼ è¾“
    transport_plan = sinkhorn(user_distribution, item_distribution,
                              cost_matrix, reg=0.1)

    # æ¨èï¼šé€‰æ‹©ä¼ è¾“è´¨é‡é«˜çš„ç‰©å“
    recommendations = transport_plan.argmax(axis=1)

    return recommendations, transport_plan
```

---

## ğŸ“š ç»ƒä¹ é¢˜

**ç»ƒä¹ 1**: è¯æ˜Wasserstein-1è·ç¦»æ»¡è¶³ä¸‰è§’ä¸ç­‰å¼ã€‚

**ç»ƒä¹ 2**: å®ç°ä¸€ç»´æƒ…å†µçš„ç²¾ç¡®æœ€ä¼˜ä¼ è¾“ã€‚

**ç»ƒä¹ 3**: æ¯”è¾ƒSinkhornç®—æ³•åœ¨ä¸åŒ $\epsilon$ ä¸‹çš„æ€§èƒ½ã€‚

**ç»ƒä¹ 4**: å®ç°ç®€å•çš„Wasserstein GANã€‚

---

## ğŸ“ ç›¸å…³è¯¾ç¨‹

| å¤§å­¦ | è¯¾ç¨‹ |
|------|------|
| **Stanford** | STATS385 - Theories of Deep Learning |
| **MIT** | 18.S096 - Topics in Mathematics with Applications |
| **ENS Paris** | Optimal Transport (Villani) |
| **UC Berkeley** | STAT260 - Mean Field Asymptotics |

---

## ğŸ“– å‚è€ƒæ–‡çŒ®

1. **Villani, C. (2009)**. *Optimal Transport: Old and New*. Springer.

2. **Santambrogio, F. (2015)**. *Optimal Transport for Applied Mathematicians*. BirkhÃ¤user.

3. **PeyrÃ©, G. & Cuturi, M. (2019)**. *Computational Optimal Transport*. Foundations and Trends in Machine Learning.

4. **Arjovsky, M. et al. (2017)**. *Wasserstein Generative Adversarial Networks*. ICML.

5. **Cuturi, M. (2013)**. *Sinkhorn Distances: Lightspeed Computation of Optimal Transport*. NIPS.

---

*æœ€åæ›´æ–°ï¼š2025å¹´10æœˆ*-
