# 04-统计物理与数学 | Statistical Physics & Mathematics

## 目录

- [04-统计物理与数学 | Statistical Physics \& Mathematics](#04-统计物理与数学--statistical-physics--mathematics)
  - [目录](#目录)
  - [1. 主题简介 | Topic Introduction](#1-主题简介--topic-introduction)
  - [2. 统计力学基础 | Fundamentals of Statistical Mechanics](#2-统计力学基础--fundamentals-of-statistical-mechanics)
    - [2.1 系综理论 | Ensemble Theory](#21-系综理论--ensemble-theory)
    - [2.2 配分函数 | Partition Functions](#22-配分函数--partition-functions)
    - [2.3 熵与信息论 | Entropy \& Information Theory](#23-熵与信息论--entropy--information-theory)
  - [3. 随机过程与马尔可夫链 | Stochastic Processes \& Markov Chains](#3-随机过程与马尔可夫链--stochastic-processes--markov-chains)
    - [3.1 随机过程基础 | Stochastic Process Fundamentals](#31-随机过程基础--stochastic-process-fundamentals)
    - [3.2 马尔可夫链 | Markov Chains](#32-马尔可夫链--markov-chains)
    - [3.3 扩散过程 | Diffusion Processes](#33-扩散过程--diffusion-processes)
  - [4. 相变理论与临界现象 | Phase Transitions \& Critical Phenomena](#4-相变理论与临界现象--phase-transitions--critical-phenomena)
    - [4.1 相变分类 | Classification of Phase Transitions](#41-相变分类--classification-of-phase-transitions)
    - [4.2 临界指数 | Critical Exponents](#42-临界指数--critical-exponents)
    - [4.3 重正化群理论 | Renormalization Group Theory](#43-重正化群理论--renormalization-group-theory)
  - [5. 复杂系统与非线性动力学 | Complex Systems \& Nonlinear Dynamics](#5-复杂系统与非线性动力学--complex-systems--nonlinear-dynamics)
    - [5.1 混沌理论 | Chaos Theory](#51-混沌理论--chaos-theory)
    - [5.2 分形几何 | Fractal Geometry](#52-分形几何--fractal-geometry)
    - [5.3 自组织临界性 | Self-Organized Criticality](#53-自组织临界性--self-organized-criticality)
  - [6. 相关性与本地跳转 | Relevance \& Local Navigation](#6-相关性与本地跳转--relevance--local-navigation)
  - [进度日志 | Progress Log](#进度日志--progress-log)

---

## 1. 主题简介 | Topic Introduction

统计物理与数学的交叉融合是现代物理学的重要分支，从玻尔兹曼的统计力学到普里戈金的耗散结构理论，从随机过程到相变理论，这一领域不仅揭示了宏观现象的微观本质，也为数学提供了丰富的应用场景和理论动机。

The intersection of statistical physics and mathematics is an important branch of modern physics, from Boltzmann's statistical mechanics to Prigogine's dissipative structure theory, from stochastic processes to phase transition theory. This field not only reveals the microscopic essence of macroscopic phenomena but also provides rich application scenarios and theoretical motivations for mathematics.

---

## 2. 统计力学基础 | Fundamentals of Statistical Mechanics

### 2.1 系综理论 | Ensemble Theory

**系综定义：**

```lean
-- 系综
structure ensemble :=
  (microstates : set microstate)
  (probability_distribution : microstate → ℝ)
  (normalization : ∑ᵢ pᵢ = 1)

-- 微正则系综
def microcanonical_ensemble (E : ℝ) (ΔE : ℝ) : ensemble :=
  { microstates = {μ | E - ΔE ≤ energy μ ≤ E + ΔE}
    probability_distribution = uniform_distribution
    normalization = ∑ᵢ pᵢ = 1 }

-- 正则系综
def canonical_ensemble (β : ℝ) : ensemble :=
  { microstates = all_microstates
    probability_distribution = λ μ, exp(-β * energy μ) / Z(β)
    normalization = ∑ᵢ pᵢ = 1 }
```

**玻尔兹曼分布：**

```lean
-- 玻尔兹曼分布
def boltzmann_distribution (E : ℝ) (β : ℝ) : ℝ :=
  exp(-β * E) / Z(β)

-- 配分函数
def partition_function (β : ℝ) : ℝ :=
  ∑ᵢ exp(-β * Eᵢ)

-- 自由能
def free_energy (β : ℝ) : ℝ :=
  -log(Z(β)) / β
```

### 2.2 配分函数 | Partition Functions

**经典配分函数：**

```lean
-- 经典配分函数
def classical_partition_function (β : ℝ) (H : phase_space → ℝ) : ℝ :=
  ∫∫ exp(-β * H(q,p)) dq dp / (h^(3N) * N!)

-- 量子配分函数
def quantum_partition_function (β : ℝ) (H : operator) : ℝ :=
  tr(exp(-β * H))

-- 巨正则配分函数
def grand_canonical_partition_function (β μ : ℝ) (H N : operator) : ℝ :=
  tr(exp(-β * (H - μ * N)))
```

**配分函数的性质：**

```python
import numpy as np
from scipy.integrate import quad

def harmonic_oscillator_partition_function(beta, omega):
    """一维谐振子的配分函数"""
    # 经典配分函数
    def integrand(p, q):
        H = 0.5 * (p**2 + omega**2 * q**2)
        return np.exp(-beta * H)
    
    # 积分范围
    p_range = (-np.inf, np.inf)
    q_range = (-np.inf, np.inf)
    
    # 计算配分函数
    Z_p, _ = quad(lambda p: quad(lambda q: integrand(p, q), *q_range)[0], *p_range)
    Z = Z_p / (2 * np.pi * hbar)  # 除以普朗克常数
    
    return Z

def quantum_harmonic_oscillator_partition_function(beta, omega):
    """量子谐振子的配分函数"""
    # 量子配分函数：Z = ∑ₙ exp(-βℏω(n+1/2))
    # 这是一个几何级数
    x = np.exp(-beta * hbar * omega)
    Z = x**(1/2) / (1 - x)
    
    return Z

# 计算热力学量
def thermodynamic_quantities(beta, omega):
    """计算热力学量"""
    Z = quantum_harmonic_oscillator_partition_function(beta, omega)
    
    # 内能
    E = -np.log(Z) / beta
    
    # 熵
    S = beta * E + np.log(Z)
    
    # 自由能
    F = -np.log(Z) / beta
    
    return E, S, F
```

### 2.3 熵与信息论 | Entropy & Information Theory

**玻尔兹曼熵：**

```lean
-- 玻尔兹曼熵
def boltzmann_entropy (W : ℕ) : ℝ :=
  k_B * log(W)
  where W is the number of microstates

-- 吉布斯熵
def gibbs_entropy (p : probability_distribution) : ℝ :=
  -k_B * ∑ᵢ pᵢ * log(pᵢ)

-- 信息熵
def information_entropy (p : probability_distribution) : ℝ :=
  -∑ᵢ pᵢ * log₂(pᵢ)
```

**熵的性质：**

```python
def entropy_analysis():
    """熵的性质分析"""
    import numpy as np
    
    # 等概率分布
    n_states = 10
    uniform_p = np.ones(n_states) / n_states
    uniform_entropy = -np.sum(uniform_p * np.log2(uniform_p))
    print(f"等概率分布熵: {uniform_entropy}")
    
    # 确定性分布
    deterministic_p = np.zeros(n_states)
    deterministic_p[0] = 1.0
    deterministic_entropy = -np.sum(deterministic_p * np.log2(deterministic_p + 1e-10))
    print(f"确定性分布熵: {deterministic_entropy}")
    
    # 最大熵原理
    def max_entropy_constraint(constraints):
        """在约束条件下最大化熵"""
        from scipy.optimize import minimize
        
        def objective(p):
            return np.sum(p * np.log2(p + 1e-10))
        
        # 约束条件
        cons = ({'type': 'eq', 'fun': lambda p: np.sum(p) - 1})  # 归一化
        for constraint in constraints:
            cons.append({'type': 'eq', 'fun': constraint})
        
        # 初始猜测
        p0 = np.ones(n_states) / n_states
        
        # 优化
        result = minimize(objective, p0, constraints=cons, method='SLSQP')
        return result.x
    
    return uniform_entropy, deterministic_entropy
```

---

## 3. 随机过程与马尔可夫链 | Stochastic Processes & Markov Chains

### 3.1 随机过程基础 | Stochastic Process Fundamentals

**随机过程定义：**

```lean
-- 随机过程
def stochastic_process (T : Type) (Ω : probability_space) (X : T → Ω → ℝ) : Prop :=
  ∀ t : T, X t is random_variable

-- 布朗运动
def brownian_motion (t : ℝ) : random_variable :=
  normal_distribution 0 (√t)

-- 维纳过程
def wiener_process (t : ℝ) : random_variable :=
  brownian_motion t
```

**随机微分方程：**

```lean
-- 随机微分方程
def stochastic_differential_equation (X : ℝ → ℝ) (μ σ : ℝ → ℝ → ℝ) : Prop :=
  dX(t) = μ(t, X(t)) dt + σ(t, X(t)) dW(t)

-- 伊藤积分
def ito_integral (f : ℝ → ℝ) (W : wiener_process) (a b : ℝ) : ℝ :=
  ∫[a,b] f(t) dW(t)
```

### 3.2 马尔可夫链 | Markov Chains

**马尔可夫性质：**

```lean
-- 马尔可夫链
structure markov_chain :=
  (states : set state)
  (transition_matrix : state → state → ℝ)
  (initial_distribution : state → ℝ)
  (markov_property : ∀ s₁ s₂ s₃, P(s₃|s₁,s₂) = P(s₃|s₂))

-- 转移概率
def transition_probability (P : transition_matrix) (i j : state) : ℝ :=
  P i j

-- 平稳分布
def stationary_distribution (P : transition_matrix) (π : state → ℝ) : Prop :=
  π = π * P
```

**马尔可夫链分析：**

```python
import numpy as np
from scipy.linalg import eig

class MarkovChain:
    def __init__(self, transition_matrix):
        self.P = np.array(transition_matrix)
        self.n_states = len(transition_matrix)
    
    def stationary_distribution(self):
        """计算平稳分布"""
        # 求解 π = πP
        # 等价于求解 (P^T - I)π = 0
        A = self.P.T - np.eye(self.n_states)
        A[-1] = np.ones(self.n_states)  # 添加归一化约束
        
        b = np.zeros(self.n_states)
        b[-1] = 1
        
        pi = np.linalg.solve(A, b)
        return pi
    
    def hitting_time(self, target_state):
        """计算到达目标状态的期望时间"""
        # 求解线性方程组
        A = np.eye(self.n_states) - self.P
        A[target_state, :] = 0
        A[target_state, target_state] = 1
        
        b = np.ones(self.n_states)
        b[target_state] = 0
        
        hitting_times = np.linalg.solve(A, b)
        return hitting_times
    
    def simulate(self, n_steps, initial_state=0):
        """模拟马尔可夫链"""
        states = [initial_state]
        current_state = initial_state
        
        for _ in range(n_steps):
            # 根据转移概率选择下一个状态
            next_state = np.random.choice(
                self.n_states, 
                p=self.P[current_state]
            )
            states.append(next_state)
            current_state = next_state
        
        return states

# 示例：简单随机游走
def simple_random_walk(n_states=5):
    """简单随机游走"""
    P = np.zeros((n_states, n_states))
    
    for i in range(n_states):
        if i == 0:
            P[i, i] = 1  # 吸收边界
        elif i == n_states - 1:
            P[i, i] = 1  # 吸收边界
        else:
            P[i, i-1] = 0.5  # 向左
            P[i, i+1] = 0.5  # 向右
    
    return MarkovChain(P)
```

### 3.3 扩散过程 | Diffusion Processes

**扩散方程：**

```lean
-- 扩散方程
def diffusion_equation (u : ℝ → ℝ → ℝ) (D : ℝ) : Prop :=
  ∂u/∂t = D * ∂²u/∂x²

-- 福克-普朗克方程
def fokker_planck_equation (P : ℝ → ℝ → ℝ) (μ σ : ℝ → ℝ) : Prop :=
  ∂P/∂t = -∂/∂x(μ(x)P) + (1/2) * ∂²/∂x²(σ²(x)P)
```

**数值求解：**

```python
def solve_diffusion_equation(D, L, T, nx, nt):
    """求解扩散方程"""
    dx = L / (nx - 1)
    dt = T / (nt - 1)
    
    # 稳定性条件
    r = D * dt / (dx**2)
    if r > 0.5:
        raise ValueError("CFL条件不满足")
    
    # 初始化
    x = np.linspace(0, L, nx)
    u = np.zeros((nt, nx))
    
    # 初始条件：高斯分布
    u[0, :] = np.exp(-(x - L/2)**2 / (2 * 0.1**2))
    
    # 时间推进
    for n in range(nt - 1):
        for i in range(1, nx - 1):
            u[n+1, i] = u[n, i] + r * (u[n, i+1] - 2*u[n, i] + u[n, i-1])
    
    return x, u

def solve_fokker_planck_equation(mu, sigma, L, T, nx, nt):
    """求解福克-普朗克方程"""
    dx = L / (nx - 1)
    dt = T / (nt - 1)
    
    x = np.linspace(0, L, nx)
    P = np.zeros((nt, nx))
    
    # 初始条件
    P[0, :] = np.exp(-(x - L/2)**2 / (2 * 0.1**2))
    P[0, :] /= np.sum(P[0, :]) * dx  # 归一化
    
    # 时间推进
    for n in range(nt - 1):
        for i in range(1, nx - 1):
            # 漂移项
            drift = mu(x[i]) * (P[n, i+1] - P[n, i-1]) / (2 * dx)
            
            # 扩散项
            diffusion = 0.5 * sigma(x[i])**2 * (P[n, i+1] - 2*P[n, i] + P[n, i-1]) / (dx**2)
            
            P[n+1, i] = P[n, i] + dt * (-drift + diffusion)
    
    return x, P
```

---

## 4. 相变理论与临界现象 | Phase Transitions & Critical Phenomena

### 4.1 相变分类 | Classification of Phase Transitions

**相变类型：**

```lean
-- 一级相变
def first_order_phase_transition (T : ℝ) : Prop :=
  ∃ discontinuity in entropy S(T) ∧
  ∃ latent_heat L = T * ΔS

-- 二级相变
def second_order_phase_transition (T : ℝ) : Prop :=
  S(T) is continuous ∧
  ∃ discontinuity in ∂S/∂T

-- 连续相变
def continuous_phase_transition (T : ℝ) : Prop :=
  all_derivatives_continuous ∧
  ∃ critical_exponents
```

**朗道理论：**

```lean
-- 朗道自由能
def landau_free_energy (η : ℝ) (T : ℝ) : ℝ :=
  a(T) * η² + b(T) * η⁴ + c(T) * η⁶ + ...

-- 序参量
def order_parameter (T : ℝ) : ℝ :=
  if T < T_c then √(-a(T)/(2*b(T))) else 0
```

### 4.2 临界指数 | Critical Exponents

**临界指数定义：**

```lean
-- 比热临界指数
def specific_heat_exponent (T : ℝ) (T_c : ℝ) : ℝ :=
  C(T) ~ |T - T_c|^(-α)

-- 序参量临界指数
def order_parameter_exponent (T : ℝ) (T_c : ℝ) : ℝ :=
  η(T) ~ (T_c - T)^β

-- 磁化率临界指数
def susceptibility_exponent (T : ℝ) (T_c : ℝ) : ℝ :=
  χ(T) ~ |T - T_c|^(-γ)

-- 关联长度临界指数
def correlation_length_exponent (T : ℝ) (T_c : ℝ) : ℝ :=
  ξ(T) ~ |T - T_c|^(-ν)
```

**标度关系：**

```python
def critical_exponents_analysis():
    """临界指数分析"""
    # 二维伊辛模型的临界指数
    ising_2d_exponents = {
        'alpha': 0,      # 对数发散
        'beta': 1/8,     # 序参量
        'gamma': 7/4,    # 磁化率
        'nu': 1,         # 关联长度
        'eta': 1/4,      # 关联函数
        'delta': 15      # 临界等温线
    }
    
    # 验证标度关系
    def scaling_relations(exponents):
        alpha = exponents['alpha']
        beta = exponents['beta']
        gamma = exponents['gamma']
        nu = exponents['nu']
        eta = exponents['eta']
        delta = exponents['delta']
        
        # Rushbrooke关系
        rushbrooke = alpha + 2*beta + gamma
        print(f"Rushbrooke关系: {rushbrooke} ≈ 2")
        
        # Widom关系
        widom = gamma - beta*(delta - 1)
        print(f"Widom关系: {widom} ≈ 0")
        
        # Fisher关系
        fisher = gamma - nu*(2 - eta)
        print(f"Fisher关系: {fisher} ≈ 0")
        
        # Josephson关系
        josephson = nu*d - 2 + alpha
        print(f"Josephson关系: {josephson} ≈ 0 (d=2)")
    
    scaling_relations(ising_2d_exponents)
    return ising_2d_exponents
```

### 4.3 重正化群理论 | Renormalization Group Theory

**重正化群变换：**

```lean
-- 重正化群变换
def renormalization_group_transform (H : hamiltonian) (b : ℝ) : hamiltonian :=
  coarse_graining H b ∧
  rescale H b ∧
  renormalize_couplings H b

-- 不动点
def fixed_point (H : hamiltonian) : Prop :=
  renormalization_group_transform H b = H

-- 临界不动点
def critical_fixed_point (H : hamiltonian) : Prop :=
  fixed_point H ∧
  ∃ relevant_operators
```

**重正化群计算：**

```python
def renormalization_group_ising_1d():
    """一维伊辛模型的重正化群"""
    def rg_transformation(K):
        """重正化群变换：K' = (1/2) * log(cosh(2K))"""
        return 0.5 * np.log(np.cosh(2*K))
    
    def find_fixed_points():
        """寻找不动点"""
        K_values = np.linspace(0, 2, 1000)
        K_prime = [rg_transformation(K) for K in K_values]
        
        # 寻找不动点
        fixed_points = []
        for i in range(len(K_values) - 1):
            if (K_values[i] - K_prime[i]) * (K_values[i+1] - K_prime[i+1]) < 0:
                # 线性插值找到精确的不动点
                K_fixed = K_values[i] + (K_values[i] - K_prime[i]) * (K_values[i+1] - K_values[i]) / ((K_values[i] - K_prime[i]) - (K_values[i+1] - K_prime[i+1]))
                fixed_points.append(K_fixed)
        
        return fixed_points
    
    def calculate_critical_exponents(K_star):
        """计算临界指数"""
        # 在不动点附近线性化
        epsilon = 1e-6
        K_plus = K_star + epsilon
        K_minus = K_star - epsilon
        
        K_plus_prime = rg_transformation(K_plus)
        K_minus_prime = rg_transformation(K_minus)
        
        # 计算重正化群本征值
        lambda_RG = (K_plus_prime - K_minus_prime) / (2 * epsilon)
        
        # 计算临界指数
        nu = np.log(2) / np.log(lambda_RG)
        
        return nu
    
    fixed_points = find_fixed_points()
    print(f"不动点: {fixed_points}")
    
    if len(fixed_points) > 0:
        nu = calculate_critical_exponents(fixed_points[0])
        print(f"关联长度临界指数 ν = {nu}")
    
    return fixed_points
```

---

## 5. 复杂系统与非线性动力学 | Complex Systems & Nonlinear Dynamics

### 5.1 混沌理论 | Chaos Theory

**混沌系统：**

```lean
-- 混沌映射
def logistic_map (r : ℝ) (x : ℝ) : ℝ :=
  r * x * (1 - x)

-- 李雅普诺夫指数
def lyapunov_exponent (f : ℝ → ℝ) (x₀ : ℝ) (n : ℕ) : ℝ :=
  (1/n) * ∑ᵢ log|f'(xᵢ)|
  where xᵢ = fⁱ(x₀)

-- 混沌定义
def chaotic_system (f : ℝ → ℝ) : Prop :=
  ∃ positive_lyapunov_exponent ∧
  ∃ dense_orbit ∧
  ∃ sensitive_dependence
```

**混沌分析：**

```python
def chaos_analysis():
    """混沌系统分析"""
    def logistic_map(r, x):
        return r * x * (1 - x)
    
    def lyapunov_exponent(r, x0, n_iter=1000):
        """计算李雅普诺夫指数"""
        x = x0
        lyap_sum = 0
        
        for _ in range(n_iter):
            # 计算导数
            derivative = r * (1 - 2*x)
            lyap_sum += np.log(abs(derivative))
            x = logistic_map(r, x)
        
        return lyap_sum / n_iter
    
    def bifurcation_diagram():
        """分岔图"""
        r_values = np.linspace(2.5, 4.0, 1000)
        x_values = []
        r_plot = []
        
        for r in r_values:
            # 迭代到稳定状态
            x = 0.5
            for _ in range(1000):
                x = logistic_map(r, x)
            
            # 记录接下来的100个点
            for _ in range(100):
                x = logistic_map(r, x)
                x_values.append(x)
                r_plot.append(r)
        
        return r_plot, x_values
    
    # 计算李雅普诺夫指数
    r_range = np.linspace(2.5, 4.0, 100)
    lyap_exponents = [lyapunov_exponent(r, 0.5) for r in r_range]
    
    # 生成分岔图
    r_plot, x_plot = bifurcation_diagram()
    
    return r_range, lyap_exponents, r_plot, x_plot
```

### 5.2 分形几何 | Fractal Geometry

**分形维数：**

```lean
-- 豪斯多夫维数
def hausdorff_dimension (F : set) : ℝ :=
  inf{d | H^d(F) = 0}
  where H^d is the d-dimensional Hausdorff measure

-- 盒维数
def box_dimension (F : set) : ℝ :=
  lim_{ε→0} log(N(ε)) / log(1/ε)
  where N(ε) is the number of ε-boxes needed to cover F
```

**分形生成：**

```python
def generate_fractals():
    """生成分形"""
    import matplotlib.pyplot as plt
    
    def sierpinski_triangle(n_iterations):
        """谢尔宾斯基三角形"""
        def midpoint(p1, p2):
            return ((p1[0] + p2[0]) / 2, (p1[1] + p2[1]) / 2)
        
        # 初始三角形
        vertices = [(0, 0), (1, 0), (0.5, np.sqrt(3)/2)]
        points = [(0.5, 0.3)]  # 起始点
        
        for _ in range(n_iterations):
            new_points = []
            for point in points:
                # 随机选择一个顶点
                vertex = vertices[np.random.randint(0, 3)]
                # 移动到中点
                new_point = midpoint(point, vertex)
                new_points.append(new_point)
            points.extend(new_points)
        
        return points
    
    def koch_snowflake(n_iterations):
        """科赫雪花"""
        def koch_curve(p1, p2, n):
            if n == 0:
                return [p1, p2]
            
            # 三等分点
            dx = (p2[0] - p1[0]) / 3
            dy = (p2[1] - p1[1]) / 3
            
            p3 = (p1[0] + dx, p1[1] + dy)
            p4 = (p1[0] + 2*dx, p1[1] + 2*dy)
            
            # 等边三角形的第三个顶点
            angle = np.arctan2(dy, dx) + np.pi/3
            length = np.sqrt(dx**2 + dy**2)
            p5 = (p3[0] + length * np.cos(angle), p3[1] + length * np.sin(angle))
            
            # 递归
            return (koch_curve(p1, p3, n-1)[:-1] + 
                   koch_curve(p3, p5, n-1)[:-1] + 
                   koch_curve(p5, p4, n-1)[:-1] + 
                   koch_curve(p4, p2, n-1))
        
        # 初始等边三角形
        p1, p2, p3 = (0, 0), (1, 0), (0.5, np.sqrt(3)/2)
        
        # 生成科赫雪花
        curve = (koch_curve(p1, p2, n_iterations)[:-1] + 
                koch_curve(p2, p3, n_iterations)[:-1] + 
                koch_curve(p3, p1, n_iterations)[:-1])
        
        return curve
    
    return sierpinski_triangle, koch_snowflake
```

### 5.3 自组织临界性 | Self-Organized Criticality

**沙堆模型：**

```lean
-- 沙堆模型
structure sandpile_model :=
  (grid : ℕ × ℕ → ℕ)
  (threshold : ℕ)
  (toppling_rule : ∀ i j, grid[i,j] ≥ threshold → 
    grid[i,j] -= 4 ∧
    grid[i±1,j] += 1 ∧
    grid[i,j±1] += 1)
```

**自组织临界性分析：**

```python
class SandpileModel:
    def __init__(self, size, threshold=4):
        self.size = size
        self.threshold = threshold
        self.grid = np.zeros((size, size), dtype=int)
        self.avalanches = []
    
    def add_grain(self, i, j):
        """添加一粒沙子"""
        self.grid[i, j] += 1
        avalanche_size = self.relax()
        if avalanche_size > 0:
            self.avalanches.append(avalanche_size)
    
    def relax(self):
        """弛豫过程"""
        avalanche_size = 0
        toppled = True
        
        while toppled:
            toppled = False
            for i in range(self.size):
                for j in range(self.size):
                    if self.grid[i, j] >= self.threshold:
                        # 崩塌
                        self.grid[i, j] -= self.threshold
                        avalanche_size += 1
                        toppled = True
                        
                        # 向邻居转移沙子
                        for di, dj in [(-1,0), (1,0), (0,-1), (0,1)]:
                            ni, nj = i + di, j + dj
                            if 0 <= ni < self.size and 0 <= nj < self.size:
                                self.grid[ni, nj] += 1
        
        return avalanche_size
    
    def analyze_criticality(self):
        """分析临界性"""
        if len(self.avalanches) == 0:
            return None
        
        # 计算崩塌大小的分布
        sizes = np.array(self.avalanches)
        unique_sizes, counts = np.unique(sizes, return_counts=True)
        
        # 拟合幂律分布
        log_sizes = np.log(unique_sizes)
        log_counts = np.log(counts)
        
        # 线性回归
        coeffs = np.polyfit(log_sizes, log_counts, 1)
        exponent = -coeffs[0]
        
        return {
            'avalanche_sizes': sizes,
            'power_law_exponent': exponent,
            'mean_avalanche_size': np.mean(sizes),
            'max_avalanche_size': np.max(sizes)
        }

def self_organized_criticality_demo():
    """自组织临界性演示"""
    # 创建沙堆模型
    model = SandpileModel(50, threshold=4)
    
    # 添加大量沙子
    for _ in range(10000):
        i = np.random.randint(0, model.size)
        j = np.random.randint(0, model.size)
        model.add_grain(i, j)
    
    # 分析临界性
    results = model.analyze_criticality()
    
    if results:
        print(f"幂律指数: {results['power_law_exponent']:.2f}")
        print(f"平均崩塌大小: {results['mean_avalanche_size']:.2f}")
        print(f"最大崩塌大小: {results['max_avalanche_size']}")
    
    return model, results
```

---

## 6. 相关性与本地跳转 | Relevance & Local Navigation

- 参见 [01-总览.md](./01-总览.md)
- 参见 [02-经典数学物理.md](./02-经典数学物理.md)
- 参见 [03-量子数学物理.md](./03-量子数学物理.md)
- 参见 [../01-总览.md](../01-总览.md)
- 参见 [../../04-分析学/06-测度论与勒贝格积分/01-总览.md](../../04-分析学/06-测度论与勒贝格积分/01-总览.md)

---

## 进度日志 | Progress Log

```markdown
### 进度日志
- 日期：2024-12-19
- 当前主题：统计物理与数学
- 已完成内容：统计力学基础、随机过程、相变理论
- 中断点：需要进一步细化复杂系统和非线性动力学部分
- 待续内容：具体物理系统的统计分析、前沿应用案例
- 责任人/AI协作：AI+人工
```

<!-- 中断点：复杂系统/非线性动力学/前沿应用案例的递归扩展 -->