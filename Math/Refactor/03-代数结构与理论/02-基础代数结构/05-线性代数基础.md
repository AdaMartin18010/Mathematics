# 线性代数基础

## 目录

- [线性代数基础](#线性代数基础)
  - [目录](#目录)
  - [1. 引言](#1-引言)
  - [2. 向量空间](#2-向量空间)
    - [2.1 向量空间的定义](#21-向量空间的定义)
    - [2.2 基与维数](#22-基与维数)
    - [2.3 子空间](#23-子空间)
  - [3. 线性变换](#3-线性变换)
    - [3.1 线性变换的定义](#31-线性变换的定义)
    - [3.2 核与像](#32-核与像)
    - [3.3 线性变换的矩阵表示](#33-线性变换的矩阵表示)
  - [4. 矩阵](#4-矩阵)
    - [4.1 矩阵的基本运算](#41-矩阵的基本运算)
    - [4.2 矩阵的秩](#42-矩阵的秩)
    - [4.3 特征值与特征向量](#43-特征值与特征向量)
  - [5. 内积空间](#5-内积空间)
    - [5.1 内积的定义](#51-内积的定义)
    - [5.2 正交性](#52-正交性)
    - [5.3 正交基](#53-正交基)
  - [6. 应用与实例](#6-应用与实例)
  - [7. 代码实现](#7-代码实现)
  - [8. 习题与练习](#8-习题与练习)
  - [9. 参考文献](#9-参考文献)

## 1. 引言

线性代数是数学的基础分支，研究向量空间、线性变换和矩阵。它是现代数学、物理学、工程学和计算机科学的重要工具。

### 1.1 历史背景

线性代数的发展可以追溯到：
- **笛卡尔**：坐标几何
- **高斯**：消元法
- **凯莱**：矩阵理论
- **希尔伯特**：无限维空间

### 1.2 重要性

线性代数在现代科学中具有重要地位：
- **量子力学**的基础
- **机器学习**的核心工具
- **计算机图形学**的基础
- **信号处理**的重要方法

## 2. 向量空间

### 2.1 向量空间的定义

**定义 2.1.1** (向量空间)
设 $F$ 是域，**向量空间** $(V, +, \cdot)$ 是一个非空集合 $V$ 配备两个运算：
- **加法** $+: V \times V \to V$
- **标量乘法** $\cdot: F \times V \to V$

满足以下公理：

**加法公理**：
1. **结合律**：$(u + v) + w = u + (v + w)$
2. **交换律**：$u + v = v + u$
3. **零元素**：存在 $0 \in V$ 使得 $v + 0 = 0 + v = v$
4. **逆元素**：对每个 $v \in V$，存在 $-v \in V$ 使得 $v + (-v) = 0$

**标量乘法公理**：
5. **分配律**：$a \cdot (u + v) = a \cdot u + a \cdot v$
6. **分配律**：$(a + b) \cdot v = a \cdot v + b \cdot v$
7. **结合律**：$(ab) \cdot v = a \cdot (b \cdot v)$
8. **单位元**：$1 \cdot v = v$

### 2.2 基与维数

**定义 2.2.1** (线性无关)
向量组 $\{v_1, v_2, \ldots, v_n\}$ 称为**线性无关**，如果方程：
$$a_1 v_1 + a_2 v_2 + \cdots + a_n v_n = 0$$
只有零解 $a_1 = a_2 = \cdots = a_n = 0$。

**定义 2.2.2** (基)
向量空间 $V$ 的子集 $B$ 称为**基**，如果：
1. $B$ 线性无关
2. $B$ 生成 $V$

**定理 2.2.3** (基的唯一表示)
如果 $B = \{v_1, v_2, \ldots, v_n\}$ 是向量空间 $V$ 的基，则每个向量 $v \in V$ 都可以唯一地表示为：
$$v = a_1 v_1 + a_2 v_2 + \cdots + a_n v_n$$

**定义 2.2.4** (维数)
向量空间 $V$ 的**维数**定义为基的基数，记作 $\dim(V)$。

### 2.3 子空间

**定义 2.3.1** (子空间)
向量空间 $V$ 的子集 $W$ 称为**子空间**，如果 $W$ 在 $V$ 的运算下也构成一个向量空间。

**定理 2.3.2** (子空间判定)
向量空间 $V$ 的非空子集 $W$ 是子空间当且仅当：
1. $u + v \in W$ 对所有 $u, v \in W$
2. $a \cdot v \in W$ 对所有 $a \in F$ 和 $v \in W$

## 3. 线性变换

### 3.1 线性变换的定义

**定义 3.1.1** (线性变换)
设 $V$ 和 $W$ 是域 $F$ 上的向量空间，映射 $T: V \to W$ 称为**线性变换**，如果：
1. $T(u + v) = T(u) + T(v)$ 对所有 $u, v \in V$
2. $T(a \cdot v) = a \cdot T(v)$ 对所有 $a \in F$ 和 $v \in V$

**例 3.1.2**
- 恒等变换：$I: V \to V$ 定义为 $I(v) = v$
- 零变换：$0: V \to W$ 定义为 $0(v) = 0_W$
- 投影：$P: \mathbb{R}^3 \to \mathbb{R}^2$ 定义为 $P(x, y, z) = (x, y)$

### 3.2 核与像

**定义 3.2.1** (核)
线性变换 $T: V \to W$ 的**核**定义为：
$$\ker(T) = \{v \in V \mid T(v) = 0_W\}$$

**定义 3.2.2** (像)
线性变换 $T: V \to W$ 的**像**定义为：
$$\operatorname{im}(T) = \{T(v) \mid v \in V\}$$

**定理 3.2.3** (核与像的性质)
- $\ker(T)$ 是 $V$ 的子空间
- $\operatorname{im}(T)$ 是 $W$ 的子空间

### 3.3 线性变换的矩阵表示

**定理 3.3.1** (矩阵表示)
设 $T: V \to W$ 是线性变换，$B_V = \{v_1, v_2, \ldots, v_n\}$ 是 $V$ 的基，$B_W = \{w_1, w_2, \ldots, w_m\}$ 是 $W$ 的基。则存在唯一的矩阵 $A$ 使得：
$$[T(v)]_{B_W} = A[v]_{B_V}$$

## 4. 矩阵

### 4.1 矩阵的基本运算

**定义 4.1.1** (矩阵加法)
设 $A = [a_{ij}]$ 和 $B = [b_{ij}]$ 是 $m \times n$ 矩阵，则：
$$A + B = [a_{ij} + b_{ij}]$$

**定义 4.1.2** (矩阵乘法)
设 $A = [a_{ij}]$ 是 $m \times n$ 矩阵，$B = [b_{jk}]$ 是 $n \times p$ 矩阵，则：
$$AB = [c_{ik}]$$
其中 $c_{ik} = \sum_{j=1}^n a_{ij} b_{jk}$。

### 4.2 矩阵的秩

**定义 4.2.1** (矩阵的秩)
矩阵 $A$ 的**秩**定义为 $A$ 的行向量组的最大线性无关向量个数，记作 $\operatorname{rank}(A)$。

**定理 4.2.2** (秩的性质)
- $\operatorname{rank}(A) = \operatorname{rank}(A^T)$
- $\operatorname{rank}(AB) \leq \min\{\operatorname{rank}(A), \operatorname{rank}(B)\}$

### 4.3 特征值与特征向量

**定义 4.3.1** (特征值与特征向量)
设 $A$ 是 $n \times n$ 矩阵，标量 $\lambda$ 称为 $A$ 的**特征值**，如果存在非零向量 $v$ 使得：
$$Av = \lambda v$$
向量 $v$ 称为对应于特征值 $\lambda$ 的**特征向量**。

**定义 4.3.2** (特征多项式)
矩阵 $A$ 的**特征多项式**定义为：
$$p_A(\lambda) = \det(A - \lambda I)$$

## 5. 内积空间

### 5.1 内积的定义

**定义 5.1.1** (内积)
设 $V$ 是域 $F$ 上的向量空间，映射 $\langle \cdot, \cdot \rangle: V \times V \to F$ 称为**内积**，如果：
1. **正定性**：$\langle v, v \rangle \geq 0$，且 $\langle v, v \rangle = 0$ 当且仅当 $v = 0$
2. **对称性**：$\langle u, v \rangle = \langle v, u \rangle$
3. **线性性**：$\langle au + bv, w \rangle = a\langle u, w \rangle + b\langle v, w \rangle$

### 5.2 正交性

**定义 5.2.1** (正交)
向量 $u$ 和 $v$ 称为**正交**，如果 $\langle u, v \rangle = 0$。

**定义 5.2.2** (正交补)
子空间 $W$ 的**正交补**定义为：
$$W^\perp = \{v \in V \mid \langle v, w \rangle = 0 \text{ 对所有 } w \in W\}$$

### 5.3 正交基

**定义 5.3.1** (正交基)
向量空间 $V$ 的基 $\{v_1, v_2, \ldots, v_n\}$ 称为**正交基**，如果：
$$\langle v_i, v_j \rangle = 0 \text{ 对所有 } i \neq j$$

**定理 5.3.2** (Gram-Schmidt正交化)
任何有限维内积空间都有正交基。

## 6. 应用与实例

### 6.1 量子力学
- 希尔伯特空间中的线性算子
- 特征值问题与能量本征态

### 6.2 机器学习
- 主成分分析(PCA)
- 支持向量机(SVM)
- 神经网络

### 6.3 计算机图形学
- 3D变换矩阵
- 投影变换
- 光照计算

## 7. 代码实现

### 7.1 Rust实现

```rust
use std::ops::{Add, Mul, Neg, Sub};
use std::fmt;

// 向量空间
#[derive(Debug, Clone, PartialEq)]
pub struct Vector<T> {
    components: Vec<T>,
}

impl<T: Clone + Add<Output = T> + Mul<Output = T> + Neg<Output = T> + Sub<Output = T> + fmt::Display> Vector<T> {
    pub fn new(components: Vec<T>) -> Self {
        Vector { components }
    }
    
    pub fn dimension(&self) -> usize {
        self.components.len()
    }
    
    pub fn dot_product(&self, other: &Self) -> T 
    where T: Default + Copy {
        if self.dimension() != other.dimension() {
            panic!("Vectors must have same dimension");
        }
        
        let mut result = T::default();
        for i in 0..self.dimension() {
            result = result + self.components[i] * other.components[i];
        }
        result
    }
}

// 矩阵
#[derive(Debug, Clone, PartialEq)]
pub struct Matrix<T> {
    data: Vec<Vec<T>>,
    rows: usize,
    cols: usize,
}

impl<T: Clone + Add<Output = T> + Mul<Output = T> + Neg<Output = T> + Sub<Output = T> + fmt::Display> Matrix<T> {
    pub fn new(data: Vec<Vec<T>>) -> Self {
        let rows = data.len();
        let cols = if rows > 0 { data[0].len() } else { 0 };
        
        Matrix { data, rows, cols }
    }
    
    pub fn identity(size: usize) -> Self 
    where T: Default + Copy + PartialEq {
        let mut data = vec![vec![T::default(); size]; size];
        for i in 0..size {
            data[i][i] = T::default(); // 需要实现单位元
        }
        Matrix { data, rows: size, cols: size }
    }
    
    pub fn multiply(&self, other: &Self) -> Self {
        if self.cols != other.rows {
            panic!("Matrix dimensions must be compatible");
        }
        
        let mut result = vec![vec![T::default(); other.cols]; self.rows];
        for i in 0..self.rows {
            for j in 0..other.cols {
                for k in 0..self.cols {
                    result[i][j] = result[i][j] + self.data[i][k] * other.data[k][j];
                }
            }
        }
        
        Matrix::new(result)
    }
}
```

### 7.2 Haskell实现

```haskell
-- 向量空间
newtype Vector a = Vector [a]
    deriving (Eq, Show)

instance Num a => AdditiveGroup (Vector a) where
    zero = Vector []
    add (Vector xs) (Vector ys) = Vector (zipWith (+) xs ys)
    negate (Vector xs) = Vector (map negate xs)

instance Num a => Module a (Vector a) where
    scalarMultiply r (Vector xs) = Vector (map (* r) xs)

-- 矩阵
newtype Matrix a = Matrix [[a]]
    deriving (Eq, Show)

instance Num a => Ring (Matrix a) where
    zero = Matrix []
    one = Matrix [[1]]
    add (Matrix xs) (Matrix ys) = Matrix (zipWith (zipWith (+)) xs ys)
    multiply (Matrix xs) (Matrix ys) = Matrix (matrixMultiply xs ys)

-- 矩阵乘法
matrixMultiply :: Num a => [[a]] -> [[a]] -> [[a]]
matrixMultiply xs ys = 
    [[sum (zipWith (*) row col) | col <- transpose ys] | row <- xs]

-- 内积
dotProduct :: Num a => Vector a -> Vector a -> a
dotProduct (Vector xs) (Vector ys) = sum (zipWith (*) xs ys)

-- 特征值计算（简化版本）
eigenvalues :: (Floating a, Ord a) => Matrix a -> [a]
eigenvalues (Matrix [[a, b], [c, d]]) = 
    let trace = a + d
        det = a * d - b * c
        discriminant = trace^2 - 4 * det
    in if discriminant >= 0
       then [trace/2 + sqrt discriminant/2, trace/2 - sqrt discriminant/2]
       else []
eigenvalues _ = []
```

## 8. 习题与练习

### 8.1 基础练习

1. **证明**：向量空间的零元素是唯一的。

2. **证明**：线性变换的核是子空间。

3. **计算**：矩阵的特征值和特征向量。

### 8.2 中级练习

4. **证明**：矩阵的秩等于其行空间和列空间的维数。

5. **构造**：给出一个不是对角化的矩阵。

6. **研究**：研究线性变换的不变子空间。

### 8.3 高级练习

7. **证明**：任何有限维向量空间都有基。

8. **证明**：Jordan标准形的存在性。

9. **研究**：研究无限维向量空间的性质。

## 9. 参考文献

### 9.1 经典教材

1. **Strang, G.** (2006). *Linear Algebra and Its Applications*. Thomson.
2. **Axler, S.** (2015). *Linear Algebra Done Right*. Springer.
3. **Hoffman, K., & Kunze, R.** (1971). *Linear Algebra*. Prentice Hall.

### 9.2 现代教材

4. **Lay, D. C.** (2012). *Linear Algebra and Its Applications*. Pearson.
5. **Poole, D.** (2015). *Linear Algebra: A Modern Introduction*. Cengage Learning.

### 9.3 专业文献

6. **Golub, G. H., & Van Loan, C. F.** (2013). *Matrix Computations*. Johns Hopkins University Press.
7. **Trefethen, L. N., & Bau, D.** (1997). *Numerical Linear Algebra*. SIAM.

---

**最后更新**: 2024-12-19
**作者**: AI助手
**版本**: 1.0
**状态**: 完成 