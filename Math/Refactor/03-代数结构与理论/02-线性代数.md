# 线性代数：向量空间与线性变换

## 目录

1. [引言](#1-引言)
2. [向量空间](#2-向量空间)
3. [线性变换](#3-线性变换)
4. [矩阵理论](#4-矩阵理论)
5. [内积空间](#5-内积空间)
6. [特征值与特征向量](#6-特征值与特征向量)
7. [线性方程组](#7-线性方程组)
8. [应用与推广](#8-应用与推广)

---

## 1. 引言

线性代数是研究向量空间、线性变换和矩阵的数学分支。它不仅是代数学的重要基础，也是微积分、微分方程、泛函分析等众多数学分支的工具。

### 1.1 线性代数的核心思想

- **线性性**：保持加法和标量乘法的运算
- **向量空间**：抽象的线性结构
- **线性变换**：保持线性结构的映射
- **矩阵**：线性变换的具体表示

### 1.2 线性代数的重要性

- **基础工具**：为其他数学分支提供基础
- **应用广泛**：在物理学、工程学、计算机科学中有广泛应用
- **计算工具**：提供高效的数值计算方法

---

## 2. 向量空间

### 2.1 向量空间的定义

#### 2.1.1 公理化定义

**定义**：设 $F$ 是域，$V$ 是集合，配备加法 $+: V \times V \rightarrow V$ 和标量乘法 $\cdot: F \times V \rightarrow V$，满足以下公理：

1. **加法公理**：
   - 结合律：$(u + v) + w = u + (v + w)$
   - 交换律：$u + v = v + u$
   - 零元：存在 $0 \in V$ 使得 $v + 0 = v$
   - 负元：对每个 $v \in V$，存在 $-v \in V$ 使得 $v + (-v) = 0$

2. **标量乘法公理**：
   - 分配律：$a(u + v) = au + av$
   - 分配律：$(a + b)v = av + bv$
   - 结合律：$(ab)v = a(bv)$
   - 单位元：$1 \cdot v = v$

#### 2.1.2 基本性质

**零向量唯一性**：向量空间的零向量是唯一的。

**负向量唯一性**：每个向量的负向量是唯一的。

**标量乘法性质**：

- $0 \cdot v = 0$
- $a \cdot 0 = 0$
- $(-a)v = -(av) = a(-v)$

### 2.2 子空间

#### 2.2.1 子空间的定义

**定义**：向量空间 $V$ 的子集 $W$ 是子空间，当且仅当：

1. $0 \in W$
2. $\forall u, v \in W, u + v \in W$
3. $\forall a \in F, \forall v \in W, av \in W$

#### 2.2.2 子空间的例子

**核空间**：线性变换 $T: V \rightarrow W$ 的核 $\ker(T) = \{v \in V : T(v) = 0\}$

**像空间**：线性变换 $T: V \rightarrow W$ 的像 $\text{im}(T) = \{T(v) : v \in V\}$

**解空间**：齐次线性方程组 $Ax = 0$ 的解空间

### 2.3 线性无关与基

#### 2.3.1 线性相关与无关

**定义**：向量组 $\{v_1, v_2, \ldots, v_n\}$ 是线性相关的，当且仅当存在不全为零的标量 $a_1, a_2, \ldots, a_n$ 使得 $a_1 v_1 + a_2 v_2 + \cdots + a_n v_n = 0$。

**线性无关**：向量组不是线性相关的。

#### 2.3.2 生成集与基

**生成集**：向量组 $\{v_1, v_2, \ldots, v_n\}$ 生成 $V$，当且仅当 $V = \text{span}\{v_1, v_2, \ldots, v_n\}$。

**基**：向量组 $\{v_1, v_2, \ldots, v_n\}$ 是 $V$ 的基，当且仅当它既是线性无关的又是生成集。

#### 2.3.3 维数

**定义**：向量空间 $V$ 的维数是其基的向量个数。

**性质**：

- 所有基的向量个数相同
- 如果 $\dim V = n$，则任何 $n$ 个线性无关的向量构成基
- 如果 $\dim V = n$，则任何 $n$ 个生成 $V$ 的向量构成基

### 2.4 坐标与同构

#### 2.4.1 坐标向量

**定义**：设 $\mathcal{B} = \{v_1, v_2, \ldots, v_n\}$ 是 $V$ 的基，向量 $v \in V$ 的坐标向量 $[v]_{\mathcal{B}}$ 是使得 $v = a_1 v_1 + a_2 v_2 + \cdots + a_n v_n$ 的标量组 $(a_1, a_2, \ldots, a_n)$。

#### 2.4.2 同构

**定义**：向量空间 $V$ 和 $W$ 同构，当且仅当存在双射线性变换 $T: V \rightarrow W$。

**定理**：两个有限维向量空间同构当且仅当它们有相同的维数。

---

## 3. 线性变换

### 3.1 线性变换的定义

#### 3.1.1 基本定义

**定义**：函数 $T: V \rightarrow W$ 是线性变换，当且仅当：

1. $\forall u, v \in V, T(u + v) = T(u) + T(v)$
2. $\forall a \in F, \forall v \in V, T(av) = aT(v)$

#### 3.1.2 基本性质

**零映射**：$T(0) = 0$

**线性组合**：$T(a_1 v_1 + a_2 v_2 + \cdots + a_n v_n) = a_1 T(v_1) + a_2 T(v_2) + \cdots + a_n T(v_n)$

### 3.2 线性变换的核与像

#### 3.2.1 核空间

**定义**：$\ker(T) = \{v \in V : T(v) = 0\}$

**性质**：

- $\ker(T)$ 是 $V$ 的子空间
- $T$ 是单射当且仅当 $\ker(T) = \{0\}$

#### 3.2.2 像空间

**定义**：$\text{im}(T) = \{T(v) : v \in V\}$

**性质**：

- $\text{im}(T)$ 是 $W$ 的子空间
- $T$ 是满射当且仅当 $\text{im}(T) = W$

#### 3.2.3 秩-零化度定理

**定理**：如果 $T: V \rightarrow W$ 是线性变换，且 $V$ 是有限维的，则：
$$\dim V = \dim \ker(T) + \dim \text{im}(T)$$

### 3.3 线性变换的运算

#### 3.3.1 加法与标量乘法

**加法**：$(S + T)(v) = S(v) + T(v)$

**标量乘法**：$(aT)(v) = aT(v)$

**性质**：所有从 $V$ 到 $W$ 的线性变换构成向量空间 $\mathcal{L}(V, W)$。

#### 3.3.2 复合

**定义**：$(T \circ S)(v) = T(S(v))$

**性质**：

- 结合律：$(T \circ S) \circ R = T \circ (S \circ R)$
- 分配律：$T \circ (S + R) = T \circ S + T \circ R$

### 3.4 线性变换的矩阵表示

#### 3.4.1 矩阵表示

**定义**：设 $\mathcal{B} = \{v_1, v_2, \ldots, v_n\}$ 是 $V$ 的基，$\mathcal{C} = \{w_1, w_2, \ldots, w_m\}$ 是 $W$ 的基，线性变换 $T: V \rightarrow W$ 的矩阵表示 $[T]_{\mathcal{B}}^{\mathcal{C}}$ 是使得 $[T(v)]_{\mathcal{C}} = [T]_{\mathcal{B}}^{\mathcal{C}} [v]_{\mathcal{B}}$ 的矩阵。

#### 3.4.2 矩阵表示的计算

**方法**：$[T]_{\mathcal{B}}^{\mathcal{C}}$ 的第 $j$ 列是 $[T(v_j)]_{\mathcal{C}}$。

**例子**：设 $T: \mathbb{R}^2 \rightarrow \mathbb{R}^2$ 定义为 $T(x, y) = (x + y, x - y)$，标准基下的矩阵表示是：
$$[T] = \begin{pmatrix} 1 & 1 \\ 1 & -1 \end{pmatrix}$$

---

## 4. 矩阵理论

### 4.1 矩阵的基本概念

#### 4.1.1 矩阵的定义

**定义**：$m \times n$ 矩阵是 $F$ 上的 $m \times n$ 数组：
$$A = \begin{pmatrix} a_{11} & a_{12} & \cdots & a_{1n} \\ a_{21} & a_{22} & \cdots & a_{2n} \\ \vdots & \vdots & \ddots & \vdots \\ a_{m1} & a_{m2} & \cdots & a_{mn} \end{pmatrix}$$

#### 4.1.2 矩阵运算

**加法**：$(A + B)_{ij} = A_{ij} + B_{ij}$

**标量乘法**：$(cA)_{ij} = cA_{ij}$

**矩阵乘法**：$(AB)_{ik} = \sum_{j=1}^n A_{ij} B_{jk}$

### 4.2 矩阵的秩

#### 4.2.1 行秩与列秩

**行秩**：矩阵的行向量组的秩。

**列秩**：矩阵的列向量组的秩。

**定理**：行秩等于列秩。

#### 4.2.2 秩的性质

**基本性质**：

- $\text{rank}(A) \leq \min(m, n)$
- $\text{rank}(A + B) \leq \text{rank}(A) + \text{rank}(B)$
- $\text{rank}(AB) \leq \min(\text{rank}(A), \text{rank}(B))$

### 4.3 可逆矩阵

#### 4.3.1 可逆性

**定义**：$n \times n$ 矩阵 $A$ 是可逆的，当且仅当存在矩阵 $B$ 使得 $AB = BA = I$。

**性质**：

- 可逆矩阵的逆矩阵是唯一的
- $A$ 可逆当且仅当 $\text{rank}(A) = n$
- $A$ 可逆当且仅当 $\det(A) \neq 0$

#### 4.3.2 逆矩阵的计算

**伴随矩阵法**：$A^{-1} = \frac{1}{\det(A)} \text{adj}(A)$

**初等变换法**：通过初等行变换将 $[A|I]$ 化为 $[I|A^{-1}]$

### 4.4 行列式

#### 4.4.1 行列式的定义

**递归定义**：

- $1 \times 1$ 矩阵：$\det([a]) = a$
- $n \times n$ 矩阵：$\det(A) = \sum_{j=1}^n (-1)^{1+j} a_{1j} \det(A_{1j})$

#### 4.4.2 行列式的性质

**基本性质**：

- $\det(AB) = \det(A) \det(B)$
- $\det(A^T) = \det(A)$
- $\det(cA) = c^n \det(A)$
- 交换两行：行列式变号
- 行倍加：行列式不变

---

## 5. 内积空间

### 5.1 内积的定义

#### 5.1.1 实内积空间

**定义**：实向量空间 $V$ 上的内积是函数 $\langle \cdot, \cdot \rangle: V \times V \rightarrow \mathbb{R}$，满足：

1. **对称性**：$\langle u, v \rangle = \langle v, u \rangle$
2. **线性性**：$\langle au + bv, w \rangle = a\langle u, w \rangle + b\langle v, w \rangle$
3. **正定性**：$\langle v, v \rangle \geq 0$，且 $\langle v, v \rangle = 0$ 当且仅当 $v = 0$

#### 5.1.2 复内积空间

**定义**：复向量空间 $V$ 上的内积是函数 $\langle \cdot, \cdot \rangle: V \times V \rightarrow \mathbb{C}$，满足：

1. **共轭对称性**：$\langle u, v \rangle = \overline{\langle v, u \rangle}$
2. **线性性**：$\langle au + bv, w \rangle = a\langle u, w \rangle + b\langle v, w \rangle$
3. **正定性**：$\langle v, v \rangle \geq 0$，且 $\langle v, v \rangle = 0$ 当且仅当 $v = 0$

### 5.2 范数与距离

#### 5.2.1 范数

**定义**：$\|v\| = \sqrt{\langle v, v \rangle}$

**性质**：

- $\|v\| \geq 0$，且 $\|v\| = 0$ 当且仅当 $v = 0$
- $\|cv\| = |c| \|v\|$
- 三角不等式：$\|u + v\| \leq \|u\| + \|v\|$

#### 5.2.2 距离

**定义**：$d(u, v) = \|u - v\|$

**性质**：

- $d(u, v) \geq 0$，且 $d(u, v) = 0$ 当且仅当 $u = v$
- $d(u, v) = d(v, u)$
- 三角不等式：$d(u, w) \leq d(u, v) + d(v, w)$

### 5.3 正交性

#### 5.3.1 正交向量

**定义**：向量 $u$ 和 $v$ 正交，当且仅当 $\langle u, v \rangle = 0$。

**性质**：

- 零向量与任何向量正交
- 如果 $u$ 与 $v_1, v_2, \ldots, v_n$ 都正交，则 $u$ 与它们的线性组合正交

#### 5.3.2 正交基

**定义**：基 $\{v_1, v_2, \ldots, v_n\}$ 是正交基，当且仅当 $\langle v_i, v_j \rangle = 0$ 对所有 $i \neq j$。

**标准正交基**：正交基 $\{v_1, v_2, \ldots, v_n\}$ 是标准正交基，当且仅当 $\|v_i\| = 1$ 对所有 $i$。

#### 5.3.3 格拉姆-施密特正交化

**过程**：

1. $u_1 = v_1$
2. $u_2 = v_2 - \frac{\langle v_2, u_1 \rangle}{\langle u_1, u_1 \rangle} u_1$
3. $u_3 = v_3 - \frac{\langle v_3, u_1 \rangle}{\langle u_1, u_1 \rangle} u_1 - \frac{\langle v_3, u_2 \rangle}{\langle u_2, u_2 \rangle} u_2$
4. 继续此过程

**结果**：$\{u_1, u_2, \ldots, u_n\}$ 是正交基。

---

## 6. 特征值与特征向量

### 6.1 特征值与特征向量

#### 6.1.1 基本定义

**定义**：设 $T: V \rightarrow V$ 是线性变换，标量 $\lambda$ 是特征值，当且仅当存在非零向量 $v$ 使得 $T(v) = \lambda v$。向量 $v$ 称为对应于特征值 $\lambda$ 的特征向量。

**等价定义**：$\lambda$ 是特征值当且仅当 $\ker(T - \lambda I) \neq \{0\}$。

#### 6.1.2 特征多项式

**定义**：$p_T(\lambda) = \det(T - \lambda I)$

**性质**：

- $p_T(\lambda)$ 是 $n$ 次多项式
- $\lambda$ 是特征值当且仅当 $p_T(\lambda) = 0$

### 6.2 对角化

#### 6.2.1 可对角化

**定义**：线性变换 $T$ 是可对角化的，当且仅当存在基 $\mathcal{B}$ 使得 $[T]_{\mathcal{B}}$ 是对角矩阵。

**等价条件**：

- $T$ 有 $n$ 个线性无关的特征向量
- $V$ 是 $T$ 的特征子空间的直和

#### 6.2.2 对角化的计算

**步骤**：

1. 求特征多项式 $p_T(\lambda)$
2. 求特征值 $\lambda_1, \lambda_2, \ldots, \lambda_k$
3. 对每个特征值求特征向量
4. 如果特征向量个数等于维数，则 $T$ 可对角化

### 6.3 若尔当标准形

#### 6.3.1 若尔当块

**定义**：若尔当块是形如
$$J(\lambda) = \begin{pmatrix} \lambda & 1 & 0 & \cdots & 0 \\ 0 & \lambda & 1 & \cdots & 0 \\ \vdots & \vdots & \ddots & \ddots & \vdots \\ 0 & 0 & 0 & \cdots & \lambda \end{pmatrix}$$
的矩阵。

#### 6.3.2 若尔当标准形

**定理**：任何复矩阵都相似于若尔当标准形。

**应用**：计算矩阵的幂和指数函数。

---

## 7. 线性方程组

### 7.1 线性方程组的基本概念

#### 7.1.1 方程组的形式

**一般形式**：
$$\begin{cases}
a_{11}x_1 + a_{12}x_2 + \cdots + a_{1n}x_n = b_1 \\
a_{21}x_1 + a_{22}x_2 + \cdots + a_{2n}x_n = b_2 \\
\vdots \\
a_{m1}x_1 + a_{m2}x_2 + \cdots + a_{mn}x_n = b_m
\end{cases}$$

**矩阵形式**：$Ax = b$

#### 7.1.2 解的存在性

**定理**：线性方程组 $Ax = b$ 有解当且仅当 $\text{rank}(A) = \text{rank}([A|b])$。

**齐次方程组**：$Ax = 0$ 总是有解（零解）。

### 7.2 高斯消元法

#### 7.2.1 基本步骤

1. **前向消元**：将增广矩阵化为行阶梯形
2. **后向代入**：从最后一行开始求解

#### 7.2.2 行阶梯形

**定义**：矩阵是行阶梯形，当且仅当：
1. 零行在非零行下方
2. 每行的首非零元素在上一行首非零元素右侧

### 7.3 解的结构

#### 7.3.1 齐次方程组的解

**定理**：齐次方程组 $Ax = 0$ 的解空间维数等于 $n - \text{rank}(A)$。

**基础解系**：解空间的基。

#### 7.3.2 非齐次方程组的解

**定理**：如果 $x_0$ 是非齐次方程组 $Ax = b$ 的特解，则通解为 $x = x_0 + x_h$，其中 $x_h$ 是齐次方程组 $Ax = 0$ 的解。

---

## 8. 应用与推广

### 8.1 数值线性代数

#### 8.1.1 数值稳定性

**条件数**：$\kappa(A) = \|A\| \|A^{-1}\|$

**意义**：条件数越大，方程组越不稳定。

#### 8.1.2 迭代方法

**雅可比迭代**：$x^{(k+1)} = D^{-1}(b - (L + U)x^{(k)})$

**高斯-赛德尔迭代**：$x^{(k+1)} = (D - L)^{-1}(b + Ux^{(k)})$

### 8.2 应用领域

#### 8.2.1 计算机图形学

**变换矩阵**：旋转、缩放、平移的矩阵表示。

**投影**：三维到二维的投影变换。

#### 8.2.2 机器学习

**主成分分析**：基于特征值分解的降维方法。

**支持向量机**：基于内积的核方法。

#### 8.2.3 信号处理

**傅里叶变换**：信号的频域表示。

**滤波器**：线性时不变系统的矩阵表示。

### 8.3 推广

#### 8.3.1 无限维向量空间

**希尔伯特空间**：完备的内积空间。

**巴拿赫空间**：完备的赋范空间。

#### 8.3.2 张量代数

**张量积**：向量空间的张量积。

**外代数**：反对称张量的代数。

---

## 结论

线性代数为数学提供了强大的工具和语言，从基础的向量空间到高级的张量理论，线性代数的思想贯穿于现代数学的各个分支。其应用范围从纯数学到应用科学，显示了其重要性和普遍性。

---

## 参考文献

1. Strang, G. (2016). Linear Algebra and Its Applications. Cengage Learning.
2. Axler, S. (2015). Linear Algebra Done Right. Springer.
3. Hoffman, K., & Kunze, R. (1971). Linear Algebra. Prentice-Hall.
4. Friedberg, S. H., Insel, A. J., & Spence, L. E. (2003). Linear Algebra. Pearson.
5. Lay, D. C. (2012). Linear Algebra and Its Applications. Pearson.
