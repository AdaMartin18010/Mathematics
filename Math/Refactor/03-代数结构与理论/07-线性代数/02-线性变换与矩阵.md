# 线性变换与矩阵

## 目录

- [线性变换与矩阵](#线性变换与矩阵)
  - [目录](#目录)
  - [1. 线性变换的基本概念](#1-线性变换的基本概念)
    - [1.1 定义与性质](#11-定义与性质)
    - [1.2 基本性质](#12-基本性质)
    - [1.3 线性变换的核与像](#13-线性变换的核与像)
    - [1.4 秩与核空间维数定理](#14-秩与核空间维数定理)
  - [2. 线性变换的矩阵表示](#2-线性变换的矩阵表示)
    - [2.1 坐标向量与矩阵表示](#21-坐标向量与矩阵表示)
    - [2.2 矩阵与向量的关系](#22-矩阵与向量的关系)
    - [2.3 标准矩阵](#23-标准矩阵)
  - [3. 线性变换的类型](#3-线性变换的类型)
    - [3.1 同构](#31-同构)
    - [3.2 自同构](#32-自同构)
    - [3.3 投影](#33-投影)
    - [3.4 反射](#34-反射)
    - [3.5 旋转](#35-旋转)
  - [4. 矩阵的性质与运算](#4-矩阵的性质与运算)
    - [4.1 矩阵的基本运算](#41-矩阵的基本运算)
    - [4.2 矩阵的行列式](#42-矩阵的行列式)
    - [4.3 可逆矩阵](#43-可逆矩阵)
    - [4.4 伴随矩阵](#44-伴随矩阵)
    - [4.5 矩阵的秩](#45-矩阵的秩)
  - [5. 坐标变换](#5-坐标变换)
    - [5.1 基变换](#51-基变换)
    - [5.2 相似变换](#52-相似变换)
    - [5.3 正交变换与正交矩阵](#53-正交变换与正交矩阵)
  - [6. 线性变换的应用实例](#6-线性变换的应用实例)
    - [6.1 计算机图形学中的变换](#61-计算机图形学中的变换)
    - [6.2 机器学习中的线性变换](#62-机器学习中的线性变换)
    - [6.3 信号处理中的线性变换](#63-信号处理中的线性变换)
  - [7. 习题与思考](#7-习题与思考)
  - [参考文献](#参考文献)

## 1. 线性变换的基本概念

### 1.1 定义与性质

**线性变换**（Linear Transformation）是向量空间之间的一种特殊映射，它保持向量加法和标量乘法运算。

设 $V$ 和 $W$ 是数域 $\mathbb{F}$ 上的向量空间，映射 $T: V \to W$ 称为**线性变换**，如果对任意 $u, v \in V$ 和任意 $\alpha \in \mathbb{F}$，满足：

1. **加法保持性**：$T(u + v) = T(u) + T(v)$
2. **标量乘法保持性**：$T(\alpha v) = \alpha T(v)$

这两个条件可以合并为一个等价条件：对任意 $u, v \in V$ 和任意 $\alpha, \beta \in \mathbb{F}$，有
$T(\alpha u + \beta v) = \alpha T(u) + \beta T(v)$。

### 1.2 基本性质

1. **零向量映射**：对任意线性变换 $T: V \to W$，有 $T(0_V) = 0_W$，其中 $0_V$ 和 $0_W$ 分别是 $V$ 和 $W$ 中的零向量。

   *证明*：$T(0_V) = T(0 \cdot v) = 0 \cdot T(v) = 0_W$，其中 $v$ 是 $V$ 中任意非零向量。

2. **负向量映射**：对任意线性变换 $T: V \to W$ 和任意 $v \in V$，有 $T(-v) = -T(v)$。

   *证明*：$0_W = T(0_V) = T(v + (-v)) = T(v) + T(-v)$，因此 $T(-v) = -T(v)$。

### 1.3 线性变换的核与像

设 $T: V \to W$ 是线性变换，则：

1. **核**（Kernel）：$\ker(T) = \{v \in V \mid T(v) = 0_W\}$，即被映射为零向量的所有向量构成的集合。
   - $\ker(T)$ 是 $V$ 的子空间。
   - 若 $\ker(T) = \{0_V\}$，则称 $T$ 是**单射**（Injective）或**一对一**（One-to-one）的。

2. **像**（Image）：$\operatorname{im}(T) = \{T(v) \mid v \in V\}$，即 $T$ 的值域。
   - $\operatorname{im}(T)$ 是 $W$ 的子空间。
   - 若 $\operatorname{im}(T) = W$，则称 $T$ 是**满射**（Surjective）或**映上**（Onto）的。

### 1.4 秩与核空间维数定理

设 $T: V \to W$ 是从 $n$ 维向量空间 $V$ 到向量空间 $W$ 的线性变换，则：

$$\dim(\ker(T)) + \dim(\operatorname{im}(T)) = \dim(V) = n$$

这一结果称为**秩-零度定理**（Rank-Nullity Theorem）。其中：

- $\dim(\ker(T))$ 称为 $T$ 的**零度**（Nullity）
- $\dim(\operatorname{im}(T))$ 称为 $T$ 的**秩**（Rank）

## 2. 线性变换的矩阵表示

### 2.1 坐标向量与矩阵表示

设 $V$ 和 $W$ 是数域 $\mathbb{F}$ 上的有限维向量空间，维数分别为 $n$ 和 $m$。选取 $V$ 的一组基 $\mathcal{B} = \{v_1, v_2, \ldots, v_n\}$ 和 $W$ 的一组基 $\mathcal{C} = \{w_1, w_2, \ldots, w_m\}$。

对于线性变换 $T: V \to W$，我们可以通过确定每个基向量的像来完全确定 $T$：

$$T(v_j) = \sum_{i=1}^m a_{ij} w_i \quad (j = 1, 2, \ldots, n)$$

其中 $a_{ij}$ 是标量系数。

这些系数可以排列成一个 $m \times n$ 的矩阵 $A = [a_{ij}]$，称为线性变换 $T$ 关于基 $\mathcal{B}$ 和 $\mathcal{C}$ 的**矩阵表示**，记作 $[T]_{\mathcal{B}}^{\mathcal{C}}$。

### 2.2 矩阵与向量的关系

设 $v \in V$，在基 $\mathcal{B}$ 下的坐标表示为 $[v]_{\mathcal{B}} = (x_1, x_2, \ldots, x_n)^T$，即 $v = \sum_{j=1}^n x_j v_j$。

则 $T(v)$ 在基 $\mathcal{C}$ 下的坐标表示为：

$$[T(v)]_{\mathcal{C}} = [T]_{\mathcal{B}}^{\mathcal{C}} \cdot [v]_{\mathcal{B}} = A \cdot \begin{pmatrix} x_1 \\ x_2 \\ \vdots \\ x_n \end{pmatrix}$$

这表明线性变换在坐标下的作用等价于矩阵与向量的乘法。

### 2.3 标准矩阵

在 $\mathbb{R}^n$ 和 $\mathbb{R}^m$ 中选取标准基（单位向量基），线性变换 $T: \mathbb{R}^n \to \mathbb{R}^m$ 的矩阵表示称为 $T$ 的**标准矩阵**。

设 $\mathbf{e}_1, \mathbf{e}_2, \ldots, \mathbf{e}_n$ 是 $\mathbb{R}^n$ 的标准基，那么 $T$ 的标准矩阵 $A$ 的第 $j$ 列就是 $T(\mathbf{e}_j)$，即：

$$A = \begin{pmatrix} | & | & & | \\ T(\mathbf{e}_1) & T(\mathbf{e}_2) & \cdots & T(\mathbf{e}_n) \\ | & | & & | \end{pmatrix}$$

## 3. 线性变换的类型

### 3.1 同构

如果线性变换 $T: V \to W$ 既是单射又是满射，则称 $T$ 为**同构**（Isomorphism），记作 $V \cong W$。

两个向量空间同构的充要条件是它们具有相同的维数。

若存在同构 $T: V \to W$，则称向量空间 $V$ 和 $W$ 是**同构的**。同构的向量空间在代数结构上是等价的。

### 3.2 自同构

若 $V = W$，则同构 $T: V \to V$ 称为 $V$ 的一个**自同构**（Automorphism）。

$n$ 维向量空间上的所有自同构构成一个群，称为**一般线性群**，记为 $GL(V)$ 或 $GL(n, \mathbb{F})$。

### 3.3 投影

**投影**（Projection）是满足 $T^2 = T$（即 $T \circ T = T$）的线性变换 $T: V \to V$。

设 $V = U \oplus W$（即 $V$ 是子空间 $U$ 和 $W$ 的直和），则从 $V$ 到 $U$ 沿 $W$ 方向的投影 $P$ 定义为：对于任意 $v = u + w$，其中 $u \in U$，$w \in W$，有 $P(v) = u$。

### 3.4 反射

**反射**（Reflection）是将向量关于某个子空间进行镜像的线性变换。

在欧几里得空间中，关于超平面的反射 $R$ 满足 $R^2 = I$（即 $R \circ R = I$，其中 $I$ 是恒等变换）。

### 3.5 旋转

**旋转**（Rotation）是保持原点和向量长度不变的线性变换。

在 $\mathbb{R}^2$ 中，逆时针旋转 $\theta$ 角度的标准矩阵为：

$$R_\theta = \begin{pmatrix} \cos\theta & -\sin\theta \\ \sin\theta & \cos\theta \end{pmatrix}$$

在 $\mathbb{R}^3$ 中，绕坐标轴旋转的标准矩阵分别为：

- 绕 $x$ 轴旋转 $\theta$ 角度：$R_x(\theta) = \begin{pmatrix} 1 & 0 & 0 \\ 0 & \cos\theta & -\sin\theta \\ 0 & \sin\theta & \cos\theta \end{pmatrix}$
- 绕 $y$ 轴旋转 $\theta$ 角度：$R_y(\theta) = \begin{pmatrix} \cos\theta & 0 & \sin\theta \\ 0 & 1 & 0 \\ -\sin\theta & 0 & \cos\theta \end{pmatrix}$
- 绕 $z$ 轴旋转 $\theta$ 角度：$R_z(\theta) = \begin{pmatrix} \cos\theta & -\sin\theta & 0 \\ \sin\theta & \cos\theta & 0 \\ 0 & 0 & 1 \end{pmatrix}$

## 4. 矩阵的性质与运算

### 4.1 矩阵的基本运算

设 $A = [a_{ij}]$ 和 $B = [b_{ij}]$ 是两个矩阵，则：

1. **加法**：$(A + B)_{ij} = a_{ij} + b_{ij}$（要求 $A$ 和 $B$ 的维度相同）
2. **标量乘法**：$(\alpha A)_{ij} = \alpha a_{ij}$，其中 $\alpha$ 是标量
3. **矩阵乘法**：$(AB)_{ij} = \sum_{k=1}^p a_{ik} b_{kj}$（要求 $A$ 的列数等于 $B$ 的行数）
4. **转置**：$(A^T)_{ij} = a_{ji}$

### 4.2 矩阵的行列式

$n \times n$ 矩阵 $A$ 的**行列式**（Determinant）记为 $\det(A)$ 或 $|A|$，可以通过以下方式递归定义：

1. 若 $n = 1$，则 $\det([a]) = a$。
2. 若 $n > 1$，则 $\det(A) = \sum_{j=1}^n a_{1j} \cdot (-1)^{1+j} \cdot \det(A_{1j})$，其中 $A_{1j}$ 是删除 $A$ 的第 1 行和第 $j$ 列后得到的子矩阵。

行列式有以下重要性质：

1. $\det(AB) = \det(A) \cdot \det(B)$
2. $\det(A^T) = \det(A)$
3. 若 $A$ 中存在全零行或全零列，则 $\det(A) = 0$
4. 若 $A$ 中两行（或两列）相同，则 $\det(A) = 0$
5. 若交换 $A$ 的两行（或两列），则行列式变号
6. 若将 $A$ 的某一行（或某一列）乘以标量 $\alpha$，则行列式变为原来的 $\alpha$ 倍

### 4.3 可逆矩阵

若存在矩阵 $B$ 使得 $AB = BA = I$（其中 $I$ 是单位矩阵），则称方阵 $A$ 是**可逆的**（Invertible）或**非奇异的**（Nonsingular），$B$ 称为 $A$ 的**逆矩阵**，记为 $A^{-1}$。

判断矩阵是否可逆的等价条件：

1. $\det(A) \neq 0$
2. $A$ 的列（或行）线性无关
3. $A$ 的秩等于 $n$（即 $A$ 的维度）
4. $0$ 不是 $A$ 的特征值
5. 线性方程组 $Ax = 0$ 只有零解

### 4.4 伴随矩阵

$n \times n$ 矩阵 $A$ 的**伴随矩阵**（Adjugate Matrix）记为 $\operatorname{adj}(A)$，定义为：

$$(\operatorname{adj}(A))_{ij} = (-1)^{i+j} \cdot \det(A_{ji})$$

其中 $A_{ji}$ 是删除 $A$ 的第 $j$ 行和第 $i$ 列后得到的子矩阵。

伴随矩阵与原矩阵的关系：$A \cdot \operatorname{adj}(A) = \operatorname{adj}(A) \cdot A = \det(A) \cdot I$

若 $A$ 可逆，则：$A^{-1} = \frac{1}{\det(A)} \cdot \operatorname{adj}(A)$

### 4.5 矩阵的秩

矩阵 $A$ 的**秩**（Rank）记为 $\operatorname{rank}(A)$，定义为 $A$ 的列空间的维数，也等于 $A$ 的行空间的维数。

等价的定义：

1. $A$ 中线性无关的列（或行）的最大数目
2. $A$ 中非零的主子式（Principal Minor）的最高阶数

矩阵秩的性质：

1. $\operatorname{rank}(A) \leq \min(m, n)$，其中 $A$ 是 $m \times n$ 矩阵
2. $\operatorname{rank}(AB) \leq \min(\operatorname{rank}(A), \operatorname{rank}(B))$
3. $\operatorname{rank}(A + B) \leq \operatorname{rank}(A) + \operatorname{rank}(B)$
4. 若 $A$ 是 $n \times n$ 矩阵，则 $A$ 可逆当且仅当 $\operatorname{rank}(A) = n$

## 5. 坐标变换

### 5.1 基变换

设 $\mathcal{B} = \{v_1, v_2, \ldots, v_n\}$ 和 $\mathcal{B}' = \{v_1', v_2', \ldots, v_n'\}$ 是向量空间 $V$ 的两组基，那么存在一个可逆矩阵 $P$，使得：

$$\begin{pmatrix} v_1' & v_2' & \cdots & v_n' \end{pmatrix} = \begin{pmatrix} v_1 & v_2 & \cdots & v_n \end{pmatrix} P$$

矩阵 $P$ 称为从基 $\mathcal{B}$ 到基 $\mathcal{B}'$ 的**过渡矩阵**（Transition Matrix）。

若向量 $v \in V$ 在两组基下的坐标分别为 $[v]_{\mathcal{B}}$ 和 $[v]_{\mathcal{B}'}$，则：

$$[v]_{\mathcal{B}'} = P^{-1} [v]_{\mathcal{B}}$$

### 5.2 相似变换

设 $T: V \to V$ 是线性变换，$\mathcal{B}$ 和 $\mathcal{B}'$ 是 $V$ 的两组基，$P$ 是从基 $\mathcal{B}$ 到基 $\mathcal{B}'$ 的过渡矩阵，则：

$$[T]_{\mathcal{B}'} = P^{-1} [T]_{\mathcal{B}} P$$

若两个矩阵 $A$ 和 $B$ 满足 $B = P^{-1} A P$，其中 $P$ 是可逆矩阵，则称 $A$ 和 $B$ 是**相似的**（Similar），记作 $A \sim B$。

相似矩阵有以下性质：

1. 具有相同的行列式：$\det(B) = \det(A)$
2. 具有相同的迹（对角线元素之和）：$\operatorname{tr}(B) = \operatorname{tr}(A)$
3. 具有相同的特征多项式，因此具有相同的特征值（包括重数）
4. 具有相同的秩：$\operatorname{rank}(B) = \operatorname{rank}(A)$
5. 若 $A$ 可逆，则 $B$ 也可逆，且 $B^{-1} = P^{-1} A^{-1} P$

### 5.3 正交变换与正交矩阵

若线性变换 $T: \mathbb{R}^n \to \mathbb{R}^n$ 保持内积不变，即对任意 $u, v \in \mathbb{R}^n$，有 $\langle T(u), T(v) \rangle = \langle u, v \rangle$，则称 $T$ 为**正交变换**（Orthogonal Transformation）。

设 $A$ 是 $T$ 的标准矩阵，则 $T$ 是正交变换的充要条件是 $A$ 是**正交矩阵**（Orthogonal Matrix），即 $A^T A = A A^T = I$，或等价地，$A^T = A^{-1}$。

正交矩阵的性质：

1. $\det(A) = \pm 1$
2. $A$ 的列（或行）构成 $\mathbb{R}^n$ 的一组标准正交基
3. 正交矩阵保持向量的长度不变，即对任意 $v \in \mathbb{R}^n$，有 $\|Av\| = \|v\|$

## 6. 线性变换的应用实例

### 6.1 计算机图形学中的变换

在计算机图形学中，线性变换用于对物体进行平移、旋转、缩放等操作：

1. **平移**：$(x, y) \mapsto (x + h, y + k)$（注意：平移不是线性变换，但可以用齐次坐标表示为线性变换）
2. **旋转**：$(x, y) \mapsto (x\cos\theta - y\sin\theta, x\sin\theta + y\cos\theta)$
3. **缩放**：$(x, y) \mapsto (sx, sy)$，其中 $s$ 是缩放因子

### 6.2 机器学习中的线性变换

在机器学习中，线性变换广泛应用于：

1. **线性回归**：$y = Xw$，其中 $X$ 是数据矩阵，$w$ 是权重向量
2. **主成分分析（PCA）**：通过正交变换将数据投影到主成分空间
3. **线性判别分析（LDA）**：通过线性变换最大化类间方差、最小化类内方差

### 6.3 信号处理中的线性变换

在信号处理领域，线性变换用于信号分析和处理：

1. **傅里叶变换**：将时域信号转换为频域表示
2. **小波变换**：将信号分解为不同频率和时间的分量
3. **离散余弦变换（DCT）**：在图像和音频压缩中广泛使用

## 7. 习题与思考

1. 证明：线性变换 $T: V \to W$ 是单射的充要条件是 $\ker(T) = \{0\}$。

2. 设 $T: \mathbb{R}^3 \to \mathbb{R}^2$ 是线性变换，且
   $T(1, 0, 0) = (1, 2)$,
   $T(0, 1, 0) = (3, 1)$,
   $T(0, 0, 1) = (2, 4)$。
   求 $T$ 的标准矩阵和 $T(2, -1, 3)$。

3. 证明：若 $T: V \to W$ 是线性变换，则 $\ker(T)$ 是 $V$ 的子空间，$\operatorname{im}(T)$ 是 $W$ 的子空间。

4. 设 $A$ 是 $3 \times 3$ 矩阵，且 $\det(A) = 5$。求 $\det(2A)$，$\det(A^T)$ 和 $\det(A^{-1})$。

5. 证明：若 $A$ 和 $B$ 是相似矩阵，则对任意正整数 $k$，$A^k$ 和 $B^k$ 也是相似矩阵。

6. 设 $T: \mathbb{R}^2 \to \mathbb{R}^2$ 是逆时针旋转 $45^\circ$ 的线性变换，求 $T$ 的标准矩阵。

## 参考文献

1. Axler, S. (2015). *Linear Algebra Done Right* (3rd ed.). Springer.
2. Strang, G. (2016). *Introduction to Linear Algebra* (5th ed.). Wellesley-Cambridge Press.
3. Horn, R. A., & Johnson, C. R. (2012). *Matrix Analysis* (2nd ed.). Cambridge University Press.
4. Friedberg, S. H., Insel, A. J., & Spence, L. E. (2003). *Linear Algebra* (4th ed.). Prentice Hall.
5. Meyer, C. D. (2000). *Matrix Analysis and Applied Linear Algebra*. SIAM.

---

**创建日期**: 2025-07-01
**最后更新**: 2025-07-01
