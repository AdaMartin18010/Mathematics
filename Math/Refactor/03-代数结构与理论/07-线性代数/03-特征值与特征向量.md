# 特征值与特征向量

## 目录

- [特征值与特征向量](#特征值与特征向量)
  - [目录](#目录)
  - [1. 基本概念与定义](#1-基本概念与定义)
    - [1.1 特征值与特征向量的定义](#11-特征值与特征向量的定义)
    - [1.2 特征方程与特征多项式](#12-特征方程与特征多项式)
    - [1.3 特征空间](#13-特征空间)
  - [2. 特征值与特征向量的性质](#2-特征值与特征向量的性质)
    - [2.1 基本性质](#21-基本性质)
    - [2.2 代数重数与几何重数](#22-代数重数与几何重数)
    - [2.3 不同特征值的特征向量的线性无关性](#23-不同特征值的特征向量的线性无关性)
  - [3. 矩阵的对角化](#3-矩阵的对角化)
    - [3.1 对角化的定义与条件](#31-对角化的定义与条件)
    - [3.2 对角化的步骤](#32-对角化的步骤)
    - [3.3 对角化的应用](#33-对角化的应用)
  - [4. 特殊矩阵的特征值](#4-特殊矩阵的特征值)
    - [4.1 对称矩阵](#41-对称矩阵)
    - [4.2 正交矩阵](#42-正交矩阵)
    - [4.3 埃尔米特矩阵](#43-埃尔米特矩阵)
    - [4.4 正定矩阵](#44-正定矩阵)
  - [5. 若尔当标准形](#5-若尔当标准形)
    - [5.1 若尔当块](#51-若尔当块)
    - [5.2 若尔当标准形定理](#52-若尔当标准形定理)
    - [5.3 若尔当链和广义特征向量](#53-若尔当链和广义特征向量)
    - [5.4 最小多项式](#54-最小多项式)
  - [6. 谱分解](#6-谱分解)
    - [6.1 投影算子和谱分解](#61-投影算子和谱分解)
    - [6.2 对称矩阵的谱分解](#62-对称矩阵的谱分解)
    - [6.3 谱半径](#63-谱半径)
  - [7. 矩阵函数](#7-矩阵函数)
    - [7.1 矩阵函数的定义](#71-矩阵函数的定义)
    - [7.2 常见的矩阵函数](#72-常见的矩阵函数)
  - [8. 特征值计算方法](#8-特征值计算方法)
    - [8.1 特征值的直接计算](#81-特征值的直接计算)
    - [8.2 幂法](#82-幂法)
    - [8.3 反幂法](#83-反幂法)
    - [8.4 QR算法](#84-qr算法)
  - [9. 特征值和特征向量的应用](#9-特征值和特征向量的应用)
    - [9.1 振动分析](#91-振动分析)
    - [9.2 主成分分析（PCA）](#92-主成分分析pca)
    - [9.3 马尔可夫链](#93-马尔可夫链)
    - [9.4 量子力学](#94-量子力学)
    - [9.5 图论与网络分析](#95-图论与网络分析)
  - [10. 习题与思考](#10-习题与思考)
  - [参考文献](#参考文献)

## 1. 基本概念与定义

### 1.1 特征值与特征向量的定义

设 $A$ 是 $n \times n$ 方阵，如果存在非零向量 $v \in \mathbb{F}^n$ 和标量 $\lambda \in \mathbb{F}$，使得：

$$Av = \lambda v$$

则称 $\lambda$ 是矩阵 $A$ 的一个**特征值**（Eigenvalue），对应的非零向量 $v$ 是矩阵 $A$ 关于特征值 $\lambda$ 的**特征向量**（Eigenvector）。

从几何角度看，特征向量是线性变换 $A$ 作用下方向保持不变的非零向量，而特征值则是这些向量在变换下的伸缩比例。

### 1.2 特征方程与特征多项式

方阵 $A$ 的**特征多项式**（Characteristic Polynomial）定义为：

$$p_A(\lambda) = \det(A - \lambda I)$$

其中 $I$ 是 $n \times n$ 单位矩阵。

方程 $p_A(\lambda) = 0$ 称为 $A$ 的**特征方程**（Characteristic Equation）。特征方程的根就是矩阵 $A$ 的特征值。

对于 $n \times n$ 矩阵，特征多项式是关于 $\lambda$ 的 $n$ 次多项式：

$$p_A(\lambda) = (-1)^n \lambda^n + c_{n-1} \lambda^{n-1} + \cdots + c_1 \lambda + c_0$$

其中 $c_0 = \det(A)$，$c_{n-1} = -\operatorname{tr}(A)$（$\operatorname{tr}(A)$ 表示 $A$ 的迹，即对角线元素之和）。

### 1.3 特征空间

给定矩阵 $A$ 的特征值 $\lambda$，与 $\lambda$ 对应的**特征空间**（Eigenspace）是 $A - \lambda I$ 的核空间：

$$E_\lambda = \ker(A - \lambda I) = \{v \in \mathbb{F}^n \mid Av = \lambda v\}$$

特征空间 $E_\lambda$ 是向量空间，包含了关于特征值 $\lambda$ 的所有特征向量以及零向量。

特征空间 $E_\lambda$ 的维数称为特征值 $\lambda$ 的**几何重数**（Geometric Multiplicity）。

## 2. 特征值与特征向量的性质

### 2.1 基本性质

1. 矩阵 $A$ 的**特征值之和**等于 $A$ 的**迹**：
   $$\sum_{i=1}^n \lambda_i = \operatorname{tr}(A)$$

2. 矩阵 $A$ 的**特征值之积**等于 $A$ 的**行列式**：
   $$\prod_{i=1}^n \lambda_i = \det(A)$$

3. 如果 $\lambda$ 是 $A$ 的特征值，$v$ 是对应的特征向量，那么对于任意标量 $c \neq 0$，$cv$ 也是 $A$ 关于特征值 $\lambda$ 的特征向量。

4. 如果 $\lambda$ 是 $A$ 的特征值，那么 $\lambda^k$ 是 $A^k$ 的特征值，对应的特征向量相同。

5. 如果 $\lambda$ 是可逆矩阵 $A$ 的特征值，那么 $\lambda^{-1}$ 是 $A^{-1}$ 的特征值，对应的特征向量相同。

6. 如果 $\lambda$ 是 $A$ 的特征值，$v$ 是对应的特征向量，那么 $p(\lambda)$ 是矩阵 $p(A)$ 的特征值，其中 $p$ 是任意多项式，对应的特征向量仍然是 $v$。

### 2.2 代数重数与几何重数

特征值 $\lambda$ 在特征多项式 $p_A(\lambda)$ 中作为根的重数称为 $\lambda$ 的**代数重数**（Algebraic Multiplicity）。

对于特征值 $\lambda$，其**几何重数**（Geometric Multiplicity）定义为与之对应的线性无关的特征向量的最大个数，即特征空间 $E_\lambda$ 的维数。

几何重数与代数重数的关系：

1. 几何重数 $\leq$ 代数重数
2. 矩阵 $A$ 可对角化的充要条件是每个特征值的几何重数等于其代数重数

### 2.3 不同特征值的特征向量的线性无关性

如果 $\lambda_1, \lambda_2, \ldots, \lambda_k$ 是矩阵 $A$ 的 $k$ 个不同的特征值，$v_1, v_2, \ldots, v_k$ 分别是对应的特征向量，那么这 $k$ 个特征向量是线性无关的。

## 3. 矩阵的对角化

### 3.1 对角化的定义与条件

如果存在可逆矩阵 $P$ 和对角矩阵 $D$，使得 $P^{-1}AP = D$，则称矩阵 $A$ 是**可对角化的**（Diagonalizable）。

矩阵 $A$ 可对角化的充要条件是 $A$ 有 $n$ 个线性无关的特征向量，其中 $n$ 是 $A$ 的阶数。

更一般地，$n \times n$ 矩阵 $A$ 可对角化的充要条件是每个特征值的几何重数等于其代数重数。

### 3.2 对角化的步骤

对角化矩阵 $A$ 的一般步骤：

1. 计算 $A$ 的特征多项式 $p_A(\lambda) = \det(A - \lambda I)$
2. 求解特征方程 $p_A(\lambda) = 0$ 得到特征值
3. 对每个特征值 $\lambda_i$，求解方程组 $(A - \lambda_i I)v = 0$ 得到对应的特征向量
4. 检查是否有 $n$ 个线性无关的特征向量
5. 如果有，将这些特征向量作为列向量构成矩阵 $P$，则 $P^{-1}AP = D$，其中 $D$ 是以特征值为对角元素的对角矩阵

### 3.3 对角化的应用

1. **计算矩阵幂**：如果 $A = PDP^{-1}$，则 $A^k = PD^kP^{-1}$，其中 $D^k$ 是对角矩阵，计算非常简单
2. **求解差分方程和微分方程**：对角化简化了线性系统的求解过程
3. **主成分分析（PCA）**：协方差矩阵的对角化是 PCA 的核心
4. **二次型的标准化**：通过正交对角化将二次型转换为标准形式

## 4. 特殊矩阵的特征值

### 4.1 对称矩阵

设 $A$ 是实对称矩阵（$A^T = A$），则：

1. $A$ 的所有特征值都是实数
2. 不同特征值对应的特征向量相互正交
3. $A$ 可正交对角化，即存在正交矩阵 $Q$（满足 $Q^TQ = QQ^T = I$），使得 $Q^TAQ = D$，其中 $D$ 是对角矩阵

### 4.2 正交矩阵

设 $Q$ 是正交矩阵（$Q^TQ = QQ^T = I$），则：

1. $Q$ 的所有特征值的模为 1，即 $|\lambda| = 1$
2. 对于实正交矩阵，特征值要么是 1，要么是 -1，要么是共轭复数对 $e^{±i\theta}$

### 4.3 埃尔米特矩阵

埃尔米特矩阵（Hermitian Matrix）是满足 $A^H = A$ 的复矩阵，其中 $A^H$ 表示 $A$ 的共轭转置。

1. 埃尔米特矩阵的所有特征值都是实数
2. 不同特征值对应的特征向量是正交的

### 4.4 正定矩阵

正定矩阵是满足对任意非零向量 $x$，都有 $x^TAx > 0$ 的实对称矩阵。

1. 正定矩阵的所有特征值都是正数
2. 负定矩阵的所有特征值都是负数
3. 半正定矩阵的所有特征值都是非负数

## 5. 若尔当标准形

### 5.1 若尔当块

对于不可对角化的矩阵，可以将其化为若尔当标准形（Jordan Normal Form）。

**若尔当块** $J_m(\lambda)$ 是 $m \times m$ 矩阵，定义为：

$$
J_m(\lambda) =
\begin{pmatrix}
\lambda & 1 & 0 & \cdots & 0 \\
0 & \lambda & 1 & \cdots & 0 \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
0 & 0 & 0 & \cdots & 1 \\
0 & 0 & 0 & \cdots & \lambda
\end{pmatrix}
$$

即主对角线上的元素都是 $\lambda$，主对角线上方的元素都是 1，其余元素都是 0。

### 5.2 若尔当标准形定理

**若尔当标准形定理**：对于任意 $n \times n$ 复矩阵 $A$，存在可逆矩阵 $P$，使得 $P^{-1}AP = J$，其中 $J$ 是分块对角矩阵：

$$
J=
\begin{pmatrix}
J_{m_1}(\lambda_1) & & & \\
& J_{m_2}(\lambda_2) & & \\
& & \ddots & \\
& & & J_{m_k}(\lambda_k)
\end{pmatrix}
$$

每个分块 $J_{m_i}(\lambda_i)$ 是若尔当块，$\lambda_1, \lambda_2, \ldots, \lambda_k$ 是 $A$ 的特征值，且 $\sum_{i=1}^k m_i = n$。

### 5.3 若尔当链和广义特征向量

**广义特征向量**：如果 $(A - \lambda I)^k v = 0$ 且 $(A - \lambda I)^{k-1} v \neq 0$，则 $v$ 是 $A$ 关于特征值 $\lambda$ 的 $k$ 阶广义特征向量。

**若尔当链**：设 $J_m(\lambda)$ 是 $A$ 的若尔当标准形中的一个若尔当块，对应的特征值为 $\lambda$。则存在向量 $v_1, v_2, \ldots, v_m$，满足：

1. $Av_1 = \lambda v_1$（$v_1$ 是特征向量）
2. $Av_j = \lambda v_j + v_{j-1}$，对于 $j = 2, 3, \ldots, m$

这组向量 $v_1, v_2, \ldots, v_m$ 称为关于特征值 $\lambda$ 的一个若尔当链。

### 5.4 最小多项式

矩阵 $A$ 的**最小多项式**（Minimal Polynomial）是次数最低的非零多项式 $m_A(\lambda)$，使得 $m_A(A) = 0$。

最小多项式与若尔当标准形的关系：

1. 最小多项式的根就是矩阵 $A$ 的所有特征值
2. 最小多项式可以写为 $m_A(\lambda) = \prod_{i=1}^r (\lambda - \lambda_i)^{r_i}$，其中 $r_i$ 是特征值 $\lambda_i$ 对应的若尔当块的最大阶数
3. 矩阵 $A$ 可对角化的充要条件是其最小多项式无重根

## 6. 谱分解

### 6.1 投影算子和谱分解

如果 $A$ 是 $n \times n$ 可对角化矩阵，特征值为 $\lambda_1, \lambda_2, \ldots, \lambda_k$（各不相同），对应的特征空间为 $E_1, E_2, \ldots, E_k$，则存在投影算子 $P_1, P_2, \ldots, P_k$，使得：

1. $P_i P_j = 0$，若 $i \neq j$
2. $P_1 + P_2 + \cdots + P_k = I$
3. $A = \lambda_1 P_1 + \lambda_2 P_2 + \cdots + \lambda_k P_k$

这就是矩阵 $A$ 的**谱分解**（Spectral Decomposition）。

### 6.2 对称矩阵的谱分解

设 $A$ 是 $n \times n$ 实对称矩阵，特征值为 $\lambda_1, \lambda_2, \ldots, \lambda_n$（可能有重复），对应的标准正交特征向量为 $v_1, v_2, \ldots, v_n$，则：

$$A = \sum_{i=1}^n \lambda_i v_i v_i^T$$

其中 $v_i v_i^T$ 是秩为 1 的投影矩阵。

### 6.3 谱半径

矩阵 $A$ 的**谱半径**（Spectral Radius）定义为其所有特征值的模的最大值：

$$\rho(A) = \max\{|\lambda_1|, |\lambda_2|, \ldots, |\lambda_n|\}$$

谱半径的一个重要应用是判断迭代方法的收敛性：线性迭代格式 $x^{(k+1)} = Bx^{(k)} + f$ 收敛的充要条件是 $\rho(B) < 1$。

## 7. 矩阵函数

### 7.1 矩阵函数的定义

设 $f(x)$ 是标量函数，$A$ 是 $n \times n$ 方阵，可对角化为 $A = PDP^{-1}$，其中 $D = \operatorname{diag}(\lambda_1, \lambda_2, \ldots, \lambda_n)$，则定义：

$$f(A) = P f(D) P^{-1} = P \operatorname{diag}(f(\lambda_1), f(\lambda_2), \ldots, f(\lambda_n)) P^{-1}$$

对于不可对角化的矩阵，可以通过若尔当标准形或幂级数展开来定义矩阵函数。

### 7.2 常见的矩阵函数

1. **矩阵指数**：$e^A = \sum_{k=0}^{\infty} \frac{A^k}{k!}$
   - 如果 $A$ 可对角化为 $A = PDP^{-1}$，则 $e^A = Pe^DP^{-1}$，其中 $e^D = \operatorname{diag}(e^{\lambda_1}, e^{\lambda_2}, \ldots, e^{\lambda_n})$
   - 矩阵指数常用于求解微分方程组 $\frac{d\mathbf{x}}{dt} = A\mathbf{x}$，其解为 $\mathbf{x}(t) = e^{At}\mathbf{x}(0)$

2. **矩阵对数**：如果 $A$ 是正定矩阵，可定义 $\ln(A)$ 为唯一的对称矩阵 $X$，使得 $e^X = A$
   - 如果 $A$ 可对角化为 $A = PDP^{-1}$，其中所有特征值都是正数，则 $\ln(A) = P\ln(D)P^{-1}$，其中 $\ln(D) = \operatorname{diag}(\ln(\lambda_1), \ln(\lambda_2), \ldots, \ln(\lambda_n))$

3. **矩阵平方根**：如果存在矩阵 $B$ 使得 $B^2 = A$，则 $B$ 称为 $A$ 的平方根
   - 正定矩阵 $A$ 有唯一的正定平方根，记为 $A^{1/2}$
   - 如果 $A = PDP^{-1}$，其中 $D = \operatorname{diag}(\lambda_1, \lambda_2, \ldots, \lambda_n)$，且所有 $\lambda_i > 0$，则 $A^{1/2} = PD^{1/2}P^{-1}$，其中 $D^{1/2} = \operatorname{diag}(\sqrt{\lambda_1}, \sqrt{\lambda_2}, \ldots, \sqrt{\lambda_n})$

## 8. 特征值计算方法

### 8.1 特征值的直接计算

对于低阶矩阵，可以通过以下步骤直接计算特征值：

1. 计算特征多项式 $p_A(\lambda) = \det(A - \lambda I)$
2. 求解特征方程 $p_A(\lambda) = 0$

但这种方法在数值计算中不稳定，尤其是对于高阶矩阵。

### 8.2 幂法

**幂法**（Power Method）是一种迭代算法，用于计算矩阵的主特征值（模最大的特征值）及其对应的特征向量。

算法步骤：

1. 选取初始向量 $v_0$
2. 重复迭代：$v_{k+1} = \frac{Av_k}{\|Av_k\|}$
3. 当序列收敛时，$v_k$ 趋近于主特征值对应的特征向量，$v_k^T A v_k$ 趋近于主特征值

### 8.3 反幂法

**反幂法**（Inverse Power Method）是幂法的变体，用于计算矩阵的最小特征值及其对应的特征向量。

算法步骤：

1. 选取初始向量 $v_0$
2. 重复迭代：$v_{k+1} = \frac{A^{-1}v_k}{\|A^{-1}v_k\|}$
3. 当序列收敛时，$v_k$ 趋近于最小特征值对应的特征向量，$(v_k^T A^{-1} v_k)^{-1}$ 趋近于最小特征值

### 8.4 QR算法

**QR算法**（QR Algorithm）是计算所有特征值的高效数值方法。

算法步骤：

1. 初始化 $A_0 = A$
2. 对于 $k = 0, 1, 2, \ldots$，进行 QR 分解：$A_k = Q_k R_k$
3. 计算 $A_{k+1} = R_k Q_k$
4. 迭代直到收敛，此时 $A_k$ 趋近于上三角矩阵，对角线元素即为特征值

在实际应用中，通常先将矩阵转化为Hessenberg形式（上Hessenberg矩阵是除了主对角线和主对角线上方之外，所有元素都为零的矩阵），然后再应用QR算法，以提高计算效率。

## 9. 特征值和特征向量的应用

### 9.1 振动分析

在工程力学中，特征值和特征向量用于分析结构的自然频率和振动模式：

- 特征值表示自然频率的平方
- 特征向量表示振动模式

### 9.2 主成分分析（PCA）

主成分分析是一种降维技术，利用数据协方差矩阵的特征值和特征向量：

- 特征向量定义主成分方向
- 特征值表示各主成分的方差贡献

### 9.3 马尔可夫链

在马尔可夫过程中，转移矩阵 $P$ 的特征值和特征向量可以用于分析系统的长期行为：

- 最大特征值为 1 对应的特征向量表示稳态分布
- 其他特征值的模小于 1，决定了系统趋于稳态的速度

### 9.4 量子力学

在量子力学中，哈密顿算子的特征值和特征向量具有重要的物理意义：

- 特征值表示能量水平
- 特征向量表示量子态

### 9.5 图论与网络分析

在图论中，邻接矩阵或拉普拉斯矩阵的特征值和特征向量可以揭示图的重要性质：

- 特征值分布反映图的连通性和社区结构
- 第二小特征值（代数连通度）与图的可分割性有关
- 谱聚类算法利用特征向量进行社区检测

## 10. 习题与思考

1. 求矩阵 $A = \begin{pmatrix} 3 & 1 \\ 1 & 3 \end{pmatrix}$ 的特征值和特征向量，并讨论它是否可对角化。

2. 证明：如果 $A$ 是实对称矩阵，那么 $A$ 的所有特征值都是实数，且 $A$ 可正交对角化。

3. 设 $A$ 是 $n \times n$ 矩阵，证明：$\det(A) = 0$ 的充要条件是 $0$ 是 $A$ 的特征值。

4. 设 $A$ 和 $B$ 是相似矩阵，证明它们有相同的特征多项式，从而有相同的特征值。

5. 证明：矩阵 $A$ 可对角化的充要条件是对于每个特征值，其代数重数等于几何重数。

6. 计算矩阵 $A = \begin{pmatrix} 1 & 1 & 0 \\ 0 & 1 & 0 \\ 0 & 0 & 2 \end{pmatrix}$ 的若尔当标准形。

7. 设 $A$ 是 $n \times n$ 矩阵，$p(x) = \sum_{i=0}^m a_i x^i$ 是多项式，证明如果 $\lambda$ 是 $A$ 的特征值，那么 $p(\lambda)$ 是 $p(A)$ 的特征值。

## 参考文献

1. Axler, S. (2015). *Linear Algebra Done Right* (3rd ed.). Springer.
2. Horn, R. A., & Johnson, C. R. (2012). *Matrix Analysis* (2nd ed.). Cambridge University Press.
3. Strang, G. (2016). *Introduction to Linear Algebra* (5th ed.). Wellesley-Cambridge Press.
4. Golub, G. H., & Van Loan, C. F. (2013). *Matrix Computations* (4th ed.). Johns Hopkins University Press.
5. Meyer, C. D. (2000). *Matrix Analysis and Applied Linear Algebra*. SIAM.
6. Trefethen, L. N., & Bau, D. (1997). *Numerical Linear Algebra*. SIAM.

---

**创建日期**: 2025-07-02
**最后更新**: 2025-07-02
