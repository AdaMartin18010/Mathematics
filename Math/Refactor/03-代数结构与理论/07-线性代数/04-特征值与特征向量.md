# 04-特征值与特征向量

如果说矩阵是线性变换的"快照"，那么特征值和特征向量就是这张快照的"灵魂"。它们描述了变换最本质的拉伸方向和拉伸比例，是理解和应用线性变换的关键。这个问题也被称为**谱理论**。

## 1. 定义

- **定义 (特征值与特征向量)**:
    设 $T: V \to V$ 是一个作用在向量空间 $V$ 上的线性算子（即从 $V$ 到自身的线性变换）。
  - 如果存在一个**非零向量** $\mathbf{v} \in V$ 和一个标量 $\lambda \in F$，使得：
      $T(\mathbf{v}) = \lambda\mathbf{v}$
  - 那么，我们称 $\lambda$ 是 $T$ 的一个**特征值 (Eigenvalue)**。
  - 称 $\mathbf{v}$ 是对应于特征值 $\lambda$ 的一个**特征向量 (Eigenvector)**。

- **直观理解**:
  - 特征向量是在线性变换 $T$ 的作用下，方向保持不变（或恰好反向）的向量。
  - 特征值 $\lambda$ 描述了特征向量 $\mathbf{v}$ 在该方向上被拉伸或压缩的比例。
    - $|\lambda| > 1$: 拉伸
    - $|\lambda| < 1$: 压缩
    - $\lambda < 0$: 反向

- **特征空间 (Eigenspace)**:
  - 对于一个给定的特征值 $\lambda$，所有对应的特征向量，再加上零向量，构成一个向量子空间，称为 $\lambda$ 的**特征空间**，记作 $E_\lambda$ 或 $E(\lambda)$。
  - $E_\lambda = \{\mathbf{v} \in V \mid T(\mathbf{v}) = \lambda\mathbf{v}\} = \ker(T - \lambda I)$。

## 2. 计算方法

对于有限维向量空间，可以通过矩阵来计算特征值和特征向量。

- **特征方程**:
  - 设 $A$ 是线性算子 $T$ 在某组基下的 $n \times n$ 矩阵表示。
  - $A\mathbf{v} = \lambda\mathbf{v}$ 可以改写为 $(A - \lambda I)\mathbf{v} = \mathbf{0}$。
  - 为了使该方程有非零解 $\mathbf{v}$，矩阵 $(A - \lambda I)$ 必须是奇异的（不可逆的）。
  - 这等价于它的行列式为零：$\det(A - \lambda I) = 0$。

- **特征多项式 (Characteristic Polynomial)**:
  - $p(\lambda) = \det(A - \lambda I)$ 是一个关于 $\lambda$ 的 $n$ 次多项式，称为 $A$ 的**特征多项式**。
  - **特征值就是特征多项式的根**。根据代数基本定理，在复数域 $\mathbb{C}$ 上，任何 $n \times n$ 矩阵都恰好有 $n$ 个特征值（计入重数）。

- **计算步骤**:
    1. 写出矩阵 $A$ 的特征多项式 $p(\lambda) = \det(A - \lambda I)$。
    2. 解方程 $p(\lambda) = 0$，求出所有的特征值 $\lambda_i$。
    3. 对于每一个特征值 $\lambda_i$，求解齐次线性方程组 $(A - \lambda_i I)\mathbf{v} = \mathbf{0}$，其非零解就是对应的特征向量。解空间就是特征空间 $E_{\lambda_i}$。

- **代数重数与几何重数**:
  - **代数重数 (Algebraic Multiplicity)**: 特征值 $\lambda$ 作为特征多项式的根的重数。
  - **几何重数 (Geometric Multiplicity)**: 对应特征空间 $E_\lambda$ 的维数，即 $\dim(\ker(A - \lambda I))$。
  - 对于任何特征值，其**几何重数 ≤ 代数重数**。

## 3. 对角化 (Diagonalization)

对角化是谱理论的核心目标，它试图找到一个最好的基，使得线性变换在该基下的矩阵表示为一个对角矩阵。

- **定义**:
    一个 $n \times n$ 矩阵 $A$ 如果**相似于**一个对角矩阵 $D$，即存在一个可逆矩阵 $P$ 使得 $A = PDP^{-1}$，则称 $A$ 是**可对角化的 (Diagonalizable)**。

- **可对角化的条件**:
    一个 $n \times n$ 矩阵 $A$ 可对角化，当且仅当它满足以下任何一个等价条件：
    1. $A$ 有 $n$ 个线性无关的特征向量。
    2. 对于 $A$ 的每一个特征值 $\lambda$，其几何重数等于其代数重数。

- **如何对角化**:
  - 如果 $A$ 可对角化，那么：
    - 对角矩阵 $D$ 的对角元是 $A$ 的特征值。
    - 可逆矩阵 $P$ 的列向量是与这些特征值一一对应的线性无关的特征向量。

- **重要性**:
  - 对角化极大地简化了计算。例如，计算对角矩阵的幂次非常容易：$A^k = (PDP^{-1})^k = PD^kP^{-1}$。这在求解线性微分方程组和计算马尔可夫链的状态时至关重要。
  - 对角化揭示了变换的内在几何结构：任何复杂的变换，如果可对角化，都可以分解为三次简单的操作：1. 切换到特征基 ($P^{-1}$)，2. 在新基的各个方向上做纯粹的拉伸 ($D$)，3. 切换回原基 ($P$)。
