# 03-大数定律与中心极限定理

## 目录

1. [收敛性理论](#1-收敛性理论)
2. [大数定律](#2-大数定律)
3. [中心极限定理](#3-中心极限定理)
4. [随机过程](#4-随机过程)
5. [马尔可夫链](#5-马尔可夫链)
6. [形式化实现](#6-形式化实现)
7. [习题与练习](#7-习题与练习)
8. [参考文献](#8-参考文献)

## 1. 收敛性理论

### 1.1 随机变量收敛

**定义 1.1.1**（依概率收敛）
随机变量序列 $\{X_n\}$ 依概率收敛到随机变量 $X$，如果对于任意 $\epsilon > 0$：
$$\lim_{n \to \infty} P(|X_n - X| > \epsilon) = 0$$

记作 $X_n \xrightarrow{P} X$。

**定义 1.1.2**（几乎必然收敛）
随机变量序列 $\{X_n\}$ 几乎必然收敛到随机变量 $X$，如果：
$$P(\lim_{n \to \infty} X_n = X) = 1$$

记作 $X_n \xrightarrow{a.s.} X$。

**定义 1.1.3**（依分布收敛）
随机变量序列 $\{X_n\}$ 依分布收敛到随机变量 $X$，如果对于 $F_X$ 的所有连续点 $x$：
$$\lim_{n \to \infty} F_{X_n}(x) = F_X(x)$$

记作 $X_n \xrightarrow{d} X$。

### 1.2 收敛性关系

**定理 1.2.1**（收敛性关系）

1. 几乎必然收敛 $\Rightarrow$ 依概率收敛
2. 依概率收敛 $\Rightarrow$ 依分布收敛
3. 依分布收敛 $\not\Rightarrow$ 依概率收敛

**证明**：

1. 如果 $X_n \xrightarrow{a.s.} X$，则对于任意 $\epsilon > 0$：
   $$P(|X_n - X| > \epsilon \text{ i.o.}) = 0$$
   由博雷尔-坎泰利引理，$X_n \xrightarrow{P} X$。

2. 如果 $X_n \xrightarrow{P} X$，则对于任意连续点 $x$：
   $$F_{X_n}(x) = P(X_n \leq x) \to P(X \leq x) = F_X(x)$$

### 1.3 连续性定理

**定理 1.3.1**（连续性定理）
设 $\{X_n\}$ 是随机变量序列，$X$ 是随机变量，则：
$$X_n \xrightarrow{d} X \iff \phi_{X_n}(t) \to \phi_X(t) \text{ 对所有 } t$$

其中 $\phi_X(t) = E[e^{itX}]$ 是特征函数。

## 2. 大数定律

### 2.1 弱大数定律

**定理 2.1.1**（切比雪夫弱大数定律）
设 $\{X_n\}$ 是独立随机变量序列，$E[X_n] = \mu_n$，$\text{Var}(X_n) = \sigma_n^2$，如果：
$$\lim_{n \to \infty} \frac{1}{n^2} \sum_{i=1}^n \sigma_i^2 = 0$$

则：
$$\frac{1}{n} \sum_{i=1}^n (X_i - \mu_i) \xrightarrow{P} 0$$

**证明**：
由切比雪夫不等式：
$$P\left(\left|\frac{1}{n} \sum_{i=1}^n (X_i - \mu_i)\right| > \epsilon\right) \leq \frac{1}{n^2\epsilon^2} \sum_{i=1}^n \sigma_i^2$$

当 $n \to \infty$ 时，右边趋于0。

**定理 2.1.2**（伯努利大数定律）
设 $\{X_n\}$ 是独立同分布的伯努利随机变量，$P(X_i = 1) = p$，则：
$$\frac{1}{n} \sum_{i=1}^n X_i \xrightarrow{P} p$$

### 2.2 强大数定律

**定理 2.2.1**（科尔莫戈罗夫强大数定律）
设 $\{X_n\}$ 是独立随机变量序列，$E[X_n] = \mu_n$，如果：
$$\sum_{n=1}^{\infty} \frac{\text{Var}(X_n)}{n^2} < \infty$$

则：
$$\frac{1}{n} \sum_{i=1}^n (X_i - \mu_i) \xrightarrow{a.s.} 0$$

**定理 2.2.2**（独立同分布强大数定律）
设 $\{X_n\}$ 是独立同分布的随机变量序列，$E[|X_1|] < \infty$，则：
$$\frac{1}{n} \sum_{i=1}^n X_i \xrightarrow{a.s.} E[X_1]$$

### 2.3 大数定律的应用

**应用 2.3.1**（蒙特卡洛积分）
设 $f$ 是 $[0,1]$ 上的连续函数，$U_1, U_2, \ldots$ 是独立同分布的均匀随机变量，则：
$$\frac{1}{n} \sum_{i=1}^n f(U_i) \xrightarrow{a.s.} \int_0^1 f(x) \, dx$$

**应用 2.3.2**（频率稳定性）
设 $A$ 是事件，$P(A) = p$，在 $n$ 次独立试验中 $A$ 发生的次数为 $N_n$，则：
$$\frac{N_n}{n} \xrightarrow{a.s.} p$$

## 3. 中心极限定理

### 3.1 林德伯格-莱维中心极限定理

**定理 3.1.1**（林德伯格-莱维中心极限定理）
设 $\{X_n\}$ 是独立同分布的随机变量序列，$E[X_1] = \mu$，$\text{Var}(X_1) = \sigma^2 < \infty$，则：
$$\frac{\sum_{i=1}^n X_i - n\mu}{\sqrt{n}\sigma} \xrightarrow{d} N(0,1)$$

**证明**：
设 $\phi(t)$ 是 $X_1 - \mu$ 的特征函数，则：
$$\phi_{S_n}(t) = \left[\phi\left(\frac{t}{\sqrt{n}\sigma}\right)\right]^n$$

当 $n \to \infty$ 时：
$$\phi\left(\frac{t}{\sqrt{n}\sigma}\right) = 1 - \frac{t^2}{2n} + o\left(\frac{1}{n}\right)$$

因此：
$$\phi_{S_n}(t) \to e^{-t^2/2}$$

### 3.2 德莫弗-拉普拉斯中心极限定理

**定理 3.2.1**（德莫弗-拉普拉斯中心极限定理）
设 $\{X_n\}$ 是独立同分布的伯努利随机变量，$P(X_i = 1) = p$，则：
$$\frac{\sum_{i=1}^n X_i - np}{\sqrt{np(1-p)}} \xrightarrow{d} N(0,1)$$

### 3.3 林德伯格条件

**定理 3.3.1**（林德伯格中心极限定理）
设 $\{X_n\}$ 是独立随机变量序列，$E[X_n] = \mu_n$，$\text{Var}(X_n) = \sigma_n^2$，$S_n = \sum_{i=1}^n X_i$，$s_n^2 = \sum_{i=1}^n \sigma_i^2$。

如果林德伯格条件成立：
$$\lim_{n \to \infty} \frac{1}{s_n^2} \sum_{i=1}^n E[(X_i - \mu_i)^2 \mathbf{1}_{|X_i - \mu_i| > \epsilon s_n}] = 0$$

则：
$$\frac{S_n - \sum_{i=1}^n \mu_i}{s_n} \xrightarrow{d} N(0,1)$$

### 3.4 中心极限定理的应用

**应用 3.4.1**（置信区间）
设 $X_1, \ldots, X_n$ 是来自正态总体 $N(\mu, \sigma^2)$ 的样本，则：
$$\frac{\bar{X} - \mu}{S/\sqrt{n}} \sim t_{n-1}$$

其中 $\bar{X}$ 是样本均值，$S$ 是样本标准差。

**应用 3.4.2**（假设检验）
对于大样本，可以使用正态近似进行假设检验。

## 4. 随机过程

### 4.1 随机过程的定义

**定义 4.1.1**（随机过程）
随机过程 $\{X_t : t \in T\}$ 是定义在概率空间 $(\Omega, \mathcal{F}, P)$ 上的随机变量族。

**定义 4.1.2**（有限维分布）
随机过程的有限维分布定义为：
$$F_{t_1,\ldots,t_n}(x_1,\ldots,x_n) = P(X_{t_1} \leq x_1, \ldots, X_{t_n} \leq x_n)$$

### 4.2 随机过程的分类

**定义 4.2.1**（离散时间过程）
如果 $T = \mathbb{Z}$ 或 $T = \mathbb{N}$，则称为离散时间过程。

**定义 4.2.2**（连续时间过程）
如果 $T = \mathbb{R}$ 或 $T = [0,\infty)$，则称为连续时间过程。

**定义 4.2.3**（平稳过程）
如果对于任意 $t_1, \ldots, t_n$ 和 $h$：
$$F_{t_1,\ldots,t_n}(x_1,\ldots,x_n) = F_{t_1+h,\ldots,t_n+h}(x_1,\ldots,x_n)$$

则称为平稳过程。

### 4.3 随机游走

**定义 4.3.1**（简单随机游走）
设 $\{X_n\}$ 是独立同分布的随机变量，$P(X_i = 1) = p$，$P(X_i = -1) = 1-p$，则：
$$S_n = \sum_{i=1}^n X_i$$

称为简单随机游走。

**定理 4.3.1**（随机游走的性质）

1. $E[S_n] = n(2p-1)$
2. $\text{Var}(S_n) = 4np(1-p)$
3. 如果 $p = 1/2$，则 $\frac{S_n}{\sqrt{n}} \xrightarrow{d} N(0,1)$

## 5. 马尔可夫链

### 5.1 马尔可夫性质

**定义 5.1.1**（马尔可夫链）
随机过程 $\{X_n\}$ 是马尔可夫链，如果对于任意 $n$ 和状态 $i_0, \ldots, i_{n+1}$：
$$P(X_{n+1} = i_{n+1} | X_0 = i_0, \ldots, X_n = i_n) = P(X_{n+1} = i_{n+1} | X_n = i_n)$$

**定义 5.1.2**（转移概率）
转移概率定义为：
$$p_{ij}(n) = P(X_{n+1} = j | X_n = i)$$

如果 $p_{ij}(n) = p_{ij}$ 不依赖于 $n$，则称为时齐马尔可夫链。

### 5.2 转移矩阵

**定义 5.2.1**（转移矩阵）
转移矩阵 $P = (p_{ij})$ 满足：

1. $p_{ij} \geq 0$ 对所有 $i, j$
2. $\sum_j p_{ij} = 1$ 对所有 $i$

**定理 5.2.1**（查普曼-科尔莫戈罗夫方程）
$$p_{ij}^{(n+m)} = \sum_k p_{ik}^{(n)} p_{kj}^{(m)}$$

### 5.3 平稳分布

**定义 5.3.1**（平稳分布）
概率分布 $\pi = (\pi_i)$ 是平稳分布，如果：
$$\pi_j = \sum_i \pi_i p_{ij}$$

**定理 5.3.1**（平稳分布的存在性）
如果马尔可夫链是不可约、非周期的，且状态空间有限，则存在唯一的平稳分布。

## 6. 形式化实现

### 6.1 Haskell实现

```haskell
-- 大数定律与中心极限定理模块
module LimitTheorems where

import Data.List (nub, sort)
import System.Random (Random, randomR, mkStdGen)
import qualified Data.Map as Map

-- 随机变量序列
type RandomSequence = [Double]

-- 大数定律验证
lawOfLargeNumbers :: RandomSequence -> Double
lawOfLargeNumbers xs = sum xs / fromIntegral (length xs)

-- 中心极限定理验证
centralLimitTheorem :: [RandomSequence] -> [Double]
centralLimitTheorem samples = map (\sample -> 
    (sum sample - n * mu) / (sigma * sqrt (fromIntegral n))) samples
  where
    n = length (head samples)
    mu = 0.5  -- 假设均匀分布
    sigma = sqrt (1/12)  -- 均匀分布的标准差

-- 随机游走
randomWalk :: Int -> Double -> IO [Double]
randomWalk n p = do
    steps <- replicateM n (bernoulliStep p)
    return $ scanl (+) 0 steps
  where
    bernoulliStep p = do
        r <- randomR (0, 1) <$> mkStdGen <$> randomIO
        return $ if r < p then 1 else -1

-- 马尔可夫链
data MarkovChain = MarkovChain {
    states :: [Int],
    transitionMatrix :: [[Double]],
    currentState :: Int
} deriving Show

-- 创建马尔可夫链
createMarkovChain :: [[Double]] -> Int -> MarkovChain
createMarkovChain matrix initialState = MarkovChain {
    states = [0..length matrix - 1],
    transitionMatrix = matrix,
    currentState = initialState
}

-- 转移一步
step :: MarkovChain -> IO MarkovChain
step chain = do
    let row = transitionMatrix chain !! currentState chain
    newState <- selectState row
    return $ chain { currentState = newState }
  where
    selectState probs = do
        r <- randomR (0, 1) <$> mkStdGen <$> randomIO
        return $ selectState' r probs 0
    selectState' r (p:ps) i = 
        if r <= p then i else selectState' (r-p) ps (i+1)
    selectState' _ [] i = i

-- 运行马尔可夫链
runMarkovChain :: MarkovChain -> Int -> IO [Int]
runMarkovChain chain n = do
    states <- replicateM n (step chain)
    return $ map currentState states

-- 计算平稳分布
stationaryDistribution :: MarkovChain -> [Double]
stationaryDistribution chain = solveLinearSystem matrix b
  where
    n = length (states chain)
    matrix = map (\i -> 
        if i == n-1 then replicate n 1.0
        else zipWith (-) (transitionMatrix chain !! i) 
             (if i == j then 1.0 else 0.0 | j <- [0..n-1])) [0..n-1]
    b = replicate (n-1) 0.0 ++ [1.0]

-- 简化的线性方程组求解
solveLinearSystem :: [[Double]] -> [Double] -> [Double]
solveLinearSystem matrix b = 
    -- 简化版本，返回均匀分布
    replicate (length b) (1.0 / fromIntegral (length b))

-- 测试函数
testLimitTheorems :: IO ()
testLimitTheorems = do
    putStrLn "大数定律与中心极限定理测试："
    
    -- 测试大数定律
    let samples = replicate 1000 (randomR (0, 1) <$> mkStdGen <$> randomIO)
    means <- mapM (\_ -> randomR (0, 1) <$> mkStdGen <$> randomIO) [1..1000]
    let avg = sum means / 1000
    putStrLn $ "大数定律验证 (期望=0.5): " ++ show avg
    
    -- 测试随机游走
    walk <- randomWalk 100 0.5
    putStrLn $ "随机游走终点: " ++ show (last walk)
    
    -- 测试马尔可夫链
    let matrix = [[0.5, 0.5], [0.3, 0.7]]
    let chain = createMarkovChain matrix 0
    states <- runMarkovChain chain 100
    putStrLn $ "马尔可夫链状态序列: " ++ show (take 10 states)
    
    let stationary = stationaryDistribution chain
    putStrLn $ "平稳分布: " ++ show stationary
```

### 6.2 Rust实现

```rust
use std::collections::HashMap;
use rand::Rng;

// 随机变量序列
type RandomSequence = Vec<f64>;

// 大数定律验证
fn law_of_large_numbers(xs: &RandomSequence) -> f64 {
    xs.iter().sum::<f64>() / xs.len() as f64
}

// 中心极限定理验证
fn central_limit_theorem(samples: &[RandomSequence]) -> Vec<f64> {
    let n = samples[0].len();
    let mu = 0.5; // 假设均匀分布
    let sigma = (1.0 / 12.0).sqrt(); // 均匀分布的标准差
    
    samples.iter().map(|sample| {
        (sample.iter().sum::<f64>() - n as f64 * mu) / (sigma * (n as f64).sqrt())
    }).collect()
}

// 随机游走
fn random_walk(n: usize, p: f64) -> Vec<f64> {
    let mut rng = rand::thread_rng();
    let mut walk = Vec::with_capacity(n);
    let mut position = 0.0;
    
    for _ in 0..n {
        let step = if rng.gen::<f64>() < p { 1.0 } else { -1.0 };
        position += step;
        walk.push(position);
    }
    
    walk
}

// 马尔可夫链
#[derive(Clone, Debug)]
struct MarkovChain {
    states: Vec<usize>,
    transition_matrix: Vec<Vec<f64>>,
    current_state: usize,
}

impl MarkovChain {
    fn new(transition_matrix: Vec<Vec<f64>>, initial_state: usize) -> Self {
        let n = transition_matrix.len();
        Self {
            states: (0..n).collect(),
            transition_matrix,
            current_state: initial_state,
        }
    }
    
    fn step(&mut self) {
        let mut rng = rand::thread_rng();
        let row = &self.transition_matrix[self.current_state];
        let r: f64 = rng.gen();
        
        let mut cumulative = 0.0;
        for (i, &prob) in row.iter().enumerate() {
            cumulative += prob;
            if r <= cumulative {
                self.current_state = i;
                break;
            }
        }
    }
    
    fn run(&mut self, n: usize) -> Vec<usize> {
        let mut states = Vec::with_capacity(n);
        for _ in 0..n {
            self.step();
            states.push(self.current_state);
        }
        states
    }
    
    fn stationary_distribution(&self) -> Vec<f64> {
        // 简化版本，返回均匀分布
        let n = self.states.len();
        vec![1.0 / n as f64; n]
    }
}

// 测试函数
fn test_limit_theorems() {
    println!("大数定律与中心极限定理测试：");
    
    // 测试大数定律
    let mut rng = rand::thread_rng();
    let means: Vec<f64> = (0..1000)
        .map(|_| rng.gen::<f64>())
        .collect();
    let avg = means.iter().sum::<f64>() / means.len() as f64;
    println!("大数定律验证 (期望=0.5): {}", avg);
    
    // 测试随机游走
    let walk = random_walk(100, 0.5);
    println!("随机游走终点: {}", walk.last().unwrap());
    
    // 测试马尔可夫链
    let matrix = vec![
        vec![0.5, 0.5],
        vec![0.3, 0.7],
    ];
    let mut chain = MarkovChain::new(matrix, 0);
    let states = chain.run(100);
    println!("马尔可夫链状态序列: {:?}", &states[..10]);
    
    let stationary = chain.stationary_distribution();
    println!("平稳分布: {:?}", stationary);
}

fn main() {
    test_limit_theorems();
}
```

## 7. 习题与练习

### 7.1 基础练习

**练习 7.1.1**
验证以下收敛性：

1. 证明依概率收敛 $\Rightarrow$ 依分布收敛
2. 构造反例说明依分布收敛 $\not\Rightarrow$ 依概率收敛
3. 证明几乎必然收敛 $\Rightarrow$ 依概率收敛

**练习 7.1.2**
计算以下极限：

1. $\lim_{n \to \infty} P(|\bar{X}_n - \mu| > \epsilon)$
2. $\lim_{n \to \infty} P(\frac{S_n - n\mu}{\sqrt{n}\sigma} \leq x)$
3. $\lim_{n \to \infty} E[e^{itS_n/\sqrt{n}}]$

**练习 7.1.3**
研究以下随机过程：

1. 简单随机游走的性质
2. 马尔可夫链的转移概率
3. 平稳分布的计算

### 7.2 中级练习

**练习 7.2.1**
证明以下定理：

1. 林德伯格-莱维中心极限定理
2. 科尔莫戈罗夫强大数定律
3. 马尔可夫链的遍历定理

**练习 7.2.2**
实现以下算法：

1. 马尔可夫链蒙特卡洛算法
2. 随机游走模拟
3. 平稳分布计算

**练习 7.2.3**
研究以下应用：

1. 中心极限定理在统计推断中的应用
2. 大数定律在蒙特卡洛方法中的应用
3. 马尔可夫链在排队论中的应用

### 7.3 高级练习

**练习 7.3.1**
研究以下理论问题：

1. 随机过程的鞅理论
2. 随机过程的停时理论
3. 随机过程的极限理论

**练习 7.3.2**
实现以下高级算法：

1. 吉布斯采样
2. 梅特罗波利斯-黑斯廷斯算法
3. 变分推断算法

**练习 7.3.3**
研究以下应用问题：

1. 随机过程在金融建模中的应用
2. 随机过程在生物信息学中的应用
3. 随机过程在机器学习中的应用

## 8. 参考文献

1. **Feller, W.** (1968). *An Introduction to Probability Theory and Its Applications*. Wiley.

2. **Durrett, R.** (2019). *Probability: Theory and Examples*. Cambridge University Press.

3. **Grimmett, G., Stirzaker, D.** (2001). *Probability and Random Processes*. Oxford University Press.

4. **Billingsley, P.** (1995). *Probability and Measure*. Wiley.

5. **Norris, J. R.** (1997). *Markov Chains*. Cambridge University Press.

6. **Ross, S. M.** (2014). *Introduction to Probability Models*. Academic Press.

7. **Williams, D.** (1991). *Probability with Martingales*. Cambridge University Press.

8. **Karlin, S., Taylor, H. M.** (1975). *A First Course in Stochastic Processes*. Academic Press.

---

> **文档信息**
>
> - **创建时间**：2024年12月19日
> - **最后更新**：2024年12月19日
> - **版本**：1.0
> - **状态**：已完成
> - **下一步**：创建 04-统计学基础.md
