# 04-统计学基础

## 目录

1. [统计学概述](#1-统计学概述)
2. [描述统计学](#2-描述统计学)
3. [参数估计](#3-参数估计)
4. [假设检验](#4-假设检验)
5. [置信区间](#5-置信区间)
6. [回归分析](#6-回归分析)
7. [形式化实现](#7-形式化实现)
8. [习题与练习](#8-习题与练习)
9. [参考文献](#9-参考文献)

## 1. 统计学概述

### 1.1 统计学的定义

**统计学**是收集、分析、解释和呈现数据的科学，它基于概率论为决策提供科学依据。

### 1.2 统计学的基本概念

**总体**：研究对象的全体。

**样本**：从总体中抽取的一部分个体。

**参数**：总体的特征量。

**统计量**：样本的函数，用于估计参数。

### 1.3 统计学的分支

**描述统计学**：数据的收集、整理和描述。

**推断统计学**：从样本推断总体特征。

**贝叶斯统计学**：基于贝叶斯定理的统计推断。

## 2. 描述统计学

### 2.1 数据整理

**定义 2.1.1**（频数分布）
设 $x_1, x_2, \ldots, x_n$ 是样本数据，频数分布定义为：
$$f_i = \text{数据中等于 } x_i \text{ 的个数}$$

**定义 2.1.2**（相对频数）
相对频数定义为：
$$p_i = \frac{f_i}{n}$$

### 2.2 集中趋势度量

**定义 2.2.1**（样本均值）
样本均值定义为：
$$\bar{x} = \frac{1}{n} \sum_{i=1}^n x_i$$

**定义 2.2.2**（样本中位数）
样本中位数是排序后位于中间位置的数值。

**定义 2.2.3**（样本众数）
样本众数是出现频率最高的数值。

### 2.3 离散程度度量

**定义 2.3.1**（样本方差）
样本方差定义为：
$$s^2 = \frac{1}{n-1} \sum_{i=1}^n (x_i - \bar{x})^2$$

**定义 2.3.2**（样本标准差）
样本标准差定义为：
$$s = \sqrt{s^2}$$

**定义 2.3.3**（变异系数）
变异系数定义为：
$$CV = \frac{s}{\bar{x}}$$

### 2.4 分布形状

**定义 2.4.1**（偏度）
偏度定义为：
$$\gamma_1 = \frac{1}{n} \sum_{i=1}^n \left(\frac{x_i - \bar{x}}{s}\right)^3$$

**定义 2.4.2**（峰度）
峰度定义为：
$$\gamma_2 = \frac{1}{n} \sum_{i=1}^n \left(\frac{x_i - \bar{x}}{s}\right)^4 - 3$$

## 3. 参数估计

### 3.1 点估计

**定义 3.1.1**（估计量）
设 $\theta$ 是总体参数，$\hat{\theta} = T(X_1, \ldots, X_n)$ 是样本统计量，如果 $\hat{\theta}$ 用于估计 $\theta$，则称 $\hat{\theta}$ 为 $\theta$ 的估计量。

**定义 3.1.2**（无偏估计）
如果 $E[\hat{\theta}] = \theta$，则称 $\hat{\theta}$ 为 $\theta$ 的无偏估计。

**定义 3.1.3**（一致估计）
如果 $\hat{\theta}_n \xrightarrow{P} \theta$，则称 $\hat{\theta}_n$ 为 $\theta$ 的一致估计。

### 3.2 最大似然估计

**定义 3.2.1**（似然函数）
设 $X_1, \ldots, X_n$ 是来自分布 $f(x;\theta)$ 的样本，似然函数定义为：
$$L(\theta) = \prod_{i=1}^n f(X_i;\theta)$$

**定义 3.2.2**（最大似然估计）
最大似然估计 $\hat{\theta}_{MLE}$ 是使似然函数最大的 $\theta$ 值：
$$\hat{\theta}_{MLE} = \arg\max_{\theta} L(\theta)$$

**定理 3.2.1**（最大似然估计的性质）

1. 最大似然估计是一致估计
2. 最大似然估计是渐近正态的
3. 最大似然估计是渐近有效的

### 3.3 矩估计

**定义 3.3.1**（矩估计）
矩估计是通过样本矩等于总体矩来估计参数的方法。

**例子**：
设 $X_1, \ldots, X_n$ 是来自正态分布 $N(\mu, \sigma^2)$ 的样本，则：
$$\hat{\mu} = \bar{X}, \quad \hat{\sigma}^2 = \frac{1}{n} \sum_{i=1}^n (X_i - \bar{X})^2$$

### 3.4 估计量的评价

**定义 3.4.1**（均方误差）
均方误差定义为：
$$MSE(\hat{\theta}) = E[(\hat{\theta} - \theta)^2]$$

**定理 3.4.1**（均方误差分解）
$$MSE(\hat{\theta}) = \text{Var}(\hat{\theta}) + [\text{Bias}(\hat{\theta})]^2$$

其中 $\text{Bias}(\hat{\theta}) = E[\hat{\theta}] - \theta$。

## 4. 假设检验

### 4.1 假设检验的基本概念

**定义 4.1.1**（零假设和备择假设）

- 零假设 $H_0$：要检验的假设
- 备择假设 $H_1$：零假设的对立假设

**定义 4.1.2**（检验统计量）
检验统计量是用于检验假设的样本函数。

**定义 4.1.3**（拒绝域）
拒绝域是导致拒绝零假设的检验统计量值的集合。

### 4.2 显著性水平与检验功效

**定义 4.2.1**（显著性水平）
显著性水平 $\alpha$ 是第一类错误的概率：
$$\alpha = P(\text{拒绝 } H_0 | H_0 \text{ 为真})$$

**定义 4.2.2**（检验功效）
检验功效 $\beta$ 是第二类错误的概率：
$$\beta = P(\text{接受 } H_0 | H_1 \text{ 为真})$$

**定义 4.2.3**（检验功效函数）
检验功效函数定义为：
$$\pi(\theta) = P(\text{拒绝 } H_0 | \theta)$$

### 4.3 常见假设检验

**定理 4.3.1**（正态总体均值的t检验）
设 $X_1, \ldots, X_n$ 是来自正态总体 $N(\mu, \sigma^2)$ 的样本，检验 $H_0: \mu = \mu_0$ vs $H_1: \mu \neq \mu_0$。

检验统计量：
$$T = \frac{\bar{X} - \mu_0}{S/\sqrt{n}} \sim t_{n-1}$$

**定理 4.3.2**（正态总体方差的卡方检验）
设 $X_1, \ldots, X_n$ 是来自正态总体 $N(\mu, \sigma^2)$ 的样本，检验 $H_0: \sigma^2 = \sigma_0^2$ vs $H_1: \sigma^2 \neq \sigma_0^2$。

检验统计量：
$$\chi^2 = \frac{(n-1)S^2}{\sigma_0^2} \sim \chi_{n-1}^2$$

**定理 4.3.3**（两个正态总体均值差的t检验）
设 $X_1, \ldots, X_m$ 和 $Y_1, \ldots, Y_n$ 分别来自正态总体 $N(\mu_1, \sigma^2)$ 和 $N(\mu_2, \sigma^2)$，检验 $H_0: \mu_1 = \mu_2$ vs $H_1: \mu_1 \neq \mu_2$。

检验统计量：
$$T = \frac{\bar{X} - \bar{Y}}{S_p \sqrt{\frac{1}{m} + \frac{1}{n}}} \sim t_{m+n-2}$$

其中 $S_p^2 = \frac{(m-1)S_1^2 + (n-1)S_2^2}{m+n-2}$。

### 4.4 p值

**定义 4.4.1**（p值）
p值是当零假设为真时，观察到与当前样本一样极端或更极端结果的概率。

**定理 4.4.1**（p值的性质）

1. $0 \leq p \leq 1$
2. 如果 $H_0$ 为真，则 $p$ 服从均匀分布 $U(0,1)$
3. 如果 $H_1$ 为真，则 $p$ 倾向于取小值

## 5. 置信区间

### 5.1 置信区间的定义

**定义 5.1.1**（置信区间）
设 $\theta$ 是总体参数，$L(X_1, \ldots, X_n)$ 和 $U(X_1, \ldots, X_n)$ 是样本函数，如果：
$$P(L \leq \theta \leq U) = 1 - \alpha$$

则称 $[L, U]$ 为 $\theta$ 的 $100(1-\alpha)\%$ 置信区间。

### 5.2 正态总体的置信区间

**定理 5.2.1**（正态总体均值的置信区间）
设 $X_1, \ldots, X_n$ 是来自正态总体 $N(\mu, \sigma^2)$ 的样本，$\mu$ 的 $100(1-\alpha)\%$ 置信区间为：
$$\left[\bar{X} - t_{\alpha/2,n-1} \frac{S}{\sqrt{n}}, \bar{X} + t_{\alpha/2,n-1} \frac{S}{\sqrt{n}}\right]$$

**定理 5.2.2**（正态总体方差的置信区间）
$\sigma^2$ 的 $100(1-\alpha)\%$ 置信区间为：
$$\left[\frac{(n-1)S^2}{\chi_{\alpha/2,n-1}^2}, \frac{(n-1)S^2}{\chi_{1-\alpha/2,n-1}^2}\right]$$

### 5.3 大样本置信区间

**定理 5.3.1**（大样本均值的置信区间）
对于大样本，总体均值 $\mu$ 的 $100(1-\alpha)\%$ 置信区间为：
$$\left[\bar{X} - z_{\alpha/2} \frac{S}{\sqrt{n}}, \bar{X} + z_{\alpha/2} \frac{S}{\sqrt{n}}\right]$$

**定理 5.3.2**（大样本比例的置信区间）
总体比例 $p$ 的 $100(1-\alpha)\%$ 置信区间为：
$$\left[\hat{p} - z_{\alpha/2} \sqrt{\frac{\hat{p}(1-\hat{p})}{n}}, \hat{p} + z_{\alpha/2} \sqrt{\frac{\hat{p}(1-\hat{p})}{n}}\right]$$

其中 $\hat{p} = \frac{X}{n}$ 是样本比例。

## 6. 回归分析

### 6.1 简单线性回归

**定义 6.1.1**（简单线性回归模型）
简单线性回归模型定义为：
$$Y_i = \beta_0 + \beta_1 X_i + \epsilon_i, \quad i = 1, \ldots, n$$

其中 $\epsilon_i \sim N(0, \sigma^2)$ 是独立同分布的误差项。

**定义 6.1.2**（最小二乘估计）
最小二乘估计 $\hat{\beta}_0, \hat{\beta}_1$ 是使残差平方和最小的参数值：
$$\min_{\beta_0, \beta_1} \sum_{i=1}^n (Y_i - \beta_0 - \beta_1 X_i)^2$$

**定理 6.1.1**（最小二乘估计的显式解）
$$\hat{\beta}_1 = \frac{\sum_{i=1}^n (X_i - \bar{X})(Y_i - \bar{Y})}{\sum_{i=1}^n (X_i - \bar{X})^2}$$
$$\hat{\beta}_0 = \bar{Y} - \hat{\beta}_1 \bar{X}$$

### 6.2 多元线性回归

**定义 6.2.1**（多元线性回归模型）
多元线性回归模型定义为：
$$\mathbf{Y} = \mathbf{X}\boldsymbol{\beta} + \boldsymbol{\epsilon}$$

其中 $\mathbf{Y}$ 是响应变量向量，$\mathbf{X}$ 是设计矩阵，$\boldsymbol{\beta}$ 是参数向量，$\boldsymbol{\epsilon} \sim N(\mathbf{0}, \sigma^2\mathbf{I})$。

**定理 6.2.1**（最小二乘估计）
$$\hat{\boldsymbol{\beta}} = (\mathbf{X}^T\mathbf{X})^{-1}\mathbf{X}^T\mathbf{Y}$$

### 6.3 回归诊断

**定义 6.3.1**（残差）
残差定义为：
$$e_i = Y_i - \hat{Y}_i$$

**定义 6.3.2**（标准化残差）
标准化残差定义为：
$$r_i = \frac{e_i}{\sqrt{MSE(1-h_{ii})}}$$

其中 $h_{ii}$ 是帽子矩阵的对角元素。

**定义 6.3.3**（学生化残差）
学生化残差定义为：
$$t_i = \frac{e_i}{\sqrt{MSE_{(i)}(1-h_{ii})}}$$

其中 $MSE_{(i)}$ 是删除第 $i$ 个观测后的均方误差。

## 7. 形式化实现

### 7.1 Haskell实现

```haskell
-- 统计学基础模块
module Statistics where

import Data.List (nub, sort)
import qualified Data.Map as Map

-- 描述统计
data DescriptiveStats = DescriptiveStats {
    mean :: Double,
    median :: Double,
    mode :: Double,
    variance :: Double,
    stdDev :: Double,
    skewness :: Double,
    kurtosis :: Double
} deriving Show

-- 计算描述统计
descriptiveStatistics :: [Double] -> DescriptiveStats
descriptiveStatistics xs = DescriptiveStats {
    mean = sampleMean xs,
    median = sampleMedian xs,
    mode = sampleMode xs,
    variance = sampleVariance xs,
    stdDev = sqrt (sampleVariance xs),
    skewness = sampleSkewness xs,
    kurtosis = sampleKurtosis xs
}

-- 样本均值
sampleMean :: [Double] -> Double
sampleMean xs = sum xs / fromIntegral (length xs)

-- 样本中位数
sampleMedian :: [Double] -> Double
sampleMedian xs = let
    sorted = sort xs
    n = length sorted
    in if odd n 
       then sorted !! (n `div` 2)
       else (sorted !! (n `div` 2 - 1) + sorted !! (n `div` 2)) / 2

-- 样本众数
sampleMode :: [Double] -> Double
sampleMode xs = let
    freq = Map.fromListWith (+) [(x, 1) | x <- xs]
    maxFreq = maximum (Map.elems freq)
    in head [x | (x, f) <- Map.toList freq, f == maxFreq]

-- 样本方差
sampleVariance :: [Double] -> Double
sampleVariance xs = let
    mu = sampleMean xs
    n = fromIntegral (length xs)
    in sum [(x - mu)^2 | x <- xs] / (n - 1)

-- 样本偏度
sampleSkewness :: [Double] -> Double
sampleSkewness xs = let
    mu = sampleMean xs
    s = sqrt (sampleVariance xs)
    n = fromIntegral (length xs)
    in sum [(x - mu)^3 | x <- xs] / (n * s^3)

-- 样本峰度
sampleKurtosis :: [Double] -> Double
sampleKurtosis xs = let
    mu = sampleMean xs
    s = sqrt (sampleVariance xs)
    n = fromIntegral (length xs)
    in sum [(x - mu)^4 | x <- xs] / (n * s^4) - 3

-- 假设检验
data HypothesisTest = HypothesisTest {
    testStatistic :: Double,
    pValue :: Double,
    criticalValue :: Double,
    decision :: String
} deriving Show

-- t检验
tTest :: [Double] -> Double -> Double -> HypothesisTest
tTest xs mu0 alpha = let
    n = fromIntegral (length xs)
    xbar = sampleMean xs
    s = sqrt (sampleVariance xs)
    t = (xbar - mu0) / (s / sqrt n)
    p = 2 * (1 - tDistribution (abs t) (n-1))
    critical = tCritical alpha/2 (n-1)
    decision = if abs t > critical then "Reject H0" else "Accept H0"
    in HypothesisTest t p critical decision

-- 置信区间
data ConfidenceInterval = ConfidenceInterval {
    lowerBound :: Double,
    upperBound :: Double,
    confidenceLevel :: Double
} deriving Show

-- 均值置信区间
meanConfidenceInterval :: [Double] -> Double -> ConfidenceInterval
meanConfidenceInterval xs alpha = let
    n = fromIntegral (length xs)
    xbar = sampleMean xs
    s = sqrt (sampleVariance xs)
    t = tCritical alpha/2 (n-1)
    margin = t * s / sqrt n
    in ConfidenceInterval (xbar - margin) (xbar + margin) (1-alpha)

-- 简化的t分布函数
tDistribution :: Double -> Double -> Double
tDistribution t df = 
    -- 简化版本，返回近似值
    if abs t < 1.96 then 0.975 else 0.025

-- t分布临界值
tCritical :: Double -> Double -> Double
tCritical alpha df = 
    -- 简化版本，返回近似值
    if alpha < 0.05 then 2.0 else 1.96

-- 线性回归
data LinearRegression = LinearRegression {
    intercept :: Double,
    slope :: Double,
    rSquared :: Double,
    residuals :: [Double]
} deriving Show

-- 简单线性回归
simpleLinearRegression :: [Double] -> [Double] -> LinearRegression
simpleLinearRegression xs ys = let
    n = fromIntegral (length xs)
    xbar = sampleMean xs
    ybar = sampleMean ys
    numerator = sum [(x - xbar) * (y - ybar) | (x, y) <- zip xs ys]
    denominator = sum [(x - xbar)^2 | x <- xs]
    slope = numerator / denominator
    intercept = ybar - slope * xbar
    yhat = [intercept + slope * x | x <- xs]
    residuals = [y - yh | (y, yh) <- zip ys yhat]
    ssRes = sum [r^2 | r <- residuals]
    ssTot = sum [(y - ybar)^2 | y <- ys]
    rSquared = 1 - ssRes / ssTot
    in LinearRegression intercept slope rSquared residuals

-- 测试函数
testStatistics :: IO ()
testStatistics = do
    putStrLn "统计学基础测试："
    
    -- 测试描述统计
    let data1 = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
    let stats = descriptiveStatistics data1
    putStrLn $ "描述统计: " ++ show stats
    
    -- 测试t检验
    let test = tTest data1 5.0 0.05
    putStrLn $ "t检验结果: " ++ show test
    
    -- 测试置信区间
    let ci = meanConfidenceInterval data1 0.05
    putStrLn $ "置信区间: " ++ show ci
    
    -- 测试线性回归
    let x = [1, 2, 3, 4, 5]
    let y = [2, 4, 5, 4, 5]
    let reg = simpleLinearRegression x y
    putStrLn $ "线性回归: " ++ show reg
```

### 7.2 Rust实现

```rust
use std::collections::HashMap;

// 描述统计
#[derive(Debug)]
struct DescriptiveStats {
    mean: f64,
    median: f64,
    mode: f64,
    variance: f64,
    std_dev: f64,
    skewness: f64,
    kurtosis: f64,
}

// 假设检验
#[derive(Debug)]
struct HypothesisTest {
    test_statistic: f64,
    p_value: f64,
    critical_value: f64,
    decision: String,
}

// 置信区间
#[derive(Debug)]
struct ConfidenceInterval {
    lower_bound: f64,
    upper_bound: f64,
    confidence_level: f64,
}

// 线性回归
#[derive(Debug)]
struct LinearRegression {
    intercept: f64,
    slope: f64,
    r_squared: f64,
    residuals: Vec<f64>,
}

impl DescriptiveStats {
    fn new(data: &[f64]) -> Self {
        Self {
            mean: Self::sample_mean(data),
            median: Self::sample_median(data),
            mode: Self::sample_mode(data),
            variance: Self::sample_variance(data),
            std_dev: Self::sample_variance(data).sqrt(),
            skewness: Self::sample_skewness(data),
            kurtosis: Self::sample_kurtosis(data),
        }
    }
    
    fn sample_mean(data: &[f64]) -> f64 {
        data.iter().sum::<f64>() / data.len() as f64
    }
    
    fn sample_median(data: &[f64]) -> f64 {
        let mut sorted = data.to_vec();
        sorted.sort_by(|a, b| a.partial_cmp(b).unwrap());
        let n = sorted.len();
        if n % 2 == 0 {
            (sorted[n/2 - 1] + sorted[n/2]) / 2.0
        } else {
            sorted[n/2]
        }
    }
    
    fn sample_mode(data: &[f64]) -> f64 {
        let mut freq = HashMap::new();
        for &x in data {
            *freq.entry(x).or_insert(0) += 1;
        }
        freq.into_iter()
            .max_by_key(|&(_, count)| count)
            .map(|(value, _)| value)
            .unwrap_or(0.0)
    }
    
    fn sample_variance(data: &[f64]) -> f64 {
        let mu = Self::sample_mean(data);
        let n = data.len() as f64;
        data.iter()
            .map(|x| (x - mu).powi(2))
            .sum::<f64>() / (n - 1.0)
    }
    
    fn sample_skewness(data: &[f64]) -> f64 {
        let mu = Self::sample_mean(data);
        let s = Self::sample_variance(data).sqrt();
        let n = data.len() as f64;
        data.iter()
            .map(|x| ((x - mu) / s).powi(3))
            .sum::<f64>() / n
    }
    
    fn sample_kurtosis(data: &[f64]) -> f64 {
        let mu = Self::sample_mean(data);
        let s = Self::sample_variance(data).sqrt();
        let n = data.len() as f64;
        data.iter()
            .map(|x| ((x - mu) / s).powi(4))
            .sum::<f64>() / n - 3.0
    }
}

impl HypothesisTest {
    fn t_test(data: &[f64], mu0: f64, alpha: f64) -> Self {
        let n = data.len() as f64;
        let xbar = DescriptiveStats::sample_mean(data);
        let s = DescriptiveStats::sample_variance(data).sqrt();
        let t = (xbar - mu0) / (s / n.sqrt());
        let p = 2.0 * (1.0 - Self::t_distribution(t.abs(), n - 1.0));
        let critical = Self::t_critical(alpha / 2.0, n - 1.0);
        let decision = if t.abs() > critical { 
            "Reject H0".to_string() 
        } else { 
            "Accept H0".to_string() 
        };
        
        Self {
            test_statistic: t,
            p_value: p,
            critical_value: critical,
            decision,
        }
    }
    
    fn t_distribution(t: f64, df: f64) -> f64 {
        // 简化版本
        if t < 1.96 then 0.975 else 0.025
    }
    
    fn t_critical(alpha: f64, df: f64) -> f64 {
        // 简化版本
        if alpha < 0.05 then 2.0 else 1.96
    }
}

impl ConfidenceInterval {
    fn mean_confidence_interval(data: &[f64], alpha: f64) -> Self {
        let n = data.len() as f64;
        let xbar = DescriptiveStats::sample_mean(data);
        let s = DescriptiveStats::sample_variance(data).sqrt();
        let t = HypothesisTest::t_critical(alpha / 2.0, n - 1.0);
        let margin = t * s / n.sqrt();
        
        Self {
            lower_bound: xbar - margin,
            upper_bound: xbar + margin,
            confidence_level: 1.0 - alpha,
        }
    }
}

impl LinearRegression {
    fn simple_linear_regression(x: &[f64], y: &[f64]) -> Self {
        let n = x.len() as f64;
        let xbar = DescriptiveStats::sample_mean(x);
        let ybar = DescriptiveStats::sample_mean(y);
        
        let numerator: f64 = x.iter().zip(y.iter())
            .map(|(&xi, &yi)| (xi - xbar) * (yi - ybar))
            .sum();
        
        let denominator: f64 = x.iter()
            .map(|&xi| (xi - xbar).powi(2))
            .sum();
        
        let slope = numerator / denominator;
        let intercept = ybar - slope * xbar;
        
        let yhat: Vec<f64> = x.iter()
            .map(|&xi| intercept + slope * xi)
            .collect();
        
        let residuals: Vec<f64> = y.iter().zip(yhat.iter())
            .map(|(&yi, &yhi)| yi - yhi)
            .collect();
        
        let ss_res: f64 = residuals.iter().map(|r| r.powi(2)).sum();
        let ss_tot: f64 = y.iter().map(|&yi| (yi - ybar).powi(2)).sum();
        let r_squared = 1.0 - ss_res / ss_tot;
        
        Self {
            intercept,
            slope,
            r_squared,
            residuals,
        }
    }
}

// 测试函数
fn test_statistics() {
    println!("统计学基础测试：");
    
    // 测试描述统计
    let data1 = vec![1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0];
    let stats = DescriptiveStats::new(&data1);
    println!("描述统计: {:?}", stats);
    
    // 测试t检验
    let test = HypothesisTest::t_test(&data1, 5.0, 0.05);
    println!("t检验结果: {:?}", test);
    
    // 测试置信区间
    let ci = ConfidenceInterval::mean_confidence_interval(&data1, 0.05);
    println!("置信区间: {:?}", ci);
    
    // 测试线性回归
    let x = vec![1.0, 2.0, 3.0, 4.0, 5.0];
    let y = vec![2.0, 4.0, 5.0, 4.0, 5.0];
    let reg = LinearRegression::simple_linear_regression(&x, &y);
    println!("线性回归: {:?}", reg);
}

fn main() {
    test_statistics();
}
```

## 8. 习题与练习

### 8.1 基础练习

**练习 8.1.1**
计算以下描述统计量：

1. 样本均值、中位数、众数
2. 样本方差、标准差、变异系数
3. 样本偏度、峰度

**练习 8.1.2**
进行以下假设检验：

1. 正态总体均值的t检验
2. 正态总体方差的卡方检验
3. 两个正态总体均值差的t检验

**练习 8.1.3**
构造以下置信区间：

1. 正态总体均值的置信区间
2. 正态总体方差的置信区间
3. 大样本比例的置信区间

### 8.2 中级练习

**练习 8.2.1**
证明以下定理：

1. 最小二乘估计的无偏性
2. 最大似然估计的一致性
3. 中心极限定理在统计推断中的应用

**练习 8.2.2**
实现以下算法：

1. 多元线性回归算法
2. 逐步回归算法
3. 岭回归算法

**练习 8.2.3**
研究以下应用：

1. 回归诊断方法
2. 异常值检测
3. 模型选择准则

### 8.3 高级练习

**练习 8.3.1**
研究以下理论问题：

1. 广义线性模型
2. 非参数回归
3. 稳健统计方法

**练习 8.3.2**
实现以下高级算法：

1. 主成分分析
2. 因子分析
3. 聚类分析

**练习 8.3.3**
研究以下应用问题：

1. 统计学在机器学习中的应用
2. 统计学在生物统计学中的应用
3. 统计学在金融统计学中的应用

## 9. 参考文献

1. **Casella, G., Berger, R. L.** (2002). *Statistical Inference*. Duxbury.

2. **Rice, J. A.** (2006). *Mathematical Statistics and Data Analysis*. Duxbury.

3. **Hogg, R. V., McKean, J. W., Craig, A. T.** (2018). *Introduction to Mathematical Statistics*. Pearson.

4. **Montgomery, D. C., Peck, E. A., Vining, G. G.** (2012). *Introduction to Linear Regression Analysis*. Wiley.

5. **Kutner, M. H., Nachtsheim, C. J., Neter, J., Li, W.** (2004). *Applied Linear Regression Models*. McGraw-Hill.

6. **Draper, N. R., Smith, H.** (1998). *Applied Regression Analysis*. Wiley.

7. **Box, G. E. P., Hunter, W. G., Hunter, J. S.** (2005). *Statistics for Experimenters*. Wiley.

8. **Myers, R. H., Montgomery, D. C., Vining, G. G.** (2016). *Generalized Linear Models*. Wiley.

---

> **文档信息**
>
> - **创建时间**：2024年12月19日
> - **最后更新**：2024年12月19日
> - **版本**：1.0
> - **状态**：已完成
> - **下一步**：创建 05-假设检验.md
