# 03 - 条件概率与独立性

---

title: "条件概率与独立性"
date: 2025-07-03

---

## 1. 引言：信息改变概率

在现实世界中，我们很少在完全无知的情况下对不确定性进行推断。我们总能获得各种各样的信息，而这些新信息会改变我们对事件发生可能性的判断。例如，你预测明天是否下雨的概率，在看到天气预报（"有90%的可能形成降雨云团"）之后，会和你不知道这个信息时完全不同。

**条件概率 (Conditional Probability)** 就是用来量化这种"信息更新"过程的数学工具。它回答了这样一个核心问题：**在已知某个事件 B 已经发生的条件下，另一个事件 A 发生的概率是多少？**

与此相关，**独立性 (Independence)** 则描述了事件之间"互不相干"的特殊关系，即一个事件的发生与否，完全不影响另一个事件的概率。

## 2. 条件概率

**定义 (条件概率)**:
设 A 和 B 是两个事件，且 $P(B) > 0$。在给定事件 B 发生的条件下，事件 A 发生的**条件概率**定义为：
$$ P(A|B) = \frac{P(A \cap B)}{P(B)} $$

- **记号**: $P(A|B)$ 读作 "the probability of A given B" (在B条件下A的概率)。
- **直观理解**: 当我们知道事件 B 已经发生，我们的样本空间实际上从原来的 Ω "缩减" 到了 B。在这个新的、缩减的样本空间 B 中，我们关心的是原先 A 和 B 同时发生的部分 ($A \cap B$) 所占的"比例"。

**例子**:

- **试验**: 掷一个六面骰子，Ω = {1, 2, 3, 4, 5, 6}。
- **事件 A**: "点数是偶数" = {2, 4, 6}，$P(A) = 3/6 = 1/2$。
- **事件 B**: "点数大于3" = {4, 5, 6}，$P(B) = 3/6 = 1/2$。
- **事件 $A \cap B$**: "点数是偶数且大于3" = {4, 6}，$P(A \cap B) = 2/6 = 1/3$。

现在我们来计算条件概率 $P(A|B)$：
$P(A|B) = \frac{P(A \cap B)}{P(B)} = \frac{1/3}{1/2} = \frac{2}{3}$

这个结果非常直观：如果我们已经知道点数大于3（即结果是4, 5, 6中的一个），那么在这个新的样本空间 {4, 5, 6} 中，是偶数（4或6）的概率确实是 2/3。

### 乘法法则

由条件概率的定义直接变形，我们得到非常有用的**乘法法则 (Multiplication Rule)**:
$$ P(A \cap B) = P(B) \cdot P(A|B) $$
或者对称地：
$$ P(A \cap B) = P(A) \cdot P(B|A) $$

这个法则可以推广到多个事件，例如：
$P(A \cap B \cap C) = P(A) \cdot P(B|A) \cdot P(C|A \cap B)$
它常用于计算一个事件序列相继发生的概率。

## 3. 事件的独立性

**定义 (独立性)**:
如果事件 B 的发生与否，对事件 A 的概率没有任何影响，即 $P(A|B) = P(A)$，那么我们称事件 A **独立于**事件 B。

将 $P(A|B) = P(A)$ 代入乘法法则，我们就得到了独立性的标准定义：

> 两个事件 A 和 B 被称为是**相互独立的 (mutually independent)**，如果它们同时发生的概率等于它们各自概率的乘积：
> $$ P(A \cap B) = P(A) \cdot P(B) $$

- **注意**: **独立**与**互斥**是两个完全不同的概念！
  - **互斥**意味着 $A \cap B = \emptyset$，如果 $P(A)>0, P(B)>0$，那么 $P(A \cap B)=0$，而 $P(A)P(B)>0$。所以，两个概率不为零的事件**不可能**既互斥又独立。
  - 直观上，互斥是"有我没你"，一个的发生直接否定了另一个发生的可能性，这本身就是一种极强的关联性，而不是独立。

**例子**:

- **试验**: 连续掷两次硬币，Ω = {HH, HT, TH, TT}。
- **事件 A**: "第一次是正面" = {HH, HT}，$P(A) = 1/2$。
- **事件 B**: "第二次是正面" = {HH, TH}，$P(B) = 1/2$。
- **事件 $A \cap B$**: "两次都是正面" = {HH}，$P(A \cap B) = 1/4$。

我们来检验独立性：$P(A) \cdot P(B) = (1/2) \cdot (1/2) = 1/4$。
因为 $P(A \cap B) = P(A) \cdot P(B)$，所以事件 A 和 B 是相互独立的。这完全符合我们的直觉：第一次掷硬币的结果不应该影响第二次的结果。

**多个事件的独立性**:
对于三个事件 A, B, C，称它们相互独立需要满足：

- $P(A \cap B) = P(A)P(B)$
- $P(A \cap C) = P(A)P(C)$
- $P(B \cap C) = P(B)P(C)$
- $P(A \cap B \cap C) = P(A)P(B)P(C)$
必须所有条件都满足，仅仅两两独立是不够的。

## 4. 总结

条件概率和独立性是概率论从基础描述向量化推断迈出的关键一步。

- **条件概率 $P(A|B)$** 提供了一种量化方法，用于根据新信息 B 来更新我们对 A 的信念。它是贝叶斯定理和许多统计推断模型的基础。
- **独立性**则形式化了事件之间"无关联"的概念。这个概念在构建复杂概率模型时至关重要，因为它允许我们将复杂系统的联合概率分解为多个简单概率的乘积，从而大大简化计算。

理解这两个概念之间的区别与联系，是掌握概率思维的核心。

---
条件概率是信息时代的数学语言，它教会我们如何根据证据调整认知；而独立性则是构建复杂随机世界模型的基石，它让我们可以化繁为简。

[返回模块总览](./00-模块总览.md) | [返回上一级: 06-概率论与统计学总览](../00-06-概率论与统计学总览.md) | [返回项目总览](../../09-项目总览/00-项目总览.md)
