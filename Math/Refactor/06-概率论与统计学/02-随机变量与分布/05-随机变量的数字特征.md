---
title: "随机变量的数字特征"
date: 2025-07-02
---

## 1. 为什么需要数字特征？

一个随机变量的概率分布（无论是PMF还是PDF）为我们提供了关于该变量的**全部**概率信息。然而，分布函数本身往往比较复杂，不便于直接比较和评价。

在实际应用中，我们常常希望用几个简单的**数字**来概括和描述一个随机变量的主要特征。这些数字就是**数字特征 (Numerical Characteristics)**。它们就像一个人的身高、体重、年龄一样，虽然不能完全代表这个人，但能快速地抓住其核心特点。

本节我们介绍最重要的几类数字特征：

* **衡量集中趋势**: 期望 (Expectation)
* **衡量离散程度**: 方差 (Variance) 和标准差 (Standard Deviation)
* **衡量相关关系**: 协方差 (Covariance) 和相关系数 (Correlation)

## 2. 期望 (Expectation)

**期望**，又称**均值 (Mean)**，是衡量随机变量取值**中心位置**或**平均水平**的最重要的数字特征。它是在概率意义下的"加权平均值"，权重就是每个取值的概率。

### 2.1 定义

* **离散型随机变量 $X$**:
    $$ E(X) = \sum_i x_i P(X=x_i) $$

* **连续型随机变量 $X$**:
    $$ E(X) = \int_{-\infty}^{\infty} x f(x) \,dx $$

**重要性质**:
期望是线性算子。对于任意常数 $a, b$ 和随机变量 $X, Y$：

* $E(c) = c$
* $E(aX + b) = aE(X) + b$
* $E(X+Y) = E(X) + E(Y)$ (这个性质**不要求** $X,Y$ 相互独立)

## 3. 方差 (Variance) 和标准差 (Standard Deviation)

**方差**是衡量随机变量取值相对于其期望值的**离散程度**或**波动大小**的数字特征。方差越大，说明数据点越分散；方差越小，说明数据点越集中。

### 3.1 定义

方差 $Var(X)$ 或 $D(X)$ 定义为随机变量与期望之差的平方的期望值：
$$ Var(X) = E \left[ (X - E(X))^2 \right] $$

* **离散型**: $Var(X) = \sum_i (x_i - E(X))^2 P(X=x_i)$
* **连续型**: $Var(X) = \int_{-\infty}^{\infty} (x - E(X))^2 f(x) \,dx$

**计算公式**:
为了计算方便，方差通常使用以下公式进行计算，它避免了计算每个值与期望的差：
$$ Var(X) = E(X^2) - [E(X)]^2 $$

**标准差 (Standard Deviation)**:
由于方差的单位是原变量单位的平方（例如，身高的方差单位是"平方厘米"），为了得到与原变量单位一致的度量，我们对方差开方，得到**标准差**，记为 $\sigma(X)$。
$$ \sigma(X) = \sqrt{Var(X)} $$
标准差是实际应用中最常用的离散程度度量。

**重要性质**:

* $Var(c) = 0$
* $Var(aX+b) = a^2 Var(X)$
* 如果 $X, Y$ **相互独立**，则 $Var(X+Y) = Var(X) + Var(Y)$。（注意：独立性是必需的！）

## 4. 协方差 (Covariance) 和相关系数 (Correlation Coefficient)

期望和方差描述的是单个随机变量的特征。当我们处理多维随机变量时，我们需要一个指标来衡量两个变量之间的**线性相关关系**。这个指标就是**协方差**。

### 4.1 协方差 (Covariance)

<a id="covariance"></a>
**定义**:
协方差 $Cov(X, Y)$ 定义为：
$$ Cov(X, Y) = E \left[ (X-E(X))(Y-E(Y)) \right] $$
**计算公式**:
$$ Cov(X, Y) = E(XY) - E(X)E(Y) $$

**解读**:

* **$Cov(X, Y) > 0$**: 表示 $X$ 和 $Y$ 倾向于**同向变化**。即当一个变量取值高于其均值时，另一个变量也倾向于取值高于其均值。
* **$Cov(X, Y) < 0$**: 表示 $X$ 和 $Y$ 倾向于**反向变化**。
* **$Cov(X, Y) = 0$**: 表示 $X$ 和 $Y$ **线性无关**。

**重要结论**: 如果 $X$ 和 $Y$ **相互独立**，那么 $Cov(X, Y) = 0$。反之不一定成立！

### 4.2 相关系数 (Correlation Coefficient)

<a id="correlation"></a>
协方差的一个缺点是它的值受变量自身尺度的影响。例如，将身高从米换算成厘米，协方差的值会发生巨大变化。为了消除这种影响，得到一个标准化的、介于-1和1之间的关系度量，我们引入**相关系数**。

**定义**:
相关系数 $\rho(X, Y)$ 或 $Corr(X, Y)$ 定义为：
$$ \rho(X, Y) = \frac{Cov(X, Y)}{\sqrt{Var(X)} \sqrt{Var(Y)}} = \frac{Cov(X, Y)}{\sigma(X) \sigma(Y)} $$

**解读**:

* $\rho$ 的取值范围是 $[-1, 1]$。
* **$\rho = 1$**: 完全正线性相关。
* **$\rho = -1$**: 完全负线性相关。
* **$\rho = 0$**: 线性无关。
* $\rho$ 的绝对值越接近1，表示两个变量之间的**线性关系**越强。

相关系数是统计学和数据分析中衡量变量间关系的最重要的指标之一。

## 5. 总结

数字特征为我们提供了一种简洁而强大的方式来理解随机变量的概率分布。

* **期望 $E(X)$** 描述了分布的**中心**。
* **方差 $Var(X)$** 和**标准差 $\sigma(X)$** 描述了分布的**离散程度**。
* **协方差 $Cov(X, Y)$** 和**相关系数 $\rho(X, Y)$** 描述了两个变量之间的**线性相关性**。

这些数字特征是整个统计推断和机器学习领域的基础，让我们能够从数据中估计总体的性质，并建立预测模型。
