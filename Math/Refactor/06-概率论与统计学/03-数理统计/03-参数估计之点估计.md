# 03-参数估计之点估计

## 1. 参数估计的基本问题

在前面的章节中，我们确立了统计推断的基本框架：我们有一个总体，其分布依赖于某个或某些未知的**参数**（例如，正态分布的均值 $\mu$ 和方差 $\sigma^2$）。我们的任务是通过一个随机样本 $X_1, X_2, \dots, X_n$ 来对这些未知参数进行推断。

**参数估计 (Parameter Estimation)** 是统计推断的核心任务之一，它旨在为未知参数提供一个合理的估计值。参数估计分为两种：

*   **点估计 (Point Estimation)**：寻找一个**单一的数值**作为未知参数的最佳猜测。例如，用样本均值 $\bar{x}=175.2$ cm 来估计全体男性的平均身高 $\mu$。
*   **区间估计 (Interval Estimation)**：寻找一个**区间**，并期望该区间以很高的概率包含未知参数的真值。例如，我们有 95% 的信心认为，全体男性的平均身高 $\mu$ 在 $[174.5, 175.9]$ cm 之间。

本节我们首先关注点估计。

需要区分两个概念：
*   **估计量 (Estimator)**：用于计算估计值的**公式或方法**。它是一个以样本为自变量的函数（即一个统计量），例如样本均值 $\bar{X} = \frac{1}{n}\sum X_i$。
*   **估计值 (Estimate)**：根据一组具体的样本观测值计算出的**具体数值**。例如，$\bar{x}=175.2$。

那么，如何系统地找到好的估计量呢？我们介绍两种最重要的方法：矩估计法和极大似然估计法。

## 2. 矩估计法 (Method of Moments, MM)

矩估计法是一种非常古老且直观的参数估计方法。

### 2.1 核心思想

该方法基于一个简单的哲学思想：**样本是总体的代表，因此样本的矩应该约等于总体的矩**。

我们通过建立样本矩和总体矩之间的等式，然后反解出未知参数。

### 2.2 操作步骤

假设我们需要估计 $k$ 个未知参数 $\theta_1, \dots, \theta_k$。

1.  **计算总体矩**: 计算总体的前 $k$ 阶**原点矩**。这些矩通常是未知参数的函数。
    *   总体一阶原点矩: $\mu_1 = E[X]$
    *   总体二阶原点矩: $\mu_2 = E[X^2]$
    *   ...

2.  **计算样本矩**: 计算样本的前 $k$ 阶**原点矩**。
    *   样本一阶原点矩: $A_1 = \bar{X} = \frac{1}{n}\sum X_i$
    *   样本二阶原点矩: $A_2 = \frac{1}{n}\sum X_i^2$
    *   ...

3.  **联立求解**: 令总体矩等于对应的样本矩，建立方程组：
    $$
    \begin{cases}
    \mu_1(\theta_1, \dots, \theta_k) = A_1 \\
    \mu_2(\theta_1, \dots, \theta_k) = A_2 \\
    \vdots \\
    \mu_k(\theta_1, \dots, \theta_k) = A_k
    \end{cases}
    $$
    解这个方程组，得到的解 $\hat{\theta}_1, \dots, \hat{\theta}_k$ 就是参数的**矩估计量**。

### 2.3 示例

假设总体 $X \sim \text{Pois}(\lambda)$，我们想估计未知的参数 $\lambda$。
1.  **总体矩**: 泊松分布的期望是 $E[X] = \lambda$。我们只需要一个方程，所以用一阶矩就够了。
2.  **样本矩**: 样本一阶矩是 $\bar{X}$。
3.  **求解**: 令 $E[X] = \bar{X}$，我们得到 $\lambda = \bar{X}$。
    因此，参数 $\lambda$ 的矩估计量是 $\hat{\lambda}_{MM} = \bar{X}$。

矩估计法非常简单直观，但它不总是能得到"最好"的估计量。

## 3. 极大似然估计法 (Maximum Likelihood Estimation, MLE)

极大似然估计法是目前应用最广、理论性质也最好的参数估计方法。

### 3.1 核心思想

MLE 的思想非常巧妙，它采取一种"反向"的视角：**我们已经观测到了这组样本，那么什么样的参数值能让这组样本出现的概率最大呢？**

换句话说，我们寻找那个能最好地"解释"我们所观测到的数据的参数值。

### 3.2 似然函数

为了实现这个想法，我们首先需要定义一个函数来表示"在给定参数 $\theta$ 下，观测到当前样本的概率"。这个函数被称为**似然函数 (Likelihood Function)**。

对于一组独立同分布的样本观测值 $x_1, \dots, x_n$，其似然函数定义为样本联合概率密度（或质量）函数：

$$ L(\theta) = L(\theta \mid x_1, \dots, x_n) = \prod_{i=1}^n f(x_i; \theta) $$

其中 $f(x_i; \theta)$ 是总体分布的 PDF 或 PMF。注意，在这里，我们把样本观测值 $x_i$ 看作是固定的，而把参数 $\theta$ 看作是变量。

### 3.3 操作步骤

我们的目标是找到使 $L(\theta)$ 最大的 $\theta$ 值。

1.  **写出似然函数** $L(\theta)$。
2.  **取对数**: 由于连乘的导数很复杂，而 $L(\theta)$ 与 $\ln L(\theta)$ 在同一点取得最大值，我们通常最大化**对数似然函数 (Log-likelihood Function)**：
    $$ \ln L(\theta) = \sum_{i=1}^n \ln f(x_i; \theta) $$
3.  **求导**: 计算对数似然函数关于参数 $\theta$ 的导数。
4.  **求解**: 令导数等于 0，即解方程 $\frac{d}{d\theta} \ln L(\theta) = 0$。得到的解 $\hat{\theta}$ 就是**极大似然估计量**，记为 $\hat{\theta}_{MLE}$。

### 3.4 示例

再次假设总体 $X \sim \text{Pois}(\lambda)$。
1.  **似然函数**:
    $$ L(\lambda) = \prod_{i=1}^n \frac{\lambda^{x_i} e^{-\lambda}}{x_i!} = \frac{\lambda^{\sum x_i} e^{-n\lambda}}{\prod x_i!} $$
2.  **对数似然**:
    $$ \ln L(\lambda) = \left(\sum x_i\right) \ln\lambda - n\lambda - \ln\left(\prod x_i!\right) $$
3.  **求导**:
    $$ \frac{d}{d\lambda} \ln L(\lambda) = \frac{\sum x_i}{\lambda} - n $$
4.  **求解**: 令导数为 0，$\frac{\sum x_i}{\lambda} - n = 0$，解得 $\lambda = \frac{\sum x_i}{n} = \bar{x}$。
    因此，参数 $\lambda$ 的极大似然估计量是 $\hat{\lambda}_{MLE} = \bar{X}$。

在这个例子中，矩估计和极大似然估计给出了相同的结果，但这并非总是如此。

MLE 拥有许多优良的统计性质（如一致性、渐近正态性、渐近有效性等），这使其成为现代统计推断中最重要的方法。我们将在下一节讨论如何评价一个估计量的好坏。 