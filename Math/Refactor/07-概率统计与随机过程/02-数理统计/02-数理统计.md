# 数理统计

## 目录

- [数理统计](#数理统计)
  - [目录](#目录)
  - [1. 统计推断基础](#1-统计推断基础)
    - [1.1 总体与样本](#11-总体与样本)
    - [1.2 统计量](#12-统计量)
    - [1.3 抽样分布](#13-抽样分布)
    - [1.4 充分统计量](#14-充分统计量)
  - [2. 参数估计](#2-参数估计)
    - [2.1 点估计](#21-点估计)
    - [2.2 矩估计法](#22-矩估计法)
    - [2.3 最大似然估计](#23-最大似然估计)
    - [2.4 贝叶斯估计](#24-贝叶斯估计)
  - [3. 假设检验](#3-假设检验)
    - [3.1 假设检验的基本概念](#31-假设检验的基本概念)
    - [3.2 显著性检验](#32-显著性检验)
    - [3.3 似然比检验](#33-似然比检验)
    - [3.4 检验的功效](#34-检验的功效)
  - [4. 区间估计](#4-区间估计)
    - [4.1 置信区间](#41-置信区间)
    - [4.2 枢轴量法](#42-枢轴量法)
    - [4.3 大样本方法](#43-大样本方法)
  - [5. 回归分析](#5-回归分析)
    - [5.1 线性回归模型](#51-线性回归模型)
    - [5.2 最小二乘法](#52-最小二乘法)
    - [5.3 回归诊断](#53-回归诊断)
  - [6. 方差分析](#6-方差分析)
    - [6.1 单因素方差分析](#61-单因素方差分析)
    - [6.2 双因素方差分析](#62-双因素方差分析)
    - [6.3 多重比较](#63-多重比较)
  - [总结](#总结)

---

## 1. 统计推断基础

### 1.1 总体与样本

**定义 1.1.1** (总体)
**总体**是研究对象的全体，通常用一个随机变量 $X$ 来描述。

**定义 1.1.2** (样本)
从总体中抽取的 $n$ 个独立同分布的随机变量 $X_1, X_2, \ldots, X_n$ 称为**样本**，$n$ 称为**样本容量**。

**定义 1.1.3** (简单随机样本)
如果 $X_1, X_2, \ldots, X_n$ 独立同分布，则称为**简单随机样本**。

**定理 1.1.4** (样本的联合分布)
设 $X_1, X_2, \ldots, X_n$ 为来自总体 $X$ 的简单随机样本，则其联合概率密度函数为：
$$f_{X_1,X_2,\ldots,X_n}(x_1,x_2,\ldots,x_n) = \prod_{i=1}^{n} f_X(x_i)$$

### 1.2 统计量

**定义 1.2.1** (统计量)
样本 $X_1, X_2, \ldots, X_n$ 的函数 $T = T(X_1, X_2, \ldots, X_n)$ 称为**统计量**，如果 $T$ 不依赖于未知参数。

**定义 1.2.2** (样本均值)
$$\bar{X} = \frac{1}{n} \sum_{i=1}^{n} X_i$$

**定义 1.2.3** (样本方差)
$$S^2 = \frac{1}{n-1} \sum_{i=1}^{n} (X_i - \bar{X})^2$$

**定理 1.2.4** (样本均值的性质)
设 $X_1, X_2, \ldots, X_n$ 为来自总体 $X$ 的简单随机样本，$E[X] = \mu$，$\text{Var}(X) = \sigma^2$，则：

1. $E[\bar{X}] = \mu$
2. $\text{Var}(\bar{X}) = \frac{\sigma^2}{n}$

**证明**：

1. $E[\bar{X}] = E\left[\frac{1}{n} \sum_{i=1}^{n} X_i\right] = \frac{1}{n} \sum_{i=1}^{n} E[X_i] = \mu$
2. $\text{Var}(\bar{X}) = \text{Var}\left(\frac{1}{n} \sum_{i=1}^{n} X_i\right) = \frac{1}{n^2} \sum_{i=1}^{n} \text{Var}(X_i) = \frac{\sigma^2}{n}$

**定理 1.2.5** (样本方差的无偏性)
设 $X_1, X_2, \ldots, X_n$ 为来自总体 $X$ 的简单随机样本，$\text{Var}(X) = \sigma^2$，则：
$$E[S^2] = \sigma^2$$

**证明**：
$$E[S^2] = E\left[\frac{1}{n-1} \sum_{i=1}^{n} (X_i - \bar{X})^2\right] = \frac{1}{n-1} E\left[\sum_{i=1}^{n} X_i^2 - n\bar{X}^2\right]$$
$$= \frac{1}{n-1} \left[\sum_{i=1}^{n} E[X_i^2] - nE[\bar{X}^2]\right] = \frac{1}{n-1} \left[n(\sigma^2 + \mu^2) - n\left(\frac{\sigma^2}{n} + \mu^2\right)\right] = \sigma^2$$

### 1.3 抽样分布

**定义 1.3.1** (χ²分布)
设 $Z_1, Z_2, \ldots, Z_n$ 为独立同分布的标准正态随机变量，则：
$$X = \sum_{i=1}^{n} Z_i^2$$
服从**χ²分布**，记作 $X \sim \chi^2(n)$。

**定理 1.3.2** (χ²分布的性质)
设 $X \sim \chi^2(n)$，则：

1. $E[X] = n$
2. $\text{Var}(X) = 2n$
3. 如果 $X_1 \sim \chi^2(n_1)$，$X_2 \sim \chi^2(n_2)$ 且独立，则 $X_1 + X_2 \sim \chi^2(n_1 + n_2)$

**定义 1.3.3** (t分布)
设 $Z \sim N(0,1)$，$X \sim \chi^2(n)$ 且独立，则：
$$T = \frac{Z}{\sqrt{X/n}}$$
服从**t分布**，记作 $T \sim t(n)$。

**定理 1.3.4** (t分布的性质)
设 $T \sim t(n)$，则：

1. $E[T] = 0$ (当 $n > 1$)
2. $\text{Var}(T) = \frac{n}{n-2}$ (当 $n > 2$)
3. 当 $n \rightarrow \infty$ 时，$T$ 的分布趋近于标准正态分布

**定义 1.3.5** (F分布)
设 $X_1 \sim \chi^2(n_1)$，$X_2 \sim \chi^2(n_2)$ 且独立，则：
$$F = \frac{X_1/n_1}{X_2/n_2}$$
服从**F分布**，记作 $F \sim F(n_1,n_2)$。

**定理 1.3.6** (正态总体的抽样分布)
设 $X_1, X_2, \ldots, X_n$ 为来自正态总体 $N(\mu,\sigma^2)$ 的简单随机样本，则：

1. $\bar{X} \sim N\left(\mu, \frac{\sigma^2}{n}\right)$
2. $\frac{(n-1)S^2}{\sigma^2} \sim \chi^2(n-1)$
3. $\bar{X}$ 与 $S^2$ 独立
4. $\frac{\bar{X} - \mu}{S/\sqrt{n}} \sim t(n-1)$

### 1.4 充分统计量

**定义 1.4.1** (充分统计量)
统计量 $T = T(X_1, X_2, \ldots, X_n)$ 称为参数 $\theta$ 的**充分统计量**，如果给定 $T = t$ 的条件下，样本的条件分布不依赖于 $\theta$。

**定理 1.4.2** (因子分解定理)
统计量 $T$ 是参数 $\theta$ 的充分统计量当且仅当联合概率密度函数可以分解为：
$$f(x_1, x_2, \ldots, x_n; \theta) = g(T(x_1, x_2, \ldots, x_n); \theta) h(x_1, x_2, \ldots, x_n)$$
其中 $h$ 不依赖于 $\theta$。

**例 1.4.3** (正态分布的充分统计量)
设 $X_1, X_2, \ldots, X_n$ 为来自正态总体 $N(\mu,\sigma^2)$ 的样本，则 $(\bar{X}, S^2)$ 是 $(\mu,\sigma^2)$ 的充分统计量。

## 2. 参数估计

### 2.1 点估计

**定义 2.1.1** (估计量)
用于估计参数 $\theta$ 的统计量 $\hat{\theta} = \hat{\theta}(X_1, X_2, \ldots, X_n)$ 称为**估计量**。

**定义 2.1.2** (无偏估计)
如果 $E[\hat{\theta}] = \theta$，则称 $\hat{\theta}$ 为 $\theta$ 的**无偏估计**。

**定义 2.1.3** (均方误差)
估计量 $\hat{\theta}$ 的**均方误差**为：
$$\text{MSE}(\hat{\theta}) = E[(\hat{\theta} - \theta)^2] = \text{Var}(\hat{\theta}) + [\text{Bias}(\hat{\theta})]^2$$
其中 $\text{Bias}(\hat{\theta}) = E[\hat{\theta}] - \theta$ 称为**偏差**。

**定理 2.1.4** (克拉美-拉奥下界)
设 $X_1, X_2, \ldots, X_n$ 为来自总体 $f(x;\theta)$ 的样本，$\hat{\theta}$ 为 $\theta$ 的无偏估计，则：
$$\text{Var}(\hat{\theta}) \geq \frac{1}{nI(\theta)}$$
其中 $I(\theta) = E\left[\left(\frac{\partial \log f(X;\theta)}{\partial \theta}\right)^2\right]$ 称为**费舍信息量**。

### 2.2 矩估计法

**定义 2.2.1** (矩估计)
设总体 $X$ 的 $k$ 阶矩为 $\mu_k = E[X^k]$，样本的 $k$ 阶矩为 $\hat{\mu}_k = \frac{1}{n} \sum_{i=1}^{n} X_i^k$，则通过解方程组：
$$\mu_k(\theta) = \hat{\mu}_k, \quad k = 1, 2, \ldots$$
得到的解 $\hat{\theta}$ 称为**矩估计**。

**例 2.2.2** (正态分布的矩估计)
设 $X_1, X_2, \ldots, X_n$ 为来自正态总体 $N(\mu,\sigma^2)$ 的样本，则：
$$\hat{\mu} = \bar{X}, \quad \hat{\sigma}^2 = \frac{1}{n} \sum_{i=1}^{n} (X_i - \bar{X})^2$$

### 2.3 最大似然估计

**定义 2.3.1** (似然函数)
设 $X_1, X_2, \ldots, X_n$ 为来自总体 $f(x;\theta)$ 的样本，则：
$$L(\theta) = \prod_{i=1}^{n} f(X_i;\theta)$$
称为**似然函数**。

**定义 2.3.2** (最大似然估计)
使得似然函数达到最大值的参数值 $\hat{\theta}$ 称为**最大似然估计**：
$$\hat{\theta} = \arg\max_{\theta} L(\theta)$$

**定理 2.3.3** (最大似然估计的性质)
在正则条件下，最大似然估计具有以下性质：

1. 相合性：$\hat{\theta} \xrightarrow{P} \theta$
2. 渐近正态性：$\sqrt{n}(\hat{\theta} - \theta) \xrightarrow{d} N(0, I^{-1}(\theta))$
3. 渐近有效性：达到克拉美-拉奥下界

**例 2.3.4** (正态分布的最大似然估计)
设 $X_1, X_2, \ldots, X_n$ 为来自正态总体 $N(\mu,\sigma^2)$ 的样本，则：
$$\hat{\mu} = \bar{X}, \quad \hat{\sigma}^2 = \frac{1}{n} \sum_{i=1}^{n} (X_i - \bar{X})^2$$

### 2.4 贝叶斯估计

**定义 2.4.1** (先验分布)
参数 $\theta$ 的**先验分布** $\pi(\theta)$ 表示在获得数据之前对 $\theta$ 的认识。

**定义 2.4.2** (后验分布)
给定数据后，参数 $\theta$ 的**后验分布**为：
$$\pi(\theta|x_1, x_2, \ldots, x_n) = \frac{f(x_1, x_2, \ldots, x_n|\theta)\pi(\theta)}{\int f(x_1, x_2, \ldots, x_n|\theta)\pi(\theta) d\theta}$$

**定义 2.4.3** (贝叶斯估计)
后验分布的均值、中位数或众数可以作为**贝叶斯估计**。

**例 2.4.4** (正态分布的贝叶斯估计)
设 $X_1, X_2, \ldots, X_n$ 为来自正态总体 $N(\mu,\sigma^2)$ 的样本，$\sigma^2$ 已知，$\mu$ 的先验分布为 $N(\mu_0, \tau^2)$，则 $\mu$ 的后验分布为：
$$N\left(\frac{\frac{n\bar{x}}{\sigma^2} + \frac{\mu_0}{\tau^2}}{\frac{n}{\sigma^2} + \frac{1}{\tau^2}}, \frac{1}{\frac{n}{\sigma^2} + \frac{1}{\tau^2}}\right)$$

## 3. 假设检验

### 3.1 假设检验的基本概念

**定义 3.1.1** (原假设与备择假设)

- **原假设** $H_0$：通常表示"无效应"或"无差异"
- **备择假设** $H_1$：通常表示"有效应"或"有差异"

**定义 3.1.2** (检验统计量)
用于检验假设的统计量 $T = T(X_1, X_2, \ldots, X_n)$ 称为**检验统计量**。

**定义 3.1.3** (拒绝域)
使得拒绝原假设的样本空间子集 $R$ 称为**拒绝域**。

**定义 3.1.4** (两类错误)

- **第一类错误**：拒绝真原假设，概率为 $\alpha$
- **第二类错误**：接受假原假设，概率为 $\beta$

**定义 3.1.5** (显著性水平)
第一类错误的概率 $\alpha$ 称为**显著性水平**。

### 3.2 显著性检验

**定义 3.2.1** (p值)
**p值**是在原假设为真的条件下，观察到比当前样本更极端结果的概率。

**定理 3.2.2** (p值的性质)

1. 在原假设为真时，p值服从均匀分布 $U(0,1)$
2. p值越小，拒绝原假设的证据越强

**例 3.2.3** (正态总体均值的检验)
设 $X_1, X_2, \ldots, X_n$ 为来自正态总体 $N(\mu,\sigma^2)$ 的样本，$\sigma^2$ 未知，检验 $H_0: \mu = \mu_0$ vs $H_1: \mu \neq \mu_0$。

检验统计量：
$$T = \frac{\bar{X} - \mu_0}{S/\sqrt{n}} \sim t(n-1)$$

拒绝域：
$$R = \{|T| > t_{\alpha/2}(n-1)\}$$

### 3.3 似然比检验

**定义 3.3.1** (似然比)
**似然比**为：
$$\Lambda = \frac{\sup_{\theta \in \Theta_0} L(\theta)}{\sup_{\theta \in \Theta} L(\theta)}$$

**定义 3.3.2** (似然比检验)
基于似然比的检验称为**似然比检验**，拒绝域为：
$$R = \{\Lambda < c\}$$
其中 $c$ 由显著性水平确定。

**定理 3.3.3** (似然比检验的渐近分布)
在原假设下，$-2\log\Lambda \xrightarrow{d} \chi^2(r)$，其中 $r$ 是约束条件的个数。

### 3.4 检验的功效

**定义 3.4.1** (功效函数)
**功效函数** $\beta(\theta) = P(\text{拒绝} H_0 | \theta)$ 表示在参数值为 $\theta$ 时拒绝原假设的概率。

**定义 3.4.2** (检验的功效)
在备择假设下拒绝原假设的概率 $1 - \beta$ 称为**检验的功效**。

**定理 3.4.3** (奈曼-皮尔逊引理)
对于简单假设 $H_0: \theta = \theta_0$ vs $H_1: \theta = \theta_1$，似然比检验是最优的。

## 4. 区间估计

### 4.1 置信区间

**定义 4.1.1** (置信区间)
设 $\theta$ 为未知参数，$L = L(X_1, X_2, \ldots, X_n)$ 和 $U = U(X_1, X_2, \ldots, X_n)$ 为统计量，如果：
$$P(L \leq \theta \leq U) = 1 - \alpha$$
则称 $[L, U]$ 为 $\theta$ 的**置信水平为 $1-\alpha$ 的置信区间**。

**定理 4.1.2** (正态总体均值的置信区间)
设 $X_1, X_2, \ldots, X_n$ 为来自正态总体 $N(\mu,\sigma^2)$ 的样本，$\sigma^2$ 未知，则 $\mu$ 的置信水平为 $1-\alpha$ 的置信区间为：
$$\left[\bar{X} - t_{\alpha/2}(n-1)\frac{S}{\sqrt{n}}, \bar{X} + t_{\alpha/2}(n-1)\frac{S}{\sqrt{n}}\right]$$

### 4.2 枢轴量法

**定义 4.2.1** (枢轴量)
**枢轴量**是包含参数 $\theta$ 和样本的统计量，其分布不依赖于 $\theta$。

**例 4.2.2** (正态总体均值的枢轴量)
设 $X_1, X_2, \ldots, X_n$ 为来自正态总体 $N(\mu,\sigma^2)$ 的样本，$\sigma^2$ 未知，则：
$$T = \frac{\bar{X} - \mu}{S/\sqrt{n}} \sim t(n-1)$$
是枢轴量。

### 4.3 大样本方法

**定理 4.3.1** (大样本置信区间)
设 $\hat{\theta}$ 为参数 $\theta$ 的相合估计，$\text{Var}(\hat{\theta}) \approx \frac{\sigma^2}{n}$，则 $\theta$ 的大样本置信区间为：
$$\left[\hat{\theta} - z_{\alpha/2}\frac{\sigma}{\sqrt{n}}, \hat{\theta} + z_{\alpha/2}\frac{\sigma}{\sqrt{n}}\right]$$

## 5. 回归分析

### 5.1 线性回归模型

**定义 5.1.1** (简单线性回归模型)
$$Y_i = \beta_0 + \beta_1 X_i + \epsilon_i, \quad i = 1, 2, \ldots, n$$
其中 $\epsilon_i \sim N(0,\sigma^2)$ 且独立。

**定义 5.1.2** (多元线性回归模型)
$$Y_i = \beta_0 + \beta_1 X_{i1} + \beta_2 X_{i2} + \cdots + \beta_p X_{ip} + \epsilon_i, \quad i = 1, 2, \ldots, n$$

**定理 5.1.3** (线性回归的矩阵形式)
$$Y = X\beta + \epsilon$$
其中 $Y = (Y_1, Y_2, \ldots, Y_n)^T$，$X$ 为设计矩阵，$\beta = (\beta_0, \beta_1, \ldots, \beta_p)^T$，$\epsilon = (\epsilon_1, \epsilon_2, \ldots, \epsilon_n)^T$。

### 5.2 最小二乘法

**定义 5.2.1** (最小二乘估计)
使得残差平方和最小的参数估计：
$$\hat{\beta} = \arg\min_{\beta} \sum_{i=1}^{n} (Y_i - X_i^T\beta)^2$$

**定理 5.2.2** (最小二乘估计的显式解)
$$\hat{\beta} = (X^TX)^{-1}X^TY$$

**证明**：
设 $Q(\beta) = (Y - X\beta)^T(Y - X\beta)$，则：
$$\frac{\partial Q}{\partial \beta} = -2X^T(Y - X\beta) = 0$$
因此 $X^TX\beta = X^TY$，即 $\hat{\beta} = (X^TX)^{-1}X^TY$。

**定理 5.2.3** (最小二乘估计的性质)

1. 无偏性：$E[\hat{\beta}] = \beta$
2. 协方差矩阵：$\text{Cov}(\hat{\beta}) = \sigma^2(X^TX)^{-1}$
3. 高斯-马尔可夫定理：在无偏线性估计中，最小二乘估计方差最小

### 5.3 回归诊断

**定义 5.3.1** (残差)
**残差**为：
$$e_i = Y_i - \hat{Y}_i = Y_i - X_i^T\hat{\beta}$$

**定义 5.3.2** (标准化残差)
**标准化残差**为：
$$r_i = \frac{e_i}{\hat{\sigma}\sqrt{1-h_{ii}}}$$
其中 $h_{ii}$ 为帽子矩阵 $H = X(X^TX)^{-1}X^T$ 的第 $i$ 个对角元素。

**定理 5.3.3** (残差的性质)

1. $\sum_{i=1}^{n} e_i = 0$
2. $\sum_{i=1}^{n} e_i X_i = 0$
3. $E[e_i] = 0$
4. $\text{Var}(e_i) = \sigma^2(1-h_{ii})$

## 6. 方差分析

### 6.1 单因素方差分析

**定义 6.1.1** (单因素方差分析模型)
$$Y_{ij} = \mu + \alpha_i + \epsilon_{ij}, \quad i = 1, 2, \ldots, k, \quad j = 1, 2, \ldots, n_i$$
其中 $\epsilon_{ij} \sim N(0,\sigma^2)$ 且独立，$\sum_{i=1}^{k} \alpha_i = 0$。

**定义 6.1.2** (总平方和分解)
$$SST = SSB + SSW$$
其中：

- $SST = \sum_{i=1}^{k} \sum_{j=1}^{n_i} (Y_{ij} - \bar{Y})^2$ (总平方和)
- $SSB = \sum_{i=1}^{k} n_i(\bar{Y}_i - \bar{Y})^2$ (组间平方和)
- $SSW = \sum_{i=1}^{k} \sum_{j=1}^{n_i} (Y_{ij} - \bar{Y}_i)^2$ (组内平方和)

**定理 6.1.3** (F统计量)
在原假设 $H_0: \alpha_1 = \alpha_2 = \cdots = \alpha_k = 0$ 下：
$$F = \frac{SSB/(k-1)}{SSW/(n-k)} \sim F(k-1, n-k)$$

### 6.2 双因素方差分析

**定义 6.2.1** (双因素方差分析模型)
$$Y_{ijk} = \mu + \alpha_i + \beta_j + (\alpha\beta)_{ij} + \epsilon_{ijk}$$
其中 $\epsilon_{ijk} \sim N(0,\sigma^2)$ 且独立。

**定理 6.2.2** (双因素方差分析的F检验)
分别检验主效应和交互效应：
$$F_A = \frac{SSA/(a-1)}{SSE/(n-ab)} \sim F(a-1, n-ab)$$
$$F_B = \frac{SSB/(b-1)}{SSE/(n-ab)} \sim F(b-1, n-ab)$$
$$F_{AB} = \frac{SSAB/((a-1)(b-1))}{SSE/(n-ab)} \sim F((a-1)(b-1), n-ab)$$

### 6.3 多重比较

**定义 6.3.1** (多重比较问题)
当进行多个假设检验时，需要控制整体显著性水平。

**定理 6.3.2** (邦费罗尼校正)
如果进行 $m$ 个检验，每个检验的显著性水平设为 $\alpha/m$，则整体显著性水平不超过 $\alpha$。

**定义 6.3.3** (图基方法)
对于所有成对比较，使用学生化极差分布进行校正。

---

## 总结

数理统计是研究如何从数据中提取信息和进行推断的理论，从统计推断基础、参数估计、假设检验，到区间估计、回归分析和方差分析，建立了完整的理论体系。

这些理论在实际应用中发挥着重要作用，为科学研究、工程实践、经济分析等领域提供了强有力的工具。数理统计的发展推动了数据科学和机器学习的进步，是现代科学不可或缺的重要组成部分。

---

**参考文献**：

1. Casella, G., & Berger, R. L. (2002). Statistical Inference. Duxbury.
2. Hogg, R. V., McKean, J. W., & Craig, A. T. (2019). Introduction to Mathematical Statistics. Pearson.
3. Lehmann, E. L., & Casella, G. (1998). Theory of Point Estimation. Springer.
4. Lehmann, E. L., & Romano, J. P. (2005). Testing Statistical Hypotheses. Springer.
