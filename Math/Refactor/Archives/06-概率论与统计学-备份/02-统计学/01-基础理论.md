# 统计学：数据科学的数学基础

## 目录

- [统计学：数据科学的数学基础](#统计学数据科学的数学基础)
  - [目录](#目录)
  - [1. 引言：统计学的历史与发展](#1-引言统计学的历史与发展)
  - [2. 描述性统计](#2-描述性统计)
    - [2.1 集中趋势](#21-集中趋势)
    - [2.2 离散程度](#22-离散程度)
    - [2.3 分布形状](#23-分布形状)
  - [3. 概率论基础](#3-概率论基础)
    - [3.1 概率空间](#31-概率空间)
    - [3.2 条件概率](#32-条件概率)
    - [3.3 独立性](#33-独立性)
  - [4. 随机变量](#4-随机变量)
    - [4.1 离散随机变量](#41-离散随机变量)
    - [4.2 连续随机变量](#42-连续随机变量)
    - [4.3 随机向量](#43-随机向量)
  - [5. 抽样理论](#5-抽样理论)
    - [5.1 抽样分布](#51-抽样分布)
    - [5.2 中心极限定理](#52-中心极限定理)
    - [5.3 大数定律](#53-大数定律)
  - [6. 统计推断](#6-统计推断)
    - [6.1 点估计](#61-点估计)
    - [6.2 区间估计](#62-区间估计)
    - [6.3 假设检验](#63-假设检验)
  - [7. 回归分析](#7-回归分析)
    - [7.1 线性回归](#71-线性回归)
    - [7.2 多元回归](#72-多元回归)
    - [7.3 非线性回归](#73-非线性回归)
  - [8. 方差分析](#8-方差分析)
    - [8.1 单因素方差分析](#81-单因素方差分析)
    - [8.2 多因素方差分析](#82-多因素方差分析)
    - [8.3 协方差分析](#83-协方差分析)
  - [9. 非参数统计](#9-非参数统计)
    - [9.1 秩检验](#91-秩检验)
    - [9.2 符号检验](#92-符号检验)
    - [9.3 分布检验](#93-分布检验)
  - [10. 贝叶斯统计](#10-贝叶斯统计)
    - [10.1 贝叶斯定理](#101-贝叶斯定理)
    - [10.2 先验分布](#102-先验分布)
    - [10.3 后验分布](#103-后验分布)
  - [11. 时间序列分析](#11-时间序列分析)
    - [11.1 平稳性](#111-平稳性)
    - [11.2 ARIMA模型](#112-arima模型)
    - [11.3 预测](#113-预测)
  - [12. 应用领域](#12-应用领域)
    - [12.1 社会科学](#121-社会科学)
    - [12.2 自然科学](#122-自然科学)
    - [12.3 工程应用](#123-工程应用)
  - [参考文献](#参考文献)

## 1. 引言：统计学的历史与发展

统计学是收集、分析、解释和呈现数据的科学。
它提供了一套系统的方法来处理不确定性，是现代数据科学的核心基础。

**历史背景**：
统计学的起源可以追溯到17世纪，最初用于人口统计和政府管理。
19世纪，高斯、拉普拉斯等人建立了概率论的基础。
20世纪，费希尔、皮尔逊等人发展了现代统计推断理论。

**核心思想**：
统计学的基本思想是通过样本数据推断总体特征，处理随机性和不确定性。
它强调数据的科学收集、分析和解释。

**现代意义**：
今天，统计学不仅在科学研究中有重要应用，在商业、医学、社会科学等领域也发挥着关键作用。

## 2. 描述性统计

### 2.1 集中趋势

**算术平均数**：
x̄ = (1/n)Σ_{i=1}^n x_i

**中位数**：
将数据按大小排序后的中间值。

**众数**：
数据中出现频率最高的值。

**几何平均数**：
G = (Π_{i=1}^n x_i)^{1/n}

**调和平均数**：
H = n/(Σ_{i=1}^n 1/x_i)

**集中趋势的选择**：

- 对称分布：均值、中位数、众数相等
- 偏态分布：中位数比均值更稳健
- 分类数据：众数最合适

### 2.2 离散程度

**方差**：
s² = (1/(n-1))Σ_{i=1}^n (x_i - x̄)²

**标准差**：
s = √s²

**变异系数**：
CV = s/|x̄|

**四分位距**：
IQR = Q₃ - Q₁

**极差**：
R = x_max - x_min

**离散程度的比较**：

- 标准差：最常用的离散程度度量
- 四分位距：对异常值不敏感
- 变异系数：无量纲的相对离散程度

### 2.3 分布形状

**偏度**：
衡量分布的对称性：
γ₁ = (1/n)Σ_{i=1}^n [(x_i - x̄)/s]³

**峰度**：
衡量分布的尖峭程度：
γ₂ = (1/n)Σ_{i=1}^n [(x_i - x̄)/s]⁴ - 3

**分布类型**：

- 正态分布：对称，钟形
- 偏态分布：左偏或右偏
- 双峰分布：有两个众数

**正态性检验**：

- 直方图
- Q-Q图
- 夏皮罗-威尔克检验

## 3. 概率论基础

### 3.1 概率空间

**样本空间**：
随机试验所有可能结果的集合Ω。

**事件**：
样本空间的子集A⊆Ω。

**概率测度**：
函数P:ℱ→[0,1]，满足：

1. P(Ω) = 1
2. 对于互斥事件A₁,A₂,...，有P(∪A_i) = ΣP(A_i)

**概率公理**：

- 非负性：P(A) ≥ 0
- 规范性：P(Ω) = 1
- 可加性：对于互斥事件A,B，P(A∪B) = P(A) + P(B)

### 3.2 条件概率

**条件概率的定义**：
P(A|B) = P(A∩B)/P(B)，其中P(B) > 0。

**乘法公式**：
P(A∩B) = P(A|B)P(B) = P(B|A)P(A)

**全概率公式**：
如果B₁,B₂,...,B_n是Ω的划分，则：
P(A) = Σ_{i=1}^n P(A|B_i)P(B_i)

**贝叶斯公式**：
P(B_i|A) = P(A|B_i)P(B_i)/Σ_{j=1}^n P(A|B_j)P(B_j)

### 3.3 独立性

**事件的独立性**：
事件A和B独立，如果P(A∩B) = P(A)P(B)。

**条件独立性**：
给定事件C，事件A和B条件独立，如果：
P(A∩B|C) = P(A|C)P(B|C)

**独立性的性质**：

- 如果A和B独立，则A和B^c也独立
- 独立性不传递
- 独立性在条件概率下可能改变

## 4. 随机变量

### 4.1 离散随机变量

**离散随机变量**：
取值可数的随机变量X。

**概率质量函数**：
p(x) = P(X = x)

**累积分布函数**：
F(x) = P(X ≤ x) = Σ_{y≤x} p(y)

**期望**：
E[X] = Σ_x x p(x)

**方差**：
Var(X) = E[(X - E[X])²] = E[X²] - (E[X])²

**常见离散分布**：

- 伯努利分布：B(1,p)
- 二项分布：B(n,p)
- 泊松分布：Poisson(λ)
- 几何分布：Geometric(p)

### 4.2 连续随机变量

**连续随机变量**：
取值连续的随机变量X。

**概率密度函数**：
f(x) ≥ 0，∫_{-∞}^∞ f(x)dx = 1

**累积分布函数**：
F(x) = P(X ≤ x) = ∫_{-∞}^x f(t)dt

**期望**：
E[X] = ∫_{-∞}^∞ x f(x)dx

**方差**：
Var(X) = ∫_{-∞}^∞ (x - E[X])² f(x)dx

**常见连续分布**：

- 均匀分布：U(a,b)
- 正态分布：N(μ,σ²)
- 指数分布：Exp(λ)
- 伽马分布：Gamma(α,β)

### 4.3 随机向量

**随机向量**：
X = (X₁,X₂,...,X_n)

**联合分布**：

- 离散：p(x₁,x₂,...,x_n) = P(X₁=x₁,X₂=x₂,...,X_n=x_n)
- 连续：f(x₁,x₂,...,x_n)

**边缘分布**：

- 离散：p₁(x₁) = Σ_{x₂,...,x_n} p(x₁,x₂,...,x_n)
- 连续：f₁(x₁) = ∫...∫ f(x₁,x₂,...,x_n)dx₂...dx_n

**协方差**：
Cov(X,Y) = E[(X - E[X])(Y - E[Y])]

**相关系数**：
ρ(X,Y) = Cov(X,Y)/√(Var(X)Var(Y))

## 5. 抽样理论

### 5.1 抽样分布

**统计量**：
样本的函数T(X₁,X₂,...,X_n)。

**抽样分布**：
统计量的概率分布。

**样本均值**：
X̄ = (1/n)Σ_{i=1}^n X_i

**样本方差**：
S² = (1/(n-1))Σ_{i=1}^n (X_i - X̄)²

**样本均值的分布**：
如果X_i ~ N(μ,σ²)，则X̄ ~ N(μ,σ²/n)

**样本方差的分布**：
如果X_i ~ N(μ,σ²)，则(n-1)S²/σ² ~ χ²(n-1)

### 5.2 中心极限定理

**中心极限定理**：
设X₁,X₂,...,X_n是独立同分布的随机变量，E[X_i] = μ，Var(X_i) = σ²，则：
√n(X̄ - μ)/σ → N(0,1) (n→∞)

**应用**：

- 大样本推断
- 近似计算
- 质量控制

**收敛速度**：

- 正态分布：最快
- 对称分布：较快
- 偏态分布：较慢

### 5.3 大数定律

**弱大数定律**：
X̄ → μ (概率收敛)

**强大数定律**：
X̄ → μ (几乎必然收敛)

**切比雪夫大数定律**：
对于任意ε > 0，P(|X̄ - μ| ≥ ε) → 0 (n→∞)

**应用**：

- 频率解释概率
- 蒙特卡罗方法
- 统计估计

## 6. 统计推断

### 6.1 点估计

**估计量**：
用于估计参数的统计量θ̂。

**无偏性**：
E[θ̂] = θ

**有效性**：
在无偏估计量中，方差最小的估计量最有效。

**一致性**：
θ̂ → θ (概率收敛)

**最大似然估计**：
θ̂_MLE = argmax L(θ|X)

**矩估计**：
通过样本矩估计总体矩。

### 6.2 区间估计

**置信区间**：
随机区间[L(X),U(X)]，使得P(θ∈[L(X),U(X)]) = 1-α。

**置信水平**：
1-α，通常取0.95或0.99。

**正态总体均值的置信区间**：

- 方差已知：X̄ ± z_{α/2}σ/√n
- 方差未知：X̄ ± t_{α/2,n-1}S/√n

**置信区间的解释**：
在重复抽样中，100(1-α)%的置信区间包含真参数。

### 6.3 假设检验

**原假设H₀**：
要检验的假设，通常表示"无效应"。

**备择假设H₁**：
与原假设对立的假设。

**显著性水平α**：
犯第一类错误的概率。

**检验统计量**：
用于检验假设的统计量T。

**p值**：
在原假设下，观察到的统计量至少与样本统计量一样极端的概率。

**决策规则**：

- 如果p值 < α，拒绝H₀
- 如果p值 ≥ α，不拒绝H₀

## 7. 回归分析

### 7.1 线性回归

**简单线性回归模型**：
Y = β₀ + β₁X + ε

**最小二乘估计**：
β̂₁ = Σ(x_i - x̄)(y_i - ȳ)/Σ(x_i - x̄)²
β̂₀ = ȳ - β̂₁x̄

**回归方程**：
Ŷ = β̂₀ + β̂₁X

**残差**：
e_i = y_i - ŷ_i

**决定系数**：
R² = 1 - Σe_i²/Σ(y_i - ȳ)²

### 7.2 多元回归

**多元线性回归模型**：
Y = β₀ + β₁X₁ + β₂X₂ + ... + β_kX_k + ε

**矩阵形式**：
Y = Xβ + ε

**最小二乘估计**：
β̂ = (X'X)^(-1)X'Y

**多重决定系数**：
R² = 1 - SSE/SST

**调整决定系数**：
R²_adj = 1 - (1-R²)(n-1)/(n-k-1)

### 7.3 非线性回归

**非线性回归模型**：
Y = f(X,β) + ε

**参数估计**：
通常使用迭代方法，如高斯-牛顿法。

**常见非线性函数**：

- 指数函数：Y = ae^(bx)
- 对数函数：Y = a + b ln(X)
- 幂函数：Y = ax^b

**模型选择**：

- 残差分析
- 信息准则（AIC、BIC）
- 交叉验证

## 8. 方差分析

### 8.1 单因素方差分析

**单因素ANOVA模型**：
Y_ij = μ + α_i + ε_ij

**假设**：

- H₀：α₁ = α₂ = ... = α_k = 0
- H₁：至少有一个α_i ≠ 0

**F统计量**：
F = MSB/MSE

**方差分解**：
SST = SSB + SSE

**事后检验**：

- LSD检验
- Tukey检验
- Scheffe检验

### 8.2 多因素方差分析

**双因素ANOVA模型**：
Y_ijk = μ + α_i + β_j + (αβ)_ij + ε_ijk

**主效应**：
α_i：因素A的效应
β_j：因素B的效应

**交互效应**：
(αβ)_ij：因素A和B的交互效应

**方差分解**：
SST = SSA + SSB + SSAB + SSE

### 8.3 协方差分析

**ANCOVA模型**：
Y_ij = μ + α_i + βX_ij + ε_ij

**协变量**：
X_ij：连续变量，用于控制混杂因素。

**调整均值**：
考虑协变量影响后的组均值。

**应用**：

- 控制混杂因素
- 提高检验功效
- 减少实验误差

## 9. 非参数统计

### 9.1 秩检验

**Wilcoxon符号秩检验**：
用于配对样本的中位数检验。

**Mann-Whitney U检验**：
用于两个独立样本的位置检验。

**Kruskal-Wallis检验**：
用于多个独立样本的位置检验。

**秩相关**：

- Spearman秩相关
- Kendall τ相关

### 9.2 符号检验

**符号检验**：
基于正负号的非参数检验。

**中位数检验**：
检验总体中位数是否等于指定值。

**配对符号检验**：
检验配对差的中位数是否为零。

**优点**：

- 对异常值不敏感
- 不需要分布假设
- 计算简单

### 9.3 分布检验

**Kolmogorov-Smirnov检验**：
检验样本是否来自指定分布。

**Anderson-Darling检验**：
改进的分布拟合检验。

**Shapiro-Wilk检验**：
专门用于正态性检验。

**卡方拟合优度检验**：
检验分类数据的分布。

## 10. 贝叶斯统计

### 10.1 贝叶斯定理

**贝叶斯定理**：
P(θ|X) = P(X|θ)P(θ)/P(X)

**后验分布**：
P(θ|X)：给定数据后参数的概率分布。

**似然函数**：
P(X|θ)：给定参数下数据的概率。

**先验分布**：
P(θ)：参数的先验信念。

### 10.2 先验分布

**共轭先验**：
后验分布与先验分布属于同一族。

**无信息先验**：
表示对参数无先验知识的分布。

**Jeffreys先验**：
基于Fisher信息的无信息先验。

**主观先验**：
基于专家知识的先验分布。

### 10.3 后验分布

**后验均值**：
E[θ|X] = ∫θP(θ|X)dθ

**后验方差**：
Var(θ|X) = E[(θ - E[θ|X])²|X]

**可信区间**：
后验分布的置信区间。

**贝叶斯因子**：
比较两个假设的相对支持度。

## 11. 时间序列分析

### 11.1 平稳性

**严格平稳**：
联合分布不随时间变化。

**弱平稳**：
均值和自协方差函数不随时间变化。

**趋势**：
时间序列的长期变化模式。

**季节性**：
周期性的变化模式。

**随机游走**：
X_t = X_{t-1} + ε_t

### 11.2 ARIMA模型

**AR(p)模型**：
X_t = φ₁X_{t-1} + φ₂X_{t-2} + ... + φ_pX_{t-p} + ε_t

**MA(q)模型**：
X_t = ε_t + θ₁ε_{t-1} + θ₂ε_{t-2} + ... + θ_qε_{t-q}

**ARIMA(p,d,q)模型**：
差分d次后的ARMA(p,q)模型。

**模型识别**：

- ACF：自相关函数
- PACF：偏自相关函数

### 11.3 预测

**点预测**：
预测未来值的最佳估计。

**区间预测**：
预测的置信区间。

**预测误差**：
实际值与预测值的差。

**预测评价**：

- MSE：均方误差
- MAE：平均绝对误差
- MAPE：平均绝对百分比误差

## 12. 应用领域

### 12.1 社会科学

**调查设计**：

- 抽样方法
- 问卷设计
- 数据收集

**实验设计**：

- 随机化
- 控制变量
- 效应大小

**因果推断**：

- 回归不连续
- 工具变量
- 倾向得分匹配

### 12.2 自然科学

**生物统计**：

- 临床试验
- 流行病学
- 遗传学

**物理统计**：

- 误差分析
- 信号处理
- 质量控制

**环境统计**：

- 污染监测
- 气候变化
- 生态建模

### 12.3 工程应用

**质量控制**：

- 控制图
- 过程能力
- 六西格玛

**可靠性工程**：

- 寿命分析
- 故障模式
- 维护优化

**金融统计**：

- 风险管理
- 投资组合
- 期权定价

## 参考文献

1. Casella, G., & Berger, R. L. (2002). Statistical Inference. Duxbury.

2. Hogg, R. V., McKean, J. W., & Craig, A. T. (2019). Introduction to Mathematical Statistics. Pearson.

3. Rice, J. A. (2006). Mathematical Statistics and Data Analysis. Cengage Learning.

4. Wasserman, L. (2004). All of Statistics: A Concise Course in Statistical Inference. Springer.

5. Box, G. E. P., Hunter, J. S., & Hunter, W. G. (2005). Statistics for Experimenters: Design, Innovation, and Discovery. Wiley.

6. Montgomery, D. C. (2017). Design and Analysis of Experiments. Wiley.

7. Kutner, M. H., Nachtsheim, C. J., Neter, J., & Li, W. (2005). Applied Linear Statistical Models. McGraw-Hill.

8. Gelman, A., Carlin, J. B., Stern, H. S., Dunson, D. B., Vehtari, A., & Rubin, D. B. (2013). Bayesian Data Analysis. CRC Press.

9. Brockwell, P. J., & Davis, R. A. (2016). Introduction to Time Series and Forecasting. Springer.

10. Hollander, M., Wolfe, D. A., & Chicken, E. (2013). Nonparametric Statistical Methods. Wiley.
