# 01-è‡ªåŠ¨åŒ–æ£€æµ‹å¼•æ“

## ğŸ“Š å¼•æ“æ¦‚è¿°

- **å¼•æ“åç§°**: Refactorè‡ªåŠ¨åŒ–æ£€æµ‹å¼•æ“
- **æ ¸å¿ƒåŠŸèƒ½**: è‡ªåŠ¨æ£€æµ‹å’ŒéªŒè¯æ–‡æ¡£è´¨é‡
- **æŠ€æœ¯æ ˆ**: Python + æ­£åˆ™è¡¨è¾¾å¼ + æœºå™¨å­¦ä¹ 
- **æ£€æµ‹è¦†ç›–ç‡ç›®æ ‡**: 100%

---

## ğŸ¯ æ ¸å¿ƒåŠŸèƒ½è®¾è®¡

### 1. å¼•ç”¨é“¾æ¥æ£€æµ‹åŠŸèƒ½

#### 1.1 é“¾æ¥æœ‰æ•ˆæ€§æ£€æµ‹

```python
# é“¾æ¥æ£€æµ‹å™¨
class LinkDetector:
    def __init__(self):
        self.session = requests.Session()
        self.timeout = 10
        self.max_retries = 3
    
    def check_link_validity(self, url):
        """æ£€æµ‹é“¾æ¥æœ‰æ•ˆæ€§"""
        try:
            response = self.session.head(url, timeout=self.timeout)
            return {
                'url': url,
                'status': response.status_code,
                'valid': 200 <= response.status_code < 400,
                'response_time': response.elapsed.total_seconds()
            }
        except Exception as e:
            return {
                'url': url,
                'status': None,
                'valid': False,
                'error': str(e)
            }
    
    def batch_check_links(self, urls, max_workers=10):
        """æ‰¹é‡æ£€æµ‹é“¾æ¥"""
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            results = list(executor.map(self.check_link_validity, urls))
        return results
    
    def extract_links_from_markdown(self, content):
        """ä»Markdownå†…å®¹ä¸­æå–é“¾æ¥"""
        link_pattern = r'\[([^\]]+)\]\(([^)]+)\)'
        links = re.findall(link_pattern, content)
        return [url for _, url in links]
```

#### 1.2 å†…éƒ¨å¼•ç”¨æ£€æµ‹

```python
# å†…éƒ¨å¼•ç”¨æ£€æµ‹å™¨
class InternalReferenceDetector:
    def __init__(self, base_path):
        self.base_path = base_path
        self.file_index = self.build_file_index()
    
    def build_file_index(self):
        """æ„å»ºæ–‡ä»¶ç´¢å¼•"""
        file_index = {}
        for root, dirs, files in os.walk(self.base_path):
            for file in files:
                if file.endswith('.md'):
                    file_path = os.path.join(root, file)
                    relative_path = os.path.relpath(file_path, self.base_path)
                    file_index[relative_path] = file_path
        return file_index
    
    def check_internal_references(self, content, current_file):
        """æ£€æµ‹å†…éƒ¨å¼•ç”¨"""
        issues = []
        
        # æ£€æµ‹ç›¸å¯¹è·¯å¾„å¼•ç”¨
        relative_pattern = r'\[([^\]]+)\]\(([^)]+\.md)\)'
        matches = re.findall(relative_pattern, content)
        
        for text, ref_path in matches:
            if not self.is_valid_internal_reference(ref_path, current_file):
                issues.append({
                    'type': 'invalid_internal_reference',
                    'text': text,
                    'reference': ref_path,
                    'current_file': current_file
                })
        
        return issues
    
    def is_valid_internal_reference(self, ref_path, current_file):
        """éªŒè¯å†…éƒ¨å¼•ç”¨æ˜¯å¦æœ‰æ•ˆ"""
        # è§£æç›¸å¯¹è·¯å¾„
        current_dir = os.path.dirname(current_file)
        absolute_ref_path = os.path.normpath(os.path.join(current_dir, ref_path))
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        return absolute_ref_path in self.file_index.values()
```

### 2. å‘½åè§„èŒƒæ£€æŸ¥åŠŸèƒ½

#### 2.1 æ–‡ä»¶å‘½åè§„èŒƒæ£€æŸ¥

```python
# æ–‡ä»¶å‘½åæ£€æµ‹å™¨
class FileNamingDetector:
    def __init__(self):
        self.naming_patterns = {
            'directory': r'^\d{2}-[A-Za-z0-9_-]+$',
            'file': r'^\d{2}-[A-Za-z0-9_-]+\.md$',
            'backup': r'^\d{2}-[A-Za-z0-9_-]+-å¤‡ä»½$'
        }
    
    def check_file_naming(self, file_path):
        """æ£€æŸ¥æ–‡ä»¶å‘½åè§„èŒƒ"""
        filename = os.path.basename(file_path)
        directory = os.path.dirname(file_path)
        
        issues = []
        
        # æ£€æŸ¥ç›®å½•å‘½å
        if os.path.isdir(file_path):
            if not re.match(self.naming_patterns['directory'], filename):
                issues.append({
                    'type': 'invalid_directory_naming',
                    'file': file_path,
                    'expected_pattern': self.naming_patterns['directory']
                })
        
        # æ£€æŸ¥æ–‡ä»¶å‘½å
        elif filename.endswith('.md'):
            if not re.match(self.naming_patterns['file'], filename):
                issues.append({
                    'type': 'invalid_file_naming',
                    'file': file_path,
                    'expected_pattern': self.naming_patterns['file']
                })
        
        return issues
    
    def suggest_correction(self, filename, file_type='file'):
        """å»ºè®®å‘½åä¿®æ­£"""
        # ç§»é™¤ç‰¹æ®Šå­—ç¬¦
        clean_name = re.sub(r'[^\w\s-]', '', filename)
        clean_name = re.sub(r'\s+', '-', clean_name)
        
        # æ·»åŠ ç¼–å·å‰ç¼€
        if not re.match(r'^\d{2}-', clean_name):
            clean_name = f"01-{clean_name}"
        
        # æ·»åŠ æ–‡ä»¶æ‰©å±•å
        if file_type == 'file' and not clean_name.endswith('.md'):
            clean_name += '.md'
        
        return clean_name
```

#### 2.2 å†…å®¹æ ‡é¢˜è§„èŒƒæ£€æŸ¥

```python
# æ ‡é¢˜è§„èŒƒæ£€æµ‹å™¨
class TitleFormatDetector:
    def __init__(self):
        self.title_patterns = {
            'main_title': r'^#\s+[A-Za-z0-9\s\-_]+$',
            'sub_title': r'^#{2,6}\s+[A-Za-z0-9\s\-_]+$'
        }
    
    def check_title_format(self, content):
        """æ£€æŸ¥æ ‡é¢˜æ ¼å¼è§„èŒƒ"""
        issues = []
        lines = content.split('\n')
        
        for line_num, line in enumerate(lines, 1):
            if line.strip().startswith('#'):
                if not self.is_valid_title_format(line):
                    issues.append({
                        'type': 'invalid_title_format',
                        'line': line_num,
                        'content': line.strip(),
                        'suggestion': self.suggest_title_correction(line)
                    })
        
        return issues
    
    def is_valid_title_format(self, title_line):
        """éªŒè¯æ ‡é¢˜æ ¼å¼"""
        title_line = title_line.strip()
        
        # æ£€æŸ¥ä¸»æ ‡é¢˜æ ¼å¼
        if title_line.startswith('# '):
            return bool(re.match(self.title_patterns['main_title'], title_line))
        
        # æ£€æŸ¥å­æ ‡é¢˜æ ¼å¼
        elif title_line.startswith('##'):
            return bool(re.match(self.title_patterns['sub_title'], title_line))
        
        return False
    
    def suggest_title_correction(self, title_line):
        """å»ºè®®æ ‡é¢˜ä¿®æ­£"""
        # ç§»é™¤å¤šä½™çš„ç©ºæ ¼
        corrected = re.sub(r'#+\s+', '# ', title_line)
        
        # ç¡®ä¿æ ‡é¢˜æ ¼å¼æ­£ç¡®
        if not corrected.startswith('# '):
            corrected = '# ' + corrected.lstrip('#').lstrip()
        
        return corrected
```

### 3. å†…å®¹å®Œæ•´æ€§éªŒè¯åŠŸèƒ½

#### 3.1 æ–‡æ¡£ç»“æ„å®Œæ•´æ€§æ£€æŸ¥

```python
# æ–‡æ¡£ç»“æ„æ£€æµ‹å™¨
class DocumentStructureDetector:
    def __init__(self):
        self.required_sections = [
            'æ¦‚è¿°', 'æ€»è§ˆ', 'Introduction', 'Overview'
        ]
        self.min_content_length = 100
    
    def check_document_structure(self, content, file_path):
        """æ£€æŸ¥æ–‡æ¡£ç»“æ„å®Œæ•´æ€§"""
        issues = []
        
        # æ£€æŸ¥å†…å®¹é•¿åº¦
        if len(content.strip()) < self.min_content_length:
            issues.append({
                'type': 'insufficient_content',
                'file': file_path,
                'current_length': len(content.strip()),
                'min_required': self.min_content_length
            })
        
        # æ£€æŸ¥æ ‡é¢˜å±‚çº§
        title_hierarchy = self.analyze_title_hierarchy(content)
        if not self.is_valid_hierarchy(title_hierarchy):
            issues.append({
                'type': 'invalid_title_hierarchy',
                'file': file_path,
                'hierarchy': title_hierarchy
            })
        
        # æ£€æŸ¥å¿…è¦ç« èŠ‚
        missing_sections = self.check_required_sections(content)
        if missing_sections:
            issues.append({
                'type': 'missing_required_sections',
                'file': file_path,
                'missing_sections': missing_sections
            })
        
        return issues
    
    def analyze_title_hierarchy(self, content):
        """åˆ†ææ ‡é¢˜å±‚çº§"""
        hierarchy = []
        lines = content.split('\n')
        
        for line in lines:
            if line.strip().startswith('#'):
                level = len(line) - len(line.lstrip('#'))
                title = line.strip('#').strip()
                hierarchy.append({'level': level, 'title': title})
        
        return hierarchy
    
    def is_valid_hierarchy(self, hierarchy):
        """éªŒè¯æ ‡é¢˜å±‚çº§æ˜¯å¦åˆç†"""
        if not hierarchy:
            return False
        
        # æ£€æŸ¥å±‚çº§è·³è·ƒ
        for i in range(1, len(hierarchy)):
            if hierarchy[i]['level'] - hierarchy[i-1]['level'] > 1:
                return False
        
        return True
    
    def check_required_sections(self, content):
        """æ£€æŸ¥å¿…è¦ç« èŠ‚"""
        missing = []
        content_lower = content.lower()
        
        for section in self.required_sections:
            if section.lower() not in content_lower:
                missing.append(section)
        
        return missing
```

#### 3.2 æ•°å­¦å…¬å¼æ ¼å¼æ£€æŸ¥

```python
# æ•°å­¦å…¬å¼æ£€æµ‹å™¨
class MathFormulaDetector:
    def __init__(self):
        self.latex_patterns = {
            'inline': r'\$([^$]+)\$',
            'block': r'\$\$([^$]+)\$\$',
            'equation': r'\\begin\{equation\}(.*?)\\end\{equation\}',
            'align': r'\\begin\{align\}(.*?)\\end\{align\}'
        }
    
    def check_math_formulas(self, content):
        """æ£€æŸ¥æ•°å­¦å…¬å¼æ ¼å¼"""
        issues = []
        
        # æ£€æŸ¥è¡Œå†…å…¬å¼
        inline_issues = self.check_inline_formulas(content)
        issues.extend(inline_issues)
        
        # æ£€æŸ¥å—çº§å…¬å¼
        block_issues = self.check_block_formulas(content)
        issues.extend(block_issues)
        
        # æ£€æŸ¥LaTeXè¯­æ³•
        latex_issues = self.check_latex_syntax(content)
        issues.extend(latex_issues)
        
        return issues
    
    def check_inline_formulas(self, content):
        """æ£€æŸ¥è¡Œå†…å…¬å¼"""
        issues = []
        matches = re.finditer(self.latex_patterns['inline'], content)
        
        for match in matches:
            formula = match.group(1)
            if not self.is_valid_latex_formula(formula):
                issues.append({
                    'type': 'invalid_inline_formula',
                    'formula': formula,
                    'position': match.start()
                })
        
        return issues
    
    def check_block_formulas(self, content):
        """æ£€æŸ¥å—çº§å…¬å¼"""
        issues = []
        matches = re.finditer(self.latex_patterns['block'], content, re.DOTALL)
        
        for match in matches:
            formula = match.group(1)
            if not self.is_valid_latex_formula(formula):
                issues.append({
                    'type': 'invalid_block_formula',
                    'formula': formula,
                    'position': match.start()
                })
        
        return issues
    
    def is_valid_latex_formula(self, formula):
        """éªŒè¯LaTeXå…¬å¼è¯­æ³•"""
        # æ£€æŸ¥åŸºæœ¬è¯­æ³•
        if not formula.strip():
            return False
        
        # æ£€æŸ¥æ‹¬å·åŒ¹é…
        if not self.check_bracket_balance(formula):
            return False
        
        # æ£€æŸ¥å¸¸è§é”™è¯¯
        common_errors = [
            r'\\[a-zA-Z]+',  # æ£€æŸ¥åæ–œæ å‘½ä»¤
            r'\{[^}]*\}',    # æ£€æŸ¥èŠ±æ‹¬å·
            r'\[[^\]]*\]',   # æ£€æŸ¥æ–¹æ‹¬å·
        ]
        
        for pattern in common_errors:
            if re.search(pattern, formula):
                # è¿›ä¸€æ­¥éªŒè¯è¯­æ³•
                pass
        
        return True
    
    def check_bracket_balance(self, formula):
        """æ£€æŸ¥æ‹¬å·å¹³è¡¡"""
        stack = []
        brackets = {'(': ')', '{': '}', '[': ']'}
        
        for char in formula:
            if char in brackets:
                stack.append(char)
            elif char in brackets.values():
                if not stack:
                    return False
                if brackets[stack.pop()] != char:
                    return False
        
        return len(stack) == 0
```

### 4. æ ¼å¼è§„èŒƒæ£€æŸ¥åŠŸèƒ½

#### 4.1 Markdownæ ¼å¼æ£€æŸ¥

```python
# Markdownæ ¼å¼æ£€æµ‹å™¨
class MarkdownFormatDetector:
    def __init__(self):
        self.format_rules = {
            'line_length': 120,
            'list_indentation': 2,
            'code_block_language': True
        }
    
    def check_markdown_format(self, content):
        """æ£€æŸ¥Markdownæ ¼å¼è§„èŒƒ"""
        issues = []
        
        # æ£€æŸ¥è¡Œé•¿åº¦
        line_length_issues = self.check_line_length(content)
        issues.extend(line_length_issues)
        
        # æ£€æŸ¥åˆ—è¡¨æ ¼å¼
        list_format_issues = self.check_list_format(content)
        issues.extend(list_format_issues)
        
        # æ£€æŸ¥ä»£ç å—æ ¼å¼
        code_block_issues = self.check_code_block_format(content)
        issues.extend(code_block_issues)
        
        # æ£€æŸ¥é“¾æ¥æ ¼å¼
        link_format_issues = self.check_link_format(content)
        issues.extend(link_format_issues)
        
        return issues
    
    def check_line_length(self, content):
        """æ£€æŸ¥è¡Œé•¿åº¦"""
        issues = []
        lines = content.split('\n')
        
        for line_num, line in enumerate(lines, 1):
            if len(line) > self.format_rules['line_length']:
                issues.append({
                    'type': 'line_too_long',
                    'line': line_num,
                    'length': len(line),
                    'max_length': self.format_rules['line_length']
                })
        
        return issues
    
    def check_list_format(self, content):
        """æ£€æŸ¥åˆ—è¡¨æ ¼å¼"""
        issues = []
        lines = content.split('\n')
        
        for line_num, line in enumerate(lines, 1):
            if line.strip().startswith(('-', '*', '+')):
                # æ£€æŸ¥ç¼©è¿›
                indent = len(line) - len(line.lstrip())
                if indent % self.format_rules['list_indentation'] != 0:
                    issues.append({
                        'type': 'invalid_list_indentation',
                        'line': line_num,
                        'indent': indent,
                        'expected': self.format_rules['list_indentation']
                    })
        
        return issues
    
    def check_code_block_format(self, content):
        """æ£€æŸ¥ä»£ç å—æ ¼å¼"""
        issues = []
        
        # æ£€æŸ¥ä»£ç å—è¯­è¨€æ ‡è¯†
        code_block_pattern = r'```(\w+)?\n(.*?)```'
        matches = re.finditer(code_block_pattern, content, re.DOTALL)
        
        for match in matches:
            language = match.group(1)
            if not language and self.format_rules['code_block_language']:
                issues.append({
                    'type': 'missing_code_language',
                    'position': match.start(),
                    'suggestion': 'Add language identifier'
                })
        
        return issues
```

---

## ğŸ—ï¸ æŠ€æœ¯æ¶æ„

### 1. æ£€æµ‹å¼•æ“æ¶æ„

```text
è‡ªåŠ¨åŒ–æ£€æµ‹å¼•æ“/
â”œâ”€â”€ detectors/              # æ£€æµ‹å™¨æ¨¡å—
â”‚   â”œâ”€â”€ link_detector.py    # é“¾æ¥æ£€æµ‹å™¨
â”‚   â”œâ”€â”€ naming_detector.py  # å‘½åæ£€æµ‹å™¨
â”‚   â”œâ”€â”€ structure_detector.py # ç»“æ„æ£€æµ‹å™¨
â”‚   â”œâ”€â”€ formula_detector.py # å…¬å¼æ£€æµ‹å™¨
â”‚   â””â”€â”€ format_detector.py  # æ ¼å¼æ£€æµ‹å™¨
â”œâ”€â”€ validators/             # éªŒè¯å™¨æ¨¡å—
â”‚   â”œâ”€â”€ link_validator.py   # é“¾æ¥éªŒè¯å™¨
â”‚   â”œâ”€â”€ content_validator.py # å†…å®¹éªŒè¯å™¨
â”‚   â””â”€â”€ format_validator.py # æ ¼å¼éªŒè¯å™¨
â”œâ”€â”€ analyzers/              # åˆ†æå™¨æ¨¡å—
â”‚   â”œâ”€â”€ quality_analyzer.py # è´¨é‡åˆ†æå™¨
â”‚   â”œâ”€â”€ trend_analyzer.py   # è¶‹åŠ¿åˆ†æå™¨
â”‚   â””â”€â”€ report_analyzer.py  # æŠ¥å‘Šåˆ†æå™¨
â”œâ”€â”€ utils/                  # å·¥å…·å‡½æ•°
â”‚   â”œâ”€â”€ file_utils.py       # æ–‡ä»¶å·¥å…·
â”‚   â”œâ”€â”€ text_utils.py       # æ–‡æœ¬å·¥å…·
â”‚   â””â”€â”€ math_utils.py       # æ•°å­¦å·¥å…·
â””â”€â”€ config/                 # é…ç½®æ–‡ä»¶
    â”œâ”€â”€ detection_rules.py  # æ£€æµ‹è§„åˆ™
    â”œâ”€â”€ quality_standards.py # è´¨é‡æ ‡å‡†
    â””â”€â”€ thresholds.py       # é˜ˆå€¼é…ç½®
```

### 2. æ£€æµ‹æµç¨‹

```text
æ–‡ä»¶æ‰«æ â†’ å†…å®¹è§£æ â†’ å¤šæ£€æµ‹å™¨å¹¶è¡Œæ£€æµ‹ â†’ ç»“æœèšåˆ â†’ é—®é¢˜åˆ†ç±» â†’ ç”ŸæˆæŠ¥å‘Š
    â†“
è§„åˆ™åŒ¹é… â†’ è¯­æ³•éªŒè¯ â†’ æ ¼å¼æ£€æŸ¥ â†’ å®Œæ•´æ€§éªŒè¯ â†’ è´¨é‡è¯„åˆ†
```

### 3. æ€§èƒ½ä¼˜åŒ–

#### 3.1 å¹¶è¡Œæ£€æµ‹

```python
# å¹¶è¡Œæ£€æµ‹ç®¡ç†å™¨
class ParallelDetectionManager:
    def __init__(self, max_workers=4):
        self.max_workers = max_workers
        self.detectors = self.load_detectors()
    
    def run_parallel_detection(self, files):
        """å¹¶è¡Œè¿è¡Œæ£€æµ‹"""
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            futures = []
            for file_path in files:
                future = executor.submit(self.detect_single_file, file_path)
                futures.append(future)
            
            results = []
            for future in as_completed(futures):
                results.extend(future.result())
        
        return results
    
    def detect_single_file(self, file_path):
        """æ£€æµ‹å•ä¸ªæ–‡ä»¶"""
        issues = []
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        for detector in self.detectors:
            detector_issues = detector.detect(content, file_path)
            issues.extend(detector_issues)
        
        return issues
```

#### 3.2 ç¼“å­˜æœºåˆ¶

```python
# æ£€æµ‹ç»“æœç¼“å­˜
class DetectionCache:
    def __init__(self, cache_dir='.detection_cache'):
        self.cache_dir = cache_dir
        os.makedirs(cache_dir, exist_ok=True)
    
    def get_cache_key(self, file_path, detector_type):
        """ç”Ÿæˆç¼“å­˜é”®"""
        file_hash = hashlib.md5(open(file_path, 'rb').read()).hexdigest()
        return f"{detector_type}_{file_hash}"
    
    def get_cached_result(self, cache_key):
        """è·å–ç¼“å­˜ç»“æœ"""
        cache_file = os.path.join(self.cache_dir, f"{cache_key}.json")
        if os.path.exists(cache_file):
            with open(cache_file, 'r') as f:
                return json.load(f)
        return None
    
    def cache_result(self, cache_key, result):
        """ç¼“å­˜æ£€æµ‹ç»“æœ"""
        cache_file = os.path.join(self.cache_dir, f"{cache_key}.json")
        with open(cache_file, 'w') as f:
            json.dump(result, f)
```

---

## ğŸ“Š è´¨é‡æŒ‡æ ‡

### 1. æ£€æµ‹æ€§èƒ½

- **æ£€æµ‹é€Ÿåº¦**: < 1ç§’/æ–‡ä»¶
- **æ£€æµ‹å‡†ç¡®ç‡**: > 95%
- **è¯¯æŠ¥ç‡**: < 5%
- **è¦†ç›–ç‡**: 100%

### 2. é—®é¢˜åˆ†ç±»

- **ä¸¥é‡é—®é¢˜**: å½±å“æ–‡æ¡£å¯è¯»æ€§çš„é—®é¢˜
- **ä¸€èˆ¬é—®é¢˜**: æ ¼å¼ä¸è§„èŒƒä½†ä¸å½±å“ç†è§£çš„é—®é¢˜
- **å»ºè®®é—®é¢˜**: å¯é€‰çš„æ”¹è¿›å»ºè®®

### 3. è´¨é‡è¯„åˆ†

```python
# è´¨é‡è¯„åˆ†è®¡ç®—å™¨
class QualityScoreCalculator:
    def __init__(self):
        self.weights = {
            'critical': 0.5,
            'normal': 0.3,
            'suggestion': 0.2
        }
    
    def calculate_score(self, issues):
        """è®¡ç®—è´¨é‡è¯„åˆ†"""
        if not issues:
            return 100.0
        
        total_penalty = 0
        for issue in issues:
            penalty = self.get_issue_penalty(issue['type'])
            total_penalty += penalty
        
        score = max(0, 100 - total_penalty)
        return round(score, 2)
    
    def get_issue_penalty(self, issue_type):
        """è·å–é—®é¢˜æ‰£åˆ†"""
        penalties = {
            'invalid_internal_reference': 10,
            'invalid_file_naming': 5,
            'insufficient_content': 15,
            'invalid_title_format': 3,
            'invalid_inline_formula': 8,
            'line_too_long': 1
        }
        return penalties.get(issue_type, 2)
```

---

## ğŸš€ éƒ¨ç½²æ–¹æ¡ˆ

### 1. å‘½ä»¤è¡Œå·¥å…·

```python
# å‘½ä»¤è¡Œæ¥å£
import argparse

def main():
    parser = argparse.ArgumentParser(description='Refactorè´¨é‡æ£€æµ‹å·¥å…·')
    parser.add_argument('path', help='æ£€æµ‹è·¯å¾„')
    parser.add_argument('--output', '-o', help='è¾“å‡ºæ–‡ä»¶')
    parser.add_argument('--format', '-f', choices=['json', 'html', 'text'], 
                       default='json', help='è¾“å‡ºæ ¼å¼')
    parser.add_argument('--parallel', '-p', type=int, default=4, 
                       help='å¹¶è¡Œæ£€æµ‹æ•°é‡')
    
    args = parser.parse_args()
    
    # è¿è¡Œæ£€æµ‹
    detector = QualityDetector()
    results = detector.detect_directory(args.path, max_workers=args.parallel)
    
    # è¾“å‡ºç»“æœ
    if args.output:
        detector.export_results(results, args.output, args.format)
    else:
        detector.print_results(results)

if __name__ == '__main__':
    main()
```

### 2. é›†æˆåˆ°CI/CD

```yaml
# GitHub Actionsé…ç½®
name: Quality Check
on: [push, pull_request]

jobs:
  quality-check:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      
      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: 3.9
      
      - name: Install dependencies
        run: |
          pip install -r requirements.txt
      
      - name: Run quality detection
        run: |
          python -m quality_detector Math/Refactor --output quality_report.json
      
      - name: Upload quality report
        uses: actions/upload-artifact@v2
        with:
          name: quality-report
          path: quality_report.json
```

---

## ğŸ“ˆ ç›‘æ§ä¸ä¼˜åŒ–

### 1. æ€§èƒ½ç›‘æ§

- **æ£€æµ‹æ—¶é—´ç›‘æ§**: è·Ÿè¸ªæ£€æµ‹è€—æ—¶
- **å†…å­˜ä½¿ç”¨ç›‘æ§**: ç›‘æ§å†…å­˜æ¶ˆè€—
- **CPUä½¿ç”¨ç›‘æ§**: ç›‘æ§CPUä½¿ç”¨ç‡
- **é”™è¯¯ç‡ç›‘æ§**: è·Ÿè¸ªæ£€æµ‹é”™è¯¯ç‡

### 2. æŒç»­ä¼˜åŒ–

- **è§„åˆ™ä¼˜åŒ–**: æ ¹æ®æ£€æµ‹ç»“æœä¼˜åŒ–æ£€æµ‹è§„åˆ™
- **ç®—æ³•ä¼˜åŒ–**: ä¼˜åŒ–æ£€æµ‹ç®—æ³•æ€§èƒ½
- **ç¼“å­˜ä¼˜åŒ–**: ä¼˜åŒ–ç¼“å­˜ç­–ç•¥
- **å¹¶è¡Œä¼˜åŒ–**: ä¼˜åŒ–å¹¶è¡Œæ£€æµ‹ç­–ç•¥

---

## ğŸ¯ åç»­å‘å±•

### 1. åŠŸèƒ½æ‰©å±•

- **æœºå™¨å­¦ä¹ æ£€æµ‹**: å¼•å…¥æœºå™¨å­¦ä¹ æ¨¡å‹è¿›è¡Œæ™ºèƒ½æ£€æµ‹
- **è¯­ä¹‰åˆ†æ**: åŸºäºè¯­ä¹‰åˆ†ææ£€æµ‹å†…å®¹è´¨é‡
- **å¤šè¯­è¨€æ”¯æŒ**: æ”¯æŒå¤šç§è¯­è¨€çš„æ£€æµ‹
- **å®æ—¶æ£€æµ‹**: æ”¯æŒå®æ—¶æ–‡ä»¶å˜åŒ–æ£€æµ‹

### 2. æ™ºèƒ½åŒ–æå‡

- **è‡ªé€‚åº”è§„åˆ™**: æ ¹æ®é¡¹ç›®ç‰¹ç‚¹è‡ªé€‚åº”è°ƒæ•´æ£€æµ‹è§„åˆ™
- **æ™ºèƒ½ä¿®å¤**: æä¾›è‡ªåŠ¨ä¿®å¤å»ºè®®
- **é¢„æµ‹åˆ†æ**: é¢„æµ‹æ½œåœ¨çš„è´¨é‡é—®é¢˜
- **å­¦ä¹ ä¼˜åŒ–**: ä»ç”¨æˆ·åé¦ˆä¸­å­¦ä¹ ä¼˜åŒ–æ£€æµ‹ç­–ç•¥

---

*æœ¬æ–‡æ¡£ä¸ºè‡ªåŠ¨åŒ–æ£€æµ‹å¼•æ“çš„è¯¦ç»†è®¾è®¡ï¼Œä¸ºRefactoré¡¹ç›®çš„è´¨é‡ç›‘æ§ç³»ç»Ÿæä¾›æ ¸å¿ƒæŠ€æœ¯æ”¯æ’‘ã€‚*
