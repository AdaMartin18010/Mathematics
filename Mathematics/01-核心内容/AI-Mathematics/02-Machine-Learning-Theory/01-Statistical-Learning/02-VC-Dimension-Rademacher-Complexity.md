# VCç»´ä¸Rademacherå¤æ‚åº¦

> **VC-Dimension and Rademacher Complexity**
>
> ç»Ÿè®¡å­¦ä¹ ç†è®ºçš„æ ¸å¿ƒå·¥å…·ï¼šé‡åŒ–å‡è®¾ç±»çš„å¤æ‚åº¦ä¸æ³›åŒ–èƒ½åŠ›

---

## ç›®å½•

- [VCç»´ä¸Rademacherå¤æ‚åº¦](#vcç»´ä¸rademacherå¤æ‚åº¦)
  - [ç›®å½•](#ç›®å½•)
  - [ğŸ“‹ æ ¸å¿ƒæ¦‚å¿µ](#-æ ¸å¿ƒæ¦‚å¿µ)
  - [ğŸ¯ VCç»´ç†è®º](#-vcç»´ç†è®º)
    - [1. æ‰“æ•£ä¸VCç»´å®šä¹‰](#1-æ‰“æ•£ä¸vcç»´å®šä¹‰)
    - [2. å¸¸è§å‡è®¾ç±»çš„VCç»´](#2-å¸¸è§å‡è®¾ç±»çš„vcç»´)
    - [3. Sauerå¼•ç†](#3-sauerå¼•ç†)
    - [4. VCç»´æ³›åŒ–ç•Œ](#4-vcç»´æ³›åŒ–ç•Œ)
  - [ğŸ“Š Rademacherå¤æ‚åº¦](#-rademacherå¤æ‚åº¦)
    - [1. å®šä¹‰ä¸ç›´è§‰](#1-å®šä¹‰ä¸ç›´è§‰)
    - [2. ç»éªŒRademacherå¤æ‚åº¦](#2-ç»éªŒrademacherå¤æ‚åº¦)
    - [3. Rademacheræ³›åŒ–ç•Œ](#3-rademacheræ³›åŒ–ç•Œ)
    - [4. æ€§è´¨ä¸è®¡ç®—](#4-æ€§è´¨ä¸è®¡ç®—)
  - [ğŸ”— ä¸¤ç§å¤æ‚åº¦çš„å…³ç³»](#-ä¸¤ç§å¤æ‚åº¦çš„å…³ç³»)
  - [ğŸ¤– AIåº”ç”¨](#-aiåº”ç”¨)
    - [1. ç¥ç»ç½‘ç»œçš„VCç»´](#1-ç¥ç»ç½‘ç»œçš„vcç»´)
    - [2. æ·±åº¦å­¦ä¹ ä¸­çš„Rademacherå¤æ‚åº¦](#2-æ·±åº¦å­¦ä¹ ä¸­çš„rademacherå¤æ‚åº¦)
    - [3. æ¨¡å‹é€‰æ‹©](#3-æ¨¡å‹é€‰æ‹©)
  - [ğŸ’» Pythonå®ç°](#-pythonå®ç°)
    - [1. VCç»´è®¡ç®—ç¤ºä¾‹](#1-vcç»´è®¡ç®—ç¤ºä¾‹)
    - [2. Rademacherå¤æ‚åº¦ä¼°è®¡](#2-rademacherå¤æ‚åº¦ä¼°è®¡)
  - [ğŸ”¬ å½¢å¼åŒ–è¯æ˜ (Lean 4)](#-å½¢å¼åŒ–è¯æ˜-lean-4)
  - [ğŸ“š æ ¸å¿ƒå®šç†æ€»ç»“](#-æ ¸å¿ƒå®šç†æ€»ç»“)
  - [ğŸ“ ç›¸å…³è¯¾ç¨‹](#-ç›¸å…³è¯¾ç¨‹)
  - [ğŸ“– å‚è€ƒæ–‡çŒ®](#-å‚è€ƒæ–‡çŒ®)
  - [ğŸ”— ç›¸å…³æ–‡æ¡£](#-ç›¸å…³æ–‡æ¡£)
  - [âœï¸ ç»ƒä¹ ](#ï¸-ç»ƒä¹ )

---

## ğŸ“‹ æ ¸å¿ƒæ¦‚å¿µ

**VCç»´**å’Œ**Rademacherå¤æ‚åº¦**æ˜¯ç»Ÿè®¡å­¦ä¹ ç†è®ºä¸­ä¸¤ä¸ªæœ€é‡è¦çš„å¤æ‚åº¦åº¦é‡å·¥å…·ï¼Œç”¨äºï¼š

1. **é‡åŒ–å‡è®¾ç±»çš„è¡¨è¾¾èƒ½åŠ›**
2. **æ¨å¯¼æ³›åŒ–è¯¯å·®ç•Œ**
3. **æŒ‡å¯¼æ¨¡å‹é€‰æ‹©å’Œæ­£åˆ™åŒ–**

**æ ¸å¿ƒæ€æƒ³**ï¼š

- **VCç»´**ï¼šç»„åˆæ€§è´¨ï¼Œæµ‹é‡å‡è®¾ç±»èƒ½"æ‰“æ•£"çš„æœ€å¤§ç‚¹é›†å¤§å°
- **Rademacherå¤æ‚åº¦**ï¼šåº¦é‡å‡è®¾ç±»ä¸éšæœºå™ªå£°çš„ç›¸å…³æ€§

---

## ğŸ¯ VCç»´ç†è®º

### 1. æ‰“æ•£ä¸VCç»´å®šä¹‰

**å®šä¹‰ 1.1 (æ‰“æ•£ Shattering)**:

è®¾ $\mathcal{H}$ ä¸ºå®šä¹‰åœ¨ $\mathcal{X}$ ä¸Šçš„å‡è®¾ç±»ã€‚ç§° $\mathcal{H}$ **æ‰“æ•£** ç‚¹é›† $C = \{x_1, \ldots, x_d\} \subseteq \mathcal{X}$ï¼Œè‹¥ï¼š

$$
|\mathcal{H}_C| = 2^d
$$

å…¶ä¸­ $\mathcal{H}_C = \{(h(x_1), \ldots, h(x_d)) : h \in \mathcal{H}\}$ æ˜¯ $\mathcal{H}$ åœ¨ $C$ ä¸Šçš„é™åˆ¶ã€‚

**ç›´è§‰**ï¼š$\mathcal{H}$ èƒ½å®ç° $C$ ä¸Šæ‰€æœ‰å¯èƒ½çš„ $2^d$ ç§æ ‡ç­¾ç»„åˆã€‚

---

**å®šä¹‰ 1.2 (VCç»´)**:

å‡è®¾ç±» $\mathcal{H}$ çš„ **VCç»´** $\text{VCdim}(\mathcal{H})$ æ˜¯èƒ½è¢« $\mathcal{H}$ æ‰“æ•£çš„æœ€å¤§ç‚¹é›†å¤§å°ï¼š

$$
\text{VCdim}(\mathcal{H}) = \max\{d : \exists C, |C| = d, \mathcal{H} \text{ shatters } C\}
$$

è‹¥å¯¹ä»»æ„ $d$ éƒ½å­˜åœ¨å¯è¢«æ‰“æ•£çš„ç‚¹é›†ï¼Œåˆ™ $\text{VCdim}(\mathcal{H}) = \infty$ã€‚

---

### 2. å¸¸è§å‡è®¾ç±»çš„VCç»´

**ç¤ºä¾‹ 2.1 (ä¸€ç»´é˜ˆå€¼å‡½æ•°)**:

$$
\mathcal{H}_{\text{threshold}} = \{h_a(x) = \mathbb{1}[x \geq a] : a \in \mathbb{R}\}
$$

**ç»“è®º**ï¼š$\text{VCdim}(\mathcal{H}_{\text{threshold}}) = 1$

**è¯æ˜**ï¼š

- å¯ä»¥æ‰“æ•£ä»»æ„1ä¸ªç‚¹ $\{x_1\}$ï¼ˆé€šè¿‡é€‰æ‹© $a > x_1$ æˆ– $a \leq x_1$ï¼‰
- æ— æ³•æ‰“æ•£ä»»æ„2ä¸ªç‚¹ $\{x_1, x_2\}$ï¼ˆå‡è®¾ $x_1 < x_2$ï¼Œæ— æ³•å®ç° $(1, 0)$ æ ‡ç­¾ï¼‰

---

**ç¤ºä¾‹ 2.2 (çº¿æ€§åˆ†ç±»å™¨)**:

$$
\mathcal{H}_{\text{linear}} = \{h_{w,b}(x) = \text{sign}(w^\top x + b) : w \in \mathbb{R}^d, b \in \mathbb{R}\}
$$

**ç»“è®º**ï¼š$\text{VCdim}(\mathcal{H}_{\text{linear}}) = d + 1$

**è¯æ˜æ€è·¯**ï¼š

- **ä¸‹ç•Œ**ï¼šæ„é€  $d+1$ ä¸ªä¸€èˆ¬ä½ç½®çš„ç‚¹ï¼ˆå¦‚å•ä½çŸ©é˜µåŠ å…¨1è¡Œï¼‰ï¼Œå¯è¢«çº¿æ€§åˆ†ç±»å™¨æ‰“æ•£
- **ä¸Šç•Œ**ï¼šä»»æ„ $d+2$ ä¸ªç‚¹åœ¨ $\mathbb{R}^d$ ä¸­çº¿æ€§ç›¸å…³ï¼Œæ— æ³•è¢«æ‰“æ•£ï¼ˆRadonå®šç†ï¼‰

---

**ç¤ºä¾‹ 2.3 (è½´å¯¹é½çŸ©å½¢)**:

$$
\mathcal{H}_{\text{rect}} = \{h_{a,b,c,d}(x_1, x_2) = \mathbb{1}[a \leq x_1 \leq b, c \leq x_2 \leq d]\}
$$

**ç»“è®º**ï¼š$\text{VCdim}(\mathcal{H}_{\text{rect}}) = 4$

---

### 3. Sauerå¼•ç†

**å®šç† 3.1 (Sauerå¼•ç†)**:

è®¾ $\mathcal{H}$ çš„VCç»´ä¸º $d < \infty$ï¼Œåˆ™å¯¹ä»»æ„ $m \geq d$ï¼š

$$
|\mathcal{H}_S| \leq \sum_{i=0}^{d} \binom{m}{i} \leq \left(\frac{em}{d}\right)^d
$$

å…¶ä¸­ $S$ æ˜¯å¤§å°ä¸º $m$ çš„ä»»æ„æ ·æœ¬ã€‚

**æ„ä¹‰**ï¼š

- VCç»´æœ‰é™ $\Rightarrow$ å¢é•¿å‡½æ•°ä»æŒ‡æ•°å¢é•¿å˜ä¸ºå¤šé¡¹å¼å¢é•¿
- è¿™æ˜¯æ³›åŒ–èƒ½åŠ›çš„å…³é”®ï¼šé¿å…"è¿‡æ‹Ÿåˆ"æ— é™å¤šçš„å‡è®¾

---

### 4. VCç»´æ³›åŒ–ç•Œ

**å®šç† 4.1 (VCç»´æ³›åŒ–ç•Œ)**:

è®¾ $\mathcal{H}$ çš„VCç»´ä¸º $d$ï¼Œåˆ™ä»¥è‡³å°‘ $1 - \delta$ çš„æ¦‚ç‡ï¼Œå¯¹æ‰€æœ‰ $h \in \mathcal{H}$ï¼š

$$
L_D(h) \leq \hat{L}_S(h) + O\left(\sqrt{\frac{d \log(m/d) + \log(1/\delta)}{m}}\right)
$$

**è¯æ˜æ€è·¯**ï¼š

1. åˆ©ç”¨Sauerå¼•ç†æ§åˆ¶ $|\mathcal{H}_S|$
2. å¯¹æ¯ä¸ª $h$ åº”ç”¨Hoeffdingä¸ç­‰å¼
3. Union bound over $|\mathcal{H}_S|$

---

## ğŸ“Š Rademacherå¤æ‚åº¦

### 1. å®šä¹‰ä¸ç›´è§‰

**å®šä¹‰ 1.1 (Rademacherå¤æ‚åº¦)**:

è®¾ $\mathcal{F}$ ä¸ºå‡½æ•°ç±»ï¼Œ$S = \{x_1, \ldots, x_m\}$ ä¸ºæ ·æœ¬ã€‚**ç»éªŒRademacherå¤æ‚åº¦**å®šä¹‰ä¸ºï¼š

$$
\hat{\mathfrak{R}}_S(\mathcal{F}) = \mathbb{E}_{\boldsymbol{\sigma}}\left[\sup_{f \in \mathcal{F}} \frac{1}{m} \sum_{i=1}^{m} \sigma_i f(x_i)\right]
$$

å…¶ä¸­ $\sigma_i \in \{-1, +1\}$ æ˜¯ç‹¬ç«‹å‡åŒ€çš„Rademacheréšæœºå˜é‡ã€‚

**Rademacherå¤æ‚åº¦**æ˜¯å¯¹æ ·æœ¬åˆ†å¸ƒçš„æœŸæœ›ï¼š

$$
\mathfrak{R}_m(\mathcal{F}) = \mathbb{E}_{S \sim D^m}\left[\hat{\mathfrak{R}}_S(\mathcal{F})\right]
$$

---

**ç›´è§‰è§£é‡Š**ï¼š

- Rademacherå¤æ‚åº¦åº¦é‡ $\mathcal{F}$ èƒ½å¤šå¥½åœ°**æ‹Ÿåˆéšæœºå™ªå£°**
- å¦‚æœ $\mathcal{F}$ å¾ˆå¤æ‚ï¼Œå³ä½¿é¢å¯¹çº¯éšæœºæ ‡ç­¾ä¹Ÿèƒ½æ‹Ÿåˆå¾—å¾ˆå¥½ â†’ é«˜Rademacherå¤æ‚åº¦
- å¦‚æœ $\mathcal{F}$ ç®€å•ï¼Œæ— æ³•æ‹Ÿåˆéšæœºå™ªå£° â†’ ä½Rademacherå¤æ‚åº¦

---

### 2. ç»éªŒRademacherå¤æ‚åº¦

**ç¤ºä¾‹ 2.1 (çº¿æ€§å‡½æ•°ç±»)**:

è€ƒè™‘ $\mathcal{F} = \{f_w(x) = w^\top x : \|w\|_2 \leq 1\}$ï¼Œæ ·æœ¬æ»¡è¶³ $\|x_i\|_2 \leq R$ã€‚

**ç»“è®º**ï¼š

$$
\hat{\mathfrak{R}}_S(\mathcal{F}) = \frac{R}{\sqrt{m}}
$$

**è¯æ˜**ï¼š

$$
\begin{align}
\hat{\mathfrak{R}}_S(\mathcal{F}) &= \mathbb{E}_{\boldsymbol{\sigma}}\left[\sup_{\|w\|_2 \leq 1} \frac{1}{m} \sum_{i=1}^{m} \sigma_i w^\top x_i\right] \\
&= \mathbb{E}_{\boldsymbol{\sigma}}\left[\sup_{\|w\|_2 \leq 1} w^\top \left(\frac{1}{m} \sum_{i=1}^{m} \sigma_i x_i\right)\right] \\
&= \mathbb{E}_{\boldsymbol{\sigma}}\left[\left\|\frac{1}{m} \sum_{i=1}^{m} \sigma_i x_i\right\|_2\right] \quad (\text{Cauchy-Schwarz}) \\
&\leq \frac{1}{m} \sqrt{\mathbb{E}\left[\left\|\sum_{i=1}^{m} \sigma_i x_i\right\|_2^2\right]} \\
&= \frac{1}{m} \sqrt{\sum_{i=1}^{m} \|x_i\|_2^2} \leq \frac{R}{\sqrt{m}}
\end{align}
$$

---

### 3. Rademacheræ³›åŒ–ç•Œ

**å®šç† 3.1 (Rademacheræ³›åŒ–ç•Œ)**:

è®¾ $\mathcal{F}$ ä¸ºå€¼åŸŸåœ¨ $[0, 1]$ çš„å‡½æ•°ç±»ã€‚ä»¥è‡³å°‘ $1 - \delta$ çš„æ¦‚ç‡ï¼Œå¯¹æ‰€æœ‰ $f \in \mathcal{F}$ï¼š

$$
L_D(f) \leq \hat{L}_S(f) + 2\mathfrak{R}_m(\mathcal{F}) + \sqrt{\frac{\log(1/\delta)}{2m}}
$$

**è¯æ˜æ€è·¯**ï¼š

1. å¯¹ç§°åŒ–ï¼šå¼•å…¥ghost sample $S'$
2. ç”¨Rademacheréšæœºå˜é‡æ›¿æ¢
3. McDiarmidä¸ç­‰å¼æ§åˆ¶é›†ä¸­

---

### 4. æ€§è´¨ä¸è®¡ç®—

**æ€§è´¨ 4.1 (åŸºæœ¬æ€§è´¨)**:

1. **å•è°ƒæ€§**ï¼š$\mathcal{F}_1 \subseteq \mathcal{F}_2 \Rightarrow \mathfrak{R}_m(\mathcal{F}_1) \leq \mathfrak{R}_m(\mathcal{F}_2)$

2. **ç¼©æ”¾**ï¼š$\mathfrak{R}_m(c\mathcal{F}) = |c| \mathfrak{R}_m(\mathcal{F})$

3. **Lipschitzç»„åˆ**ï¼šè‹¥ $\phi$ æ˜¯ $L$-Lipschitzï¼Œåˆ™
   $$
   \mathfrak{R}_m(\phi \circ \mathcal{F}) \leq L \mathfrak{R}_m(\mathcal{F})
   $$

4. **å‡¸åŒ…**ï¼š$\mathfrak{R}_m(\text{conv}(\mathcal{F})) = \mathfrak{R}_m(\mathcal{F})$

---

**ç¤ºä¾‹ 4.2 (ç¥ç»ç½‘ç»œ)**:

å¯¹äº $L$ å±‚å…¨è¿æ¥ç½‘ç»œï¼Œæƒé‡çŸ©é˜µè°±èŒƒæ•°å—é™ $\|W_\ell\|_2 \leq M_\ell$ï¼š

$$
\mathfrak{R}_m(\mathcal{F}_{\text{NN}}) \leq \frac{\prod_{\ell=1}^{L} M_\ell}{\sqrt{m}} \cdot \|X\|_F
$$

å…¶ä¸­ $\|X\|_F$ æ˜¯è¾“å…¥æ•°æ®çš„FrobeniusèŒƒæ•°ã€‚

---

## ğŸ”— ä¸¤ç§å¤æ‚åº¦çš„å…³ç³»

**å®šç† (Massartå¼•ç†)**:

è®¾ $\mathcal{H}$ çš„VCç»´ä¸º $d$ï¼Œåˆ™ï¼š

$$
\mathfrak{R}_m(\mathcal{H}) \leq \sqrt{\frac{2d \log(em/d)}{m}}
$$

**æ„ä¹‰**ï¼š

- VCç»´ â†’ Rademacherå¤æ‚åº¦çš„æ¡¥æ¢
- Rademacherå¤æ‚åº¦é€šå¸¸ç»™å‡ºæ›´ç´§çš„ç•Œï¼ˆæ•°æ®ä¾èµ–ï¼‰

---

**æ¯”è¾ƒè¡¨**:

| ç‰¹æ€§ | VCç»´ | Rademacherå¤æ‚åº¦ |
|------|------|------------------|
| **ç±»å‹** | ç»„åˆæ€§è´¨ | æ¦‚ç‡æ€§è´¨ |
| **æ•°æ®ä¾èµ–** | å¦ | æ˜¯ |
| **è®¡ç®—éš¾åº¦** | é€šå¸¸å›°éš¾ | å¯è’™ç‰¹å¡æ´›ä¼°è®¡ |
| **æ³›åŒ–ç•Œç´§åº¦** | è¾ƒæ¾ | è¾ƒç´§ |
| **é€‚ç”¨èŒƒå›´** | äºŒåˆ†ç±» | ä»»æ„æŸå¤±å‡½æ•° |

---

## ğŸ¤– AIåº”ç”¨

### 1. ç¥ç»ç½‘ç»œçš„VCç»´

**å®šç† (ç¥ç»ç½‘ç»œVCç»´)**:

è®¾ $L$ å±‚å…¨è¿æ¥ç½‘ç»œï¼Œæ€»å‚æ•°æ•°é‡ä¸º $W$ï¼Œåˆ™ï¼š

$$
\text{VCdim}(\mathcal{H}_{\text{NN}}) = O(W L \log W)
$$

**æ¨è®º**ï¼š

- è¿‡å‚æ•°åŒ–ç½‘ç»œï¼ˆ$W \gg m$ï¼‰çš„VCç»´å¯èƒ½è¿œå¤§äºæ ·æœ¬æ•°
- **VCç»´ç†è®ºæ— æ³•è§£é‡Šæ·±åº¦å­¦ä¹ çš„æ³›åŒ–ï¼**
- éœ€è¦æ›´ç²¾ç»†çš„å·¥å…·ï¼ˆRademacherå¤æ‚åº¦ã€è°±èŒƒæ•°ã€è·¯å¾„èŒƒæ•°ç­‰ï¼‰

---

### 2. æ·±åº¦å­¦ä¹ ä¸­çš„Rademacherå¤æ‚åº¦

**æ­£åˆ™åŒ–ä¸Rademacherå¤æ‚åº¦**:

å¸¸è§æ­£åˆ™åŒ–æŠ€æœ¯å¦‚ä½•å½±å“Rademacherå¤æ‚åº¦ï¼š

| æ­£åˆ™åŒ– | å¯¹Rademacherå¤æ‚åº¦çš„å½±å“ |
|--------|--------------------------|
| **æƒé‡è¡°å‡** ($\|W\|_F^2$) | é™åˆ¶è°±èŒƒæ•° â†’ $\mathfrak{R} = O(1/\sqrt{m})$ |
| **Dropout** | éšå¼çº¦æŸ â†’ é™ä½å¤æ‚åº¦ |
| **æ‰¹å½’ä¸€åŒ–** | æ ‡å‡†åŒ–æ¿€æ´» â†’ æ§åˆ¶Lipschitzå¸¸æ•° |
| **è·¯å¾„èŒƒæ•°** | ç›´æ¥æ§åˆ¶ $\mathfrak{R}$ |

---

### 3. æ¨¡å‹é€‰æ‹©

**åº”ç”¨ 3.1 (ç»“æ„é£é™©æœ€å°åŒ– SRM)**:

æ ¹æ®æ³›åŒ–ç•Œé€‰æ‹©æ¨¡å‹å¤æ‚åº¦ï¼š

$$
\min_{h \in \mathcal{H}} \left\{\hat{L}_S(h) + \lambda \sqrt{\frac{\text{VCdim}(\mathcal{H})}{m}}\right\}
$$

æˆ–ä½¿ç”¨Rademacherå¤æ‚åº¦ï¼š

$$
\min_{h \in \mathcal{H}} \left\{\hat{L}_S(h) + \lambda \mathfrak{R}_m(\mathcal{H})\right\}
$$

---

## ğŸ’» Pythonå®ç°

### 1. VCç»´è®¡ç®—ç¤ºä¾‹

```python
import numpy as np
from itertools import combinations, product

def check_shattering(points, hypothesis_class):
    """
    æ£€æŸ¥å‡è®¾ç±»æ˜¯å¦èƒ½æ‰“æ•£ç»™å®šç‚¹é›†

    Args:
        points: np.array, shape (n, d)
        hypothesis_class: å‡è®¾å‡½æ•°åˆ—è¡¨

    Returns:
        bool: æ˜¯å¦æ‰“æ•£
    """
    n = len(points)

    # ç”Ÿæˆæ‰€æœ‰å¯èƒ½çš„æ ‡ç­¾
    all_labels = list(product([0, 1], repeat=n))

    # æ£€æŸ¥æ¯ç§æ ‡ç­¾ç»„åˆæ˜¯å¦å¯å®ç°
    realizable_labels = set()
    for h in hypothesis_class:
        labels = tuple(h(x) for x in points)
        realizable_labels.add(labels)

    return len(realizable_labels) == 2**n


def compute_vc_dimension(hypothesis_class, max_dim=10, n_trials=100):
    """
    è’™ç‰¹å¡æ´›ä¼°è®¡VCç»´

    Args:
        hypothesis_class: å‡è®¾å‡½æ•°åˆ—è¡¨
        max_dim: æœ€å¤§æµ‹è¯•ç»´åº¦
        n_trials: æ¯ä¸ªç»´åº¦çš„è¯•éªŒæ¬¡æ•°

    Returns:
        int: ä¼°è®¡çš„VCç»´
    """
    for d in range(1, max_dim + 1):
        shattered = False

        for _ in range(n_trials):
            # éšæœºç”Ÿæˆ d ä¸ªç‚¹
            points = np.random.randn(d, 2)  # 2Dç©ºé—´

            if check_shattering(points, hypothesis_class):
                shattered = True
                break

        if not shattered:
            return d - 1

    return max_dim


# ç¤ºä¾‹: çº¿æ€§åˆ†ç±»å™¨çš„VCç»´
class LinearClassifier:
    def __init__(self, w, b):
        self.w = w
        self.b = b

    def __call__(self, x):
        return int(np.dot(self.w, x) + self.b >= 0)


# ç”Ÿæˆå‡è®¾ç±» (åœ¨ç½‘æ ¼ä¸Šé‡‡æ ·)
hypothesis_class = []
for w1 in np.linspace(-1, 1, 10):
    for w2 in np.linspace(-1, 1, 10):
        for b in np.linspace(-1, 1, 10):
            hypothesis_class.append(LinearClassifier(np.array([w1, w2]), b))

vc_dim = compute_vc_dimension(hypothesis_class, max_dim=5, n_trials=50)
print(f"Estimated VC dimension: {vc_dim}")
# ç†è®ºå€¼: 3 (2Dçº¿æ€§åˆ†ç±»å™¨)
```

---

### 2. Rademacherå¤æ‚åº¦ä¼°è®¡

```python
import numpy as np

def empirical_rademacher_complexity(X, hypothesis_class, n_samples=1000):
    """
    è’™ç‰¹å¡æ´›ä¼°è®¡ç»éªŒRademacherå¤æ‚åº¦

    Args:
        X: æ•°æ®æ ·æœ¬, shape (m, d)
        hypothesis_class: å‡è®¾å‡½æ•°åˆ—è¡¨
        n_samples: Rademacheré‡‡æ ·æ¬¡æ•°

    Returns:
        float: ç»éªŒRademacherå¤æ‚åº¦
    """
    m = len(X)
    supremums = []

    for _ in range(n_samples):
        # é‡‡æ ·Rademacherå˜é‡
        sigma = np.random.choice([-1, 1], size=m)

        # è®¡ç®— sup_{h in H} (1/m) * sum sigma_i h(x_i)
        correlations = []
        for h in hypothesis_class:
            predictions = np.array([h(x) for x in X])
            correlation = np.mean(sigma * predictions)
            correlations.append(correlation)

        supremums.append(max(correlations))

    return np.mean(supremums)


# ç¤ºä¾‹: çº¿æ€§å‡½æ•°ç±»
X = np.random.randn(100, 2)

# ç”Ÿæˆæœ‰ç•Œçº¿æ€§å‡½æ•°ç±»
hypothesis_class = []
for _ in range(500):
    w = np.random.randn(2)
    w = w / np.linalg.norm(w)  # å½’ä¸€åŒ–
    hypothesis_class.append(lambda x, w=w: np.dot(w, x))

rad_complexity = empirical_rademacher_complexity(X, hypothesis_class, n_samples=1000)
print(f"Empirical Rademacher complexity: {rad_complexity:.4f}")

# ç†è®ºé¢„æµ‹: R / sqrt(m) â‰ˆ 1 / sqrt(100) = 0.1
theoretical = 1.0 / np.sqrt(len(X))
print(f"Theoretical prediction: {theoretical:.4f}")
```

---

**å¯è§†åŒ–Rademacherå¤æ‚åº¦**:

```python
import matplotlib.pyplot as plt

def plot_rademacher_vs_sample_size():
    """Rademacherå¤æ‚åº¦éšæ ·æœ¬æ•°çš„å˜åŒ–"""
    sample_sizes = [10, 20, 50, 100, 200, 500, 1000]
    empirical_rad = []

    for m in sample_sizes:
        X = np.random.randn(m, 2)

        # å•ä½çƒå†…çº¿æ€§å‡½æ•°
        hypothesis_class = []
        for _ in range(300):
            w = np.random.randn(2)
            w = w / np.linalg.norm(w)
            hypothesis_class.append(lambda x, w=w: np.dot(w, x))

        rad = empirical_rademacher_complexity(X, hypothesis_class, n_samples=100)
        empirical_rad.append(rad)

    # ç†è®ºæ›²çº¿
    theoretical = [1.0 / np.sqrt(m) for m in sample_sizes]

    plt.figure(figsize=(10, 6))
    plt.plot(sample_sizes, empirical_rad, 'o-', label='Empirical', linewidth=2, markersize=8)
    plt.plot(sample_sizes, theoretical, '--', label=r'Theoretical $1/\sqrt{m}$', linewidth=2)
    plt.xlabel('Sample Size (m)', fontsize=12)
    plt.ylabel('Rademacher Complexity', fontsize=12)
    plt.title('Rademacher Complexity vs Sample Size', fontsize=14)
    plt.legend(fontsize=12)
    plt.grid(True, alpha=0.3)
    plt.xscale('log')
    plt.yscale('log')
    plt.tight_layout()
    plt.show()

# plot_rademacher_vs_sample_size()
```

---

## ğŸ”¬ å½¢å¼åŒ–è¯æ˜ (Lean 4)

```lean
import Mathlib.Probability.ProbabilityMassFunction.Basic
import Mathlib.Data.Fintype.Card
import Mathlib.Combinatorics.SimpleGraph.Basic

-- VCç»´çš„å½¢å¼åŒ–å®šä¹‰
structure HypothesisClass (X : Type*) where
  H : Set (X â†’ Bool)

-- æ‰“æ•£çš„å®šä¹‰
def Shatters {X : Type*} (hc : HypothesisClass X) (C : Finset X) : Prop :=
  âˆ€ (labeling : X â†’ Bool), âˆƒ h âˆˆ hc.H, âˆ€ x âˆˆ C, h x = labeling x

-- VCç»´
noncomputable def VCDimension {X : Type*} (hc : HypothesisClass X) : â„• :=
  sSup {d : â„• | âˆƒ (C : Finset X), C.card = d âˆ§ Shatters hc C}

-- Sauerå¼•ç†
theorem sauer_lemma {X : Type*} [Fintype X] (hc : HypothesisClass X) (d : â„•)
  (h_vc : VCDimension hc â‰¤ d) (S : Finset X) (h_size : d â‰¤ S.card) :
  (hc.H.restrict S).ncard â‰¤ âˆ‘ i in Finset.range (d + 1), Nat.choose S.card i := by
  sorry

-- Rademacherå¤æ‚åº¦
structure FunctionClass (X : Type*) where
  F : Set (X â†’ â„)

noncomputable def EmpiricalRademacherComplexity
  {X : Type*} (fc : FunctionClass X) (S : List X) : â„ :=
  -- E_Ïƒ [ sup_{f âˆˆ F} (1/m) Î£ Ïƒ_i f(x_i) ]
  sorry

-- Rademacheræ³›åŒ–ç•Œ
theorem rademacher_generalization_bound
  {X : Type*} (fc : FunctionClass X)
  (m : â„•) (Î´ : â„) (h_Î´ : 0 < Î´ âˆ§ Î´ < 1) :
  -- ä»¥æ¦‚ç‡ â‰¥ 1-Î´, æ³›åŒ–è¯¯å·®ç”±Rademacherå¤æ‚åº¦æ§åˆ¶
  sorry := by
  sorry

-- VCç»´ä¸Rademacherå¤æ‚åº¦çš„å…³ç³»
theorem vc_to_rademacher {X : Type*} (hc : HypothesisClass X) (m : â„•) :
  let d := VCDimension hc
  EmpiricalRademacherComplexity âŸ¨{f | âˆƒ h âˆˆ hc.H, f = fun x => if h x then 1 else 0}âŸ© [] â‰¤
    Real.sqrt (2 * d * Real.log (m / d) / m) := by
  sorry
```

---

## ğŸ“š æ ¸å¿ƒå®šç†æ€»ç»“

| å®šç† | é™ˆè¿° | æ„ä¹‰ |
|------|------|------|
| **VCç»´æ³›åŒ–ç•Œ** | $L_D(h) \leq \hat{L}_S(h) + O(\sqrt{d/m})$ | VCç»´æ§åˆ¶æ³›åŒ– |
| **Sauerå¼•ç†** | $\|\mathcal{H}_S\| \leq (em/d)^d$ | å¢é•¿å‡½æ•°ä»æŒ‡æ•°åˆ°å¤šé¡¹å¼ |
| **Rademacherç•Œ** | $L_D(f) \leq \hat{L}_S(f) + 2\mathfrak{R}_m(\mathcal{F})$ | æ›´ç´§çš„æ•°æ®ä¾èµ–ç•Œ |
| **Massartå¼•ç†** | $\mathfrak{R}_m(\mathcal{H}) \leq \sqrt{2d\log(em/d)/m}$ | VCç»´ â†’ Rademacher |

---

## ğŸ“ ç›¸å…³è¯¾ç¨‹

| å¤§å­¦ | è¯¾ç¨‹ | è¦†ç›–å†…å®¹ |
|------|------|----------|
| **MIT** | 9.520 Statistical Learning Theory | VCç»´ã€Rademacherå¤æ‚åº¦ã€æ ¸æ–¹æ³• |
| **Stanford** | CS229T Statistical Learning Theory | PACå­¦ä¹ ã€æ³›åŒ–ç•Œã€åœ¨çº¿å­¦ä¹  |
| **CMU** | 10-715 Advanced Machine Learning | VCç»´ã€PAC-Bayesã€ç®—æ³•ç¨³å®šæ€§ |
| **Cambridge** | L90 Statistical Theory of ML | VCç†è®ºã€æœ€ä¼˜ç‡ã€è‡ªé€‚åº”æ€§ |

---

## ğŸ“– å‚è€ƒæ–‡çŒ®

1. **Vapnik & Chervonenkis (1971)**. "On the Uniform Convergence of Relative Frequencies of Events to Their Probabilities". *Theory of Probability & Its Applications*.

2. **Shalev-Shwartz & Ben-David (2014)**. *Understanding Machine Learning: From Theory to Algorithms*. Cambridge University Press.

3. **Bartlett & Mendelson (2002)**. "Rademacher and Gaussian Complexities: Risk Bounds and Structural Results". *JMLR*.

4. **Mohri et al. (2018)**. *Foundations of Machine Learning* (2nd ed.). MIT Press.

5. **Boucheron et al. (2013)**. *Concentration Inequalities*. Oxford University Press.

---

## ğŸ”— ç›¸å…³æ–‡æ¡£

- [PACå­¦ä¹ æ¡†æ¶](01-PAC-Learning-Framework.md)
- [æ³›åŒ–ç†è®º](03-Generalization-Theory.md)
- [ç¥ç»ç½‘ç»œé€šç”¨é€¼è¿‘å®šç†](../02-Deep-Learning-Math/01-Universal-Approximation-Theorem.md)
- [ç»Ÿè®¡å­¦ä¹ ç†è®ºæ¨¡å—ä¸»é¡µ](README.md)

---

## âœï¸ ç»ƒä¹ 

**ç»ƒä¹  1 (åŸºç¡€)**ï¼šè¯æ˜ä¸€ç»´é˜ˆå€¼å‡½æ•°çš„VCç»´ä¸º1ã€‚

**ç»ƒä¹  2 (ä¸­ç­‰)**ï¼šè®¡ç®— $\mathbb{R}^2$ ä¸Šè½´å¯¹é½çŸ©å½¢çš„VCç»´ã€‚

**ç»ƒä¹  3 (ä¸­ç­‰)**ï¼šè¯æ˜æœ‰é™å‡è®¾ç±» $|\mathcal{H}| = k$ çš„VCç»´æ»¡è¶³ $\text{VCdim}(\mathcal{H}) \leq \log_2 k$ã€‚

**ç»ƒä¹  4 (å›°éš¾)**ï¼šè¯æ˜Sauerå¼•ç†ï¼ˆæç¤ºï¼šä½¿ç”¨åŒé‡å½’çº³ï¼‰ã€‚

**ç»ƒä¹  5 (å®è·µ)**ï¼šå®ç°Rademacherå¤æ‚åº¦ä¼°è®¡ï¼Œå¹¶åœ¨çœŸå®æ•°æ®é›†ä¸Šæ¯”è¾ƒä¸åŒæ¨¡å‹çš„å¤æ‚åº¦ã€‚

**ç»ƒä¹  6 (ç ”ç©¶)**ï¼šé˜…è¯»Bartlettç­‰äººå…³äºç¥ç»ç½‘ç»œè°±èŒƒæ•°ç•Œçš„è®ºæ–‡ï¼Œæ¨å¯¼æ·±åº¦ç½‘ç»œçš„Rademacherå¤æ‚åº¦ã€‚

---

*æœ€åæ›´æ–°ï¼š2025å¹´10æœˆ*-
