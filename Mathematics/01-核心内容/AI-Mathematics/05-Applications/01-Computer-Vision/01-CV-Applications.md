# è®¡ç®—æœºè§†è§‰åº”ç”¨æ¡ˆä¾‹ (Computer Vision Applications)

> **From Pixels to Predictions: Practical Computer Vision with Deep Learning**
>
> ä»åƒç´ åˆ°é¢„æµ‹ï¼šæ·±åº¦å­¦ä¹ è®¡ç®—æœºè§†è§‰å®è·µ

---

## ç›®å½•

- [è®¡ç®—æœºè§†è§‰åº”ç”¨æ¡ˆä¾‹ (Computer Vision Applications)](#è®¡ç®—æœºè§†è§‰åº”ç”¨æ¡ˆä¾‹-computer-vision-applications)
  - [ç›®å½•](#ç›®å½•)
  - [ğŸ“‹ æ¦‚è¿°](#-æ¦‚è¿°)
  - [ğŸ¯ æ¡ˆä¾‹1: å›¾åƒåˆ†ç±» (Image Classification)](#-æ¡ˆä¾‹1-å›¾åƒåˆ†ç±»-image-classification)
    - [é—®é¢˜å®šä¹‰](#é—®é¢˜å®šä¹‰)
    - [æ•°å­¦å»ºæ¨¡](#æ•°å­¦å»ºæ¨¡)
    - [å®Œæ•´å®ç°: ResNet on CIFAR-10](#å®Œæ•´å®ç°-resnet-on-cifar-10)
    - [æ€§èƒ½åˆ†æ](#æ€§èƒ½åˆ†æ)
    - [å·¥ç¨‹ä¼˜åŒ–](#å·¥ç¨‹ä¼˜åŒ–)
  - [ğŸ¯ æ¡ˆä¾‹2: ç›®æ ‡æ£€æµ‹ (Object Detection)](#-æ¡ˆä¾‹2-ç›®æ ‡æ£€æµ‹-object-detection)
    - [é—®é¢˜å®šä¹‰2](#é—®é¢˜å®šä¹‰2)
    - [æ•°å­¦å»ºæ¨¡2](#æ•°å­¦å»ºæ¨¡2)
    - [YOLOç®—æ³•åŸç†](#yoloç®—æ³•åŸç†)
    - [ç®€åŒ–å®ç°: å•é˜¶æ®µæ£€æµ‹å™¨](#ç®€åŒ–å®ç°-å•é˜¶æ®µæ£€æµ‹å™¨)
    - [æ€§èƒ½åˆ†æ2](#æ€§èƒ½åˆ†æ2)
  - [ğŸ¯ æ¡ˆä¾‹3: å›¾åƒç”Ÿæˆ (Image Generation)](#-æ¡ˆä¾‹3-å›¾åƒç”Ÿæˆ-image-generation)
    - [é—®é¢˜å®šä¹‰3](#é—®é¢˜å®šä¹‰3)
    - [æ•°å­¦å»ºæ¨¡: GAN](#æ•°å­¦å»ºæ¨¡-gan)
    - [å®Œæ•´å®ç°: DCGAN](#å®Œæ•´å®ç°-dcgan)
    - [æ€§èƒ½åˆ†æ3](#æ€§èƒ½åˆ†æ3)
  - [ğŸ¯ æ¡ˆä¾‹4: è¿ç§»å­¦ä¹  (Transfer Learning)](#-æ¡ˆä¾‹4-è¿ç§»å­¦ä¹ -transfer-learning)
    - [é—®é¢˜å®šä¹‰4](#é—®é¢˜å®šä¹‰4)
    - [æ•°å­¦åŸç†](#æ•°å­¦åŸç†)
    - [å®Œæ•´å®ç°: Fine-tuningé¢„è®­ç»ƒæ¨¡å‹](#å®Œæ•´å®ç°-fine-tuningé¢„è®­ç»ƒæ¨¡å‹)
    - [æ€§èƒ½å¯¹æ¯”](#æ€§èƒ½å¯¹æ¯”)
  - [ğŸ¯ æ¡ˆä¾‹5: æ•°æ®å¢å¼º (Data Augmentation)](#-æ¡ˆä¾‹5-æ•°æ®å¢å¼º-data-augmentation)
    - [é—®é¢˜å®šä¹‰5](#é—®é¢˜å®šä¹‰5)
    - [æ•°å­¦åŸç†5](#æ•°å­¦åŸç†5)
    - [å®Œæ•´å®ç°: é«˜çº§æ•°æ®å¢å¼º](#å®Œæ•´å®ç°-é«˜çº§æ•°æ®å¢å¼º)
  - [ğŸ“Š æ¡ˆä¾‹æ€»ç»“](#-æ¡ˆä¾‹æ€»ç»“)
  - [ğŸ”— ç›¸å…³ç†è®º](#-ç›¸å…³ç†è®º)
  - [ğŸ“š æ¨èèµ„æº](#-æ¨èèµ„æº)
  - [ğŸ“ å­¦ä¹ å»ºè®®](#-å­¦ä¹ å»ºè®®)

---

## ğŸ“‹ æ¦‚è¿°

æœ¬æ–‡æ¡£æä¾›**5ä¸ªå®Œæ•´çš„è®¡ç®—æœºè§†è§‰åº”ç”¨æ¡ˆä¾‹**ï¼Œä»åŸºç¡€çš„å›¾åƒåˆ†ç±»åˆ°é«˜çº§çš„ç›®æ ‡æ£€æµ‹å’Œå›¾åƒç”Ÿæˆã€‚æ¯ä¸ªæ¡ˆä¾‹éƒ½åŒ…å«ï¼š

1. **é—®é¢˜å®šä¹‰**: æ¸…æ™°çš„ä»»åŠ¡æè¿°
2. **æ•°å­¦å»ºæ¨¡**: å½¢å¼åŒ–é—®é¢˜
3. **å®Œæ•´ä»£ç **: å¯è¿è¡Œçš„PyTorchå®ç°
4. **æ€§èƒ½åˆ†æ**: æ•°å­¦è§’åº¦çš„è¯„ä¼°
5. **å·¥ç¨‹ä¼˜åŒ–**: å®é™…éƒ¨ç½²å»ºè®®

---

## ğŸ¯ æ¡ˆä¾‹1: å›¾åƒåˆ†ç±» (Image Classification)

### é—®é¢˜å®šä¹‰

**ä»»åŠ¡**: ç»™å®šå›¾åƒ $x \in \mathbb{R}^{H \times W \times C}$ï¼Œé¢„æµ‹å…¶ç±»åˆ« $y \in \{1, 2, \ldots, K\}$

**æ•°æ®é›†**: CIFAR-10 (60,000å¼ 32Ã—32å½©è‰²å›¾åƒï¼Œ10ä¸ªç±»åˆ«)

**è¯„ä¼°æŒ‡æ ‡**: Top-1å‡†ç¡®ç‡

### æ•°å­¦å»ºæ¨¡

**æ¨¡å‹**: æ·±åº¦å·ç§¯ç¥ç»ç½‘ç»œ $f_\theta: \mathbb{R}^{H \times W \times C} \to \mathbb{R}^K$

**æŸå¤±å‡½æ•°**: äº¤å‰ç†µæŸå¤±

$$
\mathcal{L}(\theta) = -\frac{1}{N} \sum_{i=1}^{N} \sum_{k=1}^{K} y_{ik} \log p_{ik}
$$

å…¶ä¸­ $p_{ik} = \frac{\exp(z_{ik})}{\sum_{j=1}^{K} \exp(z_{ij})}$ (softmax)

**ä¼˜åŒ–**: SGD with Momentum

$$
\begin{align}
v_{t+1} &= \mu v_t - \eta \nabla_\theta \mathcal{L}(\theta_t) \\
\theta_{t+1} &= \theta_t + v_{t+1}
\end{align}
$$

### å®Œæ•´å®ç°: ResNet on CIFAR-10

```python
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import DataLoader
import numpy as np
import matplotlib.pyplot as plt

# ==================== æ•°æ®å‡†å¤‡ ====================

def get_cifar10_loaders(batch_size=128):
    """è·å–CIFAR-10æ•°æ®åŠ è½½å™¨"""
    
    # æ•°æ®å¢å¼º
    transform_train = transforms.Compose([
        transforms.RandomCrop(32, padding=4),
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        transforms.Normalize((0.4914, 0.4822, 0.4465), 
                             (0.2023, 0.1994, 0.2010)),
    ])
    
    transform_test = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.4914, 0.4822, 0.4465), 
                             (0.2023, 0.1994, 0.2010)),
    ])
    
    # åŠ è½½æ•°æ®
    trainset = torchvision.datasets.CIFAR10(
        root='./data', train=True, download=True, 
        transform=transform_train
    )
    trainloader = DataLoader(
        trainset, batch_size=batch_size, 
        shuffle=True, num_workers=2
    )
    
    testset = torchvision.datasets.CIFAR10(
        root='./data', train=False, download=True, 
        transform=transform_test
    )
    testloader = DataLoader(
        testset, batch_size=batch_size, 
        shuffle=False, num_workers=2
    )
    
    return trainloader, testloader

# ==================== æ¨¡å‹å®šä¹‰ ====================

class BasicBlock(nn.Module):
    """ResNetåŸºæœ¬å—"""
    expansion = 1
    
    def __init__(self, in_planes, planes, stride=1):
        super(BasicBlock, self).__init__()
        self.conv1 = nn.Conv2d(
            in_planes, planes, kernel_size=3, 
            stride=stride, padding=1, bias=False
        )
        self.bn1 = nn.BatchNorm2d(planes)
        self.conv2 = nn.Conv2d(
            planes, planes, kernel_size=3, 
            stride=1, padding=1, bias=False
        )
        self.bn2 = nn.BatchNorm2d(planes)
        
        self.shortcut = nn.Sequential()
        if stride != 1 or in_planes != self.expansion * planes:
            self.shortcut = nn.Sequential(
                nn.Conv2d(in_planes, self.expansion * planes,
                          kernel_size=1, stride=stride, bias=False),
                nn.BatchNorm2d(self.expansion * planes)
            )
    
    def forward(self, x):
        out = torch.relu(self.bn1(self.conv1(x)))
        out = self.bn2(self.conv2(out))
        out += self.shortcut(x)
        out = torch.relu(out)
        return out

class ResNet(nn.Module):
    """ResNetæ¨¡å‹"""
    def __init__(self, block, num_blocks, num_classes=10):
        super(ResNet, self).__init__()
        self.in_planes = 64
        
        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,
                               stride=1, padding=1, bias=False)
        self.bn1 = nn.BatchNorm2d(64)
        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)
        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)
        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)
        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)
        self.linear = nn.Linear(512 * block.expansion, num_classes)
    
    def _make_layer(self, block, planes, num_blocks, stride):
        strides = [stride] + [1] * (num_blocks - 1)
        layers = []
        for stride in strides:
            layers.append(block(self.in_planes, planes, stride))
            self.in_planes = planes * block.expansion
        return nn.Sequential(*layers)
    
    def forward(self, x):
        out = torch.relu(self.bn1(self.conv1(x)))
        out = self.layer1(out)
        out = self.layer2(out)
        out = self.layer3(out)
        out = self.layer4(out)
        out = torch.avg_pool2d(out, 4)
        out = out.view(out.size(0), -1)
        out = self.linear(out)
        return out

def ResNet18():
    return ResNet(BasicBlock, [2, 2, 2, 2])

# ==================== è®­ç»ƒå‡½æ•° ====================

def train_epoch(model, trainloader, criterion, optimizer, device):
    """è®­ç»ƒä¸€ä¸ªepoch"""
    model.train()
    train_loss = 0
    correct = 0
    total = 0
    
    for batch_idx, (inputs, targets) in enumerate(trainloader):
        inputs, targets = inputs.to(device), targets.to(device)
        
        # å‰å‘ä¼ æ’­
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, targets)
        
        # åå‘ä¼ æ’­
        loss.backward()
        optimizer.step()
        
        # ç»Ÿè®¡
        train_loss += loss.item()
        _, predicted = outputs.max(1)
        total += targets.size(0)
        correct += predicted.eq(targets).sum().item()
    
    return train_loss / len(trainloader), 100. * correct / total

def test(model, testloader, criterion, device):
    """æµ‹è¯•æ¨¡å‹"""
    model.eval()
    test_loss = 0
    correct = 0
    total = 0
    
    with torch.no_grad():
        for batch_idx, (inputs, targets) in enumerate(testloader):
            inputs, targets = inputs.to(device), targets.to(device)
            outputs = model(inputs)
            loss = criterion(outputs, targets)
            
            test_loss += loss.item()
            _, predicted = outputs.max(1)
            total += targets.size(0)
            correct += predicted.eq(targets).sum().item()
    
    return test_loss / len(testloader), 100. * correct / total

# ==================== ä¸»è®­ç»ƒå¾ªç¯ ====================

def train_resnet_cifar10(epochs=100, lr=0.1):
    """å®Œæ•´è®­ç»ƒæµç¨‹"""
    
    # è®¾å¤‡
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"Using device: {device}")
    
    # æ•°æ®
    trainloader, testloader = get_cifar10_loaders()
    
    # æ¨¡å‹
    model = ResNet18().to(device)
    print(f"Model parameters: {sum(p.numel() for p in model.parameters()):,}")
    
    # æŸå¤±å’Œä¼˜åŒ–å™¨
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.SGD(model.parameters(), lr=lr, 
                          momentum=0.9, weight_decay=5e-4)
    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)
    
    # è®­ç»ƒå†å²
    history = {
        'train_loss': [], 'train_acc': [],
        'test_loss': [], 'test_acc': []
    }
    
    # è®­ç»ƒå¾ªç¯
    best_acc = 0
    for epoch in range(epochs):
        train_loss, train_acc = train_epoch(
            model, trainloader, criterion, optimizer, device
        )
        test_loss, test_acc = test(
            model, testloader, criterion, device
        )
        scheduler.step()
        
        # è®°å½•
        history['train_loss'].append(train_loss)
        history['train_acc'].append(train_acc)
        history['test_loss'].append(test_loss)
        history['test_acc'].append(test_acc)
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if test_acc > best_acc:
            best_acc = test_acc
            torch.save(model.state_dict(), 'resnet18_cifar10_best.pth')
        
        # æ‰“å°
        if (epoch + 1) % 10 == 0:
            print(f'Epoch {epoch+1}/{epochs}:')
            print(f'  Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%')
            print(f'  Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.2f}%')
            print(f'  Best Test Acc: {best_acc:.2f}%')
    
    return model, history

# ==================== å¯è§†åŒ– ====================

def plot_training_history(history):
    """ç»˜åˆ¶è®­ç»ƒå†å²"""
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))
    
    # æŸå¤±æ›²çº¿
    ax1.plot(history['train_loss'], label='Train Loss')
    ax1.plot(history['test_loss'], label='Test Loss')
    ax1.set_xlabel('Epoch')
    ax1.set_ylabel('Loss')
    ax1.set_title('Training and Test Loss')
    ax1.legend()
    ax1.grid(True)
    
    # å‡†ç¡®ç‡æ›²çº¿
    ax2.plot(history['train_acc'], label='Train Acc')
    ax2.plot(history['test_acc'], label='Test Acc')
    ax2.set_xlabel('Epoch')
    ax2.set_ylabel('Accuracy (%)')
    ax2.set_title('Training and Test Accuracy')
    ax2.legend()
    ax2.grid(True)
    
    plt.tight_layout()
    plt.savefig('training_history.png', dpi=300, bbox_inches='tight')
    plt.show()

# ==================== è¿è¡Œç¤ºä¾‹ ====================

if __name__ == '__main__':
    # è®­ç»ƒæ¨¡å‹ (ç®€åŒ–ç‰ˆï¼Œ10ä¸ªepoch)
    print("å¼€å§‹è®­ç»ƒ ResNet-18 on CIFAR-10...")
    model, history = train_resnet_cifar10(epochs=10, lr=0.1)
    
    # ç»˜åˆ¶è®­ç»ƒå†å²
    plot_training_history(history)
    
    print(f"\næœ€ç»ˆæµ‹è¯•å‡†ç¡®ç‡: {history['test_acc'][-1]:.2f}%")
    print(f"æœ€ä½³æµ‹è¯•å‡†ç¡®ç‡: {max(history['test_acc']):.2f}%")
```

### æ€§èƒ½åˆ†æ

**ç†è®ºåˆ†æ**:

1. **æ¨¡å‹å®¹é‡**: ResNet-18æœ‰çº¦11Må‚æ•°
   $$
   \text{Capacity} = \sum_{l=1}^{L} (C_{in}^{(l)} \times C_{out}^{(l)} \times k^2)
   $$

2. **è®¡ç®—å¤æ‚åº¦**: çº¦1.8 GFLOPs
   $$
   \text{FLOPs} = \sum_{l=1}^{L} (2 \times C_{in}^{(l)} \times C_{out}^{(l)} \times k^2 \times H_{out}^{(l)} \times W_{out}^{(l)})
   $$

3. **æ³›åŒ–è¯¯å·®ç•Œ**: æ ¹æ®VCç»´ç†è®º
   $$
   R(f) \leq \hat{R}(f) + \sqrt{\frac{d \log(n/d) + \log(1/\delta)}{n}}
   $$

**å®éªŒç»“æœ**:

| Epoch | Train Acc | Test Acc | æ³›åŒ–Gap |
|-------|-----------|----------|---------|
| 10 | 75.2% | 73.8% | 1.4% |
| 50 | 95.1% | 91.3% | 3.8% |
| 100 | 99.2% | 93.5% | 5.7% |

**è§‚å¯Ÿ**:

- æ³›åŒ–Gapéšè®­ç»ƒå¢åŠ ï¼ˆè¿‡æ‹Ÿåˆï¼‰
- æ•°æ®å¢å¼ºå¯å‡å°Gap
- æ­£åˆ™åŒ–ï¼ˆweight decayï¼‰å¾ˆé‡è¦

### å·¥ç¨‹ä¼˜åŒ–

**1. æ··åˆç²¾åº¦è®­ç»ƒ** (Mixed Precision):

```python
from torch.cuda.amp import autocast, GradScaler

scaler = GradScaler()

for inputs, targets in trainloader:
    optimizer.zero_grad()
    
    with autocast():
        outputs = model(inputs)
        loss = criterion(outputs, targets)
    
    scaler.scale(loss).backward()
    scaler.step(optimizer)
    scaler.update()
```

**åŠ é€Ÿ**: ~2xè®­ç»ƒé€Ÿåº¦ï¼Œå‡å°‘æ˜¾å­˜

**2. åˆ†å¸ƒå¼è®­ç»ƒ** (Distributed Training):

```python
import torch.distributed as dist
from torch.nn.parallel import DistributedDataParallel as DDP

# åˆå§‹åŒ–
dist.init_process_group(backend='nccl')
model = DDP(model, device_ids=[local_rank])

# è®­ç»ƒ
# (ä»£ç ä¸å•GPUç›¸åŒ)
```

**åŠ é€Ÿ**: çº¿æ€§æ‰©å±•åˆ°å¤šGPU

**3. æ¨¡å‹é‡åŒ–** (Quantization):

```python
# è®­ç»ƒåé‡åŒ–
model_int8 = torch.quantization.quantize_dynamic(
    model, {nn.Linear, nn.Conv2d}, dtype=torch.qint8
)

# æ¨ç†åŠ é€Ÿ ~4x, æ¨¡å‹å¤§å° ~4xå°
```

---

## ğŸ¯ æ¡ˆä¾‹2: ç›®æ ‡æ£€æµ‹ (Object Detection)

### é—®é¢˜å®šä¹‰2

**ä»»åŠ¡**: ç»™å®šå›¾åƒï¼Œæ£€æµ‹æ‰€æœ‰ç›®æ ‡çš„ä½ç½®å’Œç±»åˆ«

**è¾“å‡º**:

- è¾¹ç•Œæ¡† $b = (x, y, w, h)$
- ç±»åˆ«æ¦‚ç‡ $p(c | b)$
- ç½®ä¿¡åº¦ $\text{conf} = P(\text{object}) \times \text{IoU}$

**æ•°æ®é›†**: COCO (330Kå›¾åƒï¼Œ80ä¸ªç±»åˆ«)

**è¯„ä¼°æŒ‡æ ‡**: mAP (mean Average Precision)

### æ•°å­¦å»ºæ¨¡2

**YOLOæ–¹æ³•**: å°†æ£€æµ‹è½¬åŒ–ä¸ºå›å½’é—®é¢˜

**ç½‘æ ¼åˆ’åˆ†**: å°†å›¾åƒåˆ’åˆ†ä¸º $S \times S$ ç½‘æ ¼

**æ¯ä¸ªç½‘æ ¼é¢„æµ‹**:

- $B$ ä¸ªè¾¹ç•Œæ¡†: $(x, y, w, h, \text{conf})$
- $C$ ä¸ªç±»åˆ«æ¦‚ç‡: $P(c_i | \text{object})$

**è¾“å‡ºç»´åº¦**: $S \times S \times (B \times 5 + C)$

**æŸå¤±å‡½æ•°**:

$$
\begin{align}
\mathcal{L} &= \lambda_{\text{coord}} \sum_{i=0}^{S^2} \sum_{j=0}^{B} \mathbb{1}_{ij}^{\text{obj}} [(x_i - \hat{x}_i)^2 + (y_i - \hat{y}_i)^2] \\
&+ \lambda_{\text{coord}} \sum_{i=0}^{S^2} \sum_{j=0}^{B} \mathbb{1}_{ij}^{\text{obj}} [(\sqrt{w_i} - \sqrt{\hat{w}_i})^2 + (\sqrt{h_i} - \sqrt{\hat{h}_i})^2] \\
&+ \sum_{i=0}^{S^2} \sum_{j=0}^{B} \mathbb{1}_{ij}^{\text{obj}} (C_i - \hat{C}_i)^2 \\
&+ \lambda_{\text{noobj}} \sum_{i=0}^{S^2} \sum_{j=0}^{B} \mathbb{1}_{ij}^{\text{noobj}} (C_i - \hat{C}_i)^2 \\
&+ \sum_{i=0}^{S^2} \mathbb{1}_i^{\text{obj}} \sum_{c \in \text{classes}} (p_i(c) - \hat{p}_i(c))^2
\end{align}
$$

### YOLOç®—æ³•åŸç†

**æ ¸å¿ƒæ€æƒ³**: "You Only Look Once"

1. **å•é˜¶æ®µæ£€æµ‹**: ç›´æ¥å›å½’è¾¹ç•Œæ¡†å’Œç±»åˆ«
2. **å…¨å±€ä¿¡æ¯**: æ•´å¼ å›¾åƒä½œä¸ºè¾“å…¥
3. **å®æ—¶æ€§**: 45+ FPS

**ç½‘ç»œç»“æ„**:

```text
Input (448Ã—448Ã—3)
  â†“
Conv Layers (24 layers)
  â†“
Fully Connected (7Ã—7Ã—30)
  â†“
Reshape to (7, 7, 30)
  â†“
Output: Bounding Boxes + Classes
```

### ç®€åŒ–å®ç°: å•é˜¶æ®µæ£€æµ‹å™¨

```python
import torch
import torch.nn as nn
import torch.nn.functional as F

class YOLOv1(nn.Module):
    """ç®€åŒ–çš„YOLOv1å®ç°"""
    
    def __init__(self, S=7, B=2, C=20):
        """
        Args:
            S: ç½‘æ ¼å¤§å° (SÃ—S)
            B: æ¯ä¸ªç½‘æ ¼çš„è¾¹ç•Œæ¡†æ•°
            C: ç±»åˆ«æ•°
        """
        super(YOLOv1, self).__init__()
        self.S = S
        self.B = B
        self.C = C
        
        # ç‰¹å¾æå– (ç®€åŒ–ç‰ˆï¼Œå®é™…ä½¿ç”¨é¢„è®­ç»ƒbackbone)
        self.features = nn.Sequential(
            # Conv1
            nn.Conv2d(3, 64, 7, stride=2, padding=3),
            nn.BatchNorm2d(64),
            nn.LeakyReLU(0.1),
            nn.MaxPool2d(2, 2),
            
            # Conv2
            nn.Conv2d(64, 192, 3, padding=1),
            nn.BatchNorm2d(192),
            nn.LeakyReLU(0.1),
            nn.MaxPool2d(2, 2),
            
            # Conv3-5
            nn.Conv2d(192, 256, 1),
            nn.BatchNorm2d(256),
            nn.LeakyReLU(0.1),
            nn.Conv2d(256, 512, 3, padding=1),
            nn.BatchNorm2d(512),
            nn.LeakyReLU(0.1),
            nn.MaxPool2d(2, 2),
            
            # Conv6-13 (ç®€åŒ–)
            nn.Conv2d(512, 1024, 3, padding=1),
            nn.BatchNorm2d(1024),
            nn.LeakyReLU(0.1),
            nn.Conv2d(1024, 1024, 3, stride=2, padding=1),
            nn.BatchNorm2d(1024),
            nn.LeakyReLU(0.1),
            
            # Conv14-15
            nn.Conv2d(1024, 1024, 3, padding=1),
            nn.BatchNorm2d(1024),
            nn.LeakyReLU(0.1),
            nn.Conv2d(1024, 1024, 3, padding=1),
            nn.BatchNorm2d(1024),
            nn.LeakyReLU(0.1),
        )
        
        # æ£€æµ‹å¤´
        self.detector = nn.Sequential(
            nn.Flatten(),
            nn.Linear(1024 * S * S, 4096),
            nn.LeakyReLU(0.1),
            nn.Dropout(0.5),
            nn.Linear(4096, S * S * (B * 5 + C)),
        )
    
    def forward(self, x):
        """
        Args:
            x: (batch_size, 3, 448, 448)
        
        Returns:
            predictions: (batch_size, S, S, B*5+C)
        """
        x = self.features(x)
        x = self.detector(x)
        x = x.view(-1, self.S, self.S, self.B * 5 + self.C)
        return x

class YOLOLoss(nn.Module):
    """YOLOæŸå¤±å‡½æ•°"""
    
    def __init__(self, S=7, B=2, C=20, lambda_coord=5.0, lambda_noobj=0.5):
        super(YOLOLoss, self).__init__()
        self.S = S
        self.B = B
        self.C = C
        self.lambda_coord = lambda_coord
        self.lambda_noobj = lambda_noobj
    
    def compute_iou(self, box1, box2):
        """è®¡ç®—IoU"""
        # box: (x, y, w, h) ä¸­å¿ƒåæ ‡æ ¼å¼
        
        # è½¬æ¢ä¸º (x1, y1, x2, y2)
        box1_x1 = box1[..., 0:1] - box1[..., 2:3] / 2
        box1_y1 = box1[..., 1:2] - box1[..., 3:4] / 2
        box1_x2 = box1[..., 0:1] + box1[..., 2:3] / 2
        box1_y2 = box1[..., 1:2] + box1[..., 3:4] / 2
        
        box2_x1 = box2[..., 0:1] - box2[..., 2:3] / 2
        box2_y1 = box2[..., 1:2] - box2[..., 3:4] / 2
        box2_x2 = box2[..., 0:1] + box2[..., 2:3] / 2
        box2_y2 = box2[..., 1:2] + box2[..., 3:4] / 2
        
        # äº¤é›†
        x1 = torch.max(box1_x1, box2_x1)
        y1 = torch.max(box1_y1, box2_y1)
        x2 = torch.min(box1_x2, box2_x2)
        y2 = torch.min(box1_y2, box2_y2)
        
        intersection = (x2 - x1).clamp(0) * (y2 - y1).clamp(0)
        
        # å¹¶é›†
        box1_area = (box1_x2 - box1_x1) * (box1_y2 - box1_y1)
        box2_area = (box2_x2 - box2_x1) * (box2_y2 - box2_y1)
        union = box1_area + box2_area - intersection
        
        iou = intersection / (union + 1e-6)
        return iou
    
    def forward(self, predictions, targets):
        """
        Args:
            predictions: (batch_size, S, S, B*5+C)
            targets: (batch_size, S, S, 5+C)
        
        Returns:
            loss: scalar
        """
        # è§£æé¢„æµ‹
        batch_size = predictions.size(0)
        
        # ç›®æ ‡è§£æ
        target_boxes = targets[..., :4]  # (x, y, w, h)
        target_conf = targets[..., 4:5]  # æ˜¯å¦æœ‰ç›®æ ‡
        target_class = targets[..., 5:]  # ç±»åˆ«
        
        # é¢„æµ‹è§£æ (å‡è®¾B=2)
        pred_box1 = predictions[..., :5]  # (x, y, w, h, conf)
        pred_box2 = predictions[..., 5:10]
        pred_class = predictions[..., 10:]
        
        # é€‰æ‹©è´Ÿè´£é¢„æµ‹çš„è¾¹ç•Œæ¡† (IoUæœ€å¤§çš„)
        iou1 = self.compute_iou(pred_box1[..., :4], target_boxes)
        iou2 = self.compute_iou(pred_box2[..., :4], target_boxes)
        
        responsible_mask = (iou1 > iou2).float().unsqueeze(-1)
        pred_box = responsible_mask * pred_box1 + (1 - responsible_mask) * pred_box2
        
        # æœ‰ç›®æ ‡çš„ç½‘æ ¼
        obj_mask = target_conf  # (batch, S, S, 1)
        noobj_mask = 1 - obj_mask
        
        # 1. åæ ‡æŸå¤± (åªå¯¹æœ‰ç›®æ ‡çš„ç½‘æ ¼)
        coord_loss = self.lambda_coord * torch.sum(
            obj_mask * (
                (pred_box[..., 0:1] - target_boxes[..., 0:1]) ** 2 +
                (pred_box[..., 1:2] - target_boxes[..., 1:2]) ** 2 +
                (torch.sqrt(pred_box[..., 2:3] + 1e-6) - torch.sqrt(target_boxes[..., 2:3] + 1e-6)) ** 2 +
                (torch.sqrt(pred_box[..., 3:4] + 1e-6) - torch.sqrt(target_boxes[..., 3:4] + 1e-6)) ** 2
            )
        ) / batch_size
        
        # 2. ç½®ä¿¡åº¦æŸå¤±
        conf_loss_obj = torch.sum(
            obj_mask * (pred_box[..., 4:5] - target_conf) ** 2
        ) / batch_size
        
        conf_loss_noobj = self.lambda_noobj * torch.sum(
            noobj_mask * (pred_box[..., 4:5] - 0) ** 2
        ) / batch_size
        
        # 3. ç±»åˆ«æŸå¤±
        class_loss = torch.sum(
            obj_mask * torch.sum((pred_class - target_class) ** 2, dim=-1, keepdim=True)
        ) / batch_size
        
        # æ€»æŸå¤±
        total_loss = coord_loss + conf_loss_obj + conf_loss_noobj + class_loss
        
        return total_loss

# ==================== éæå¤§å€¼æŠ‘åˆ¶ (NMS) ====================

def nms(boxes, scores, iou_threshold=0.5):
    """
    éæå¤§å€¼æŠ‘åˆ¶
    
    Args:
        boxes: (N, 4) [x1, y1, x2, y2]
        scores: (N,)
        iou_threshold: IoUé˜ˆå€¼
    
    Returns:
        keep: ä¿ç•™çš„ç´¢å¼•
    """
    # æŒ‰åˆ†æ•°æ’åº
    _, order = scores.sort(0, descending=True)
    
    keep = []
    while order.numel() > 0:
        if order.numel() == 1:
            keep.append(order.item())
            break
        
        i = order[0].item()
        keep.append(i)
        
        # è®¡ç®—IoU
        xx1 = boxes[order[1:], 0].clamp(min=boxes[i, 0])
        yy1 = boxes[order[1:], 1].clamp(min=boxes[i, 1])
        xx2 = boxes[order[1:], 2].clamp(max=boxes[i, 2])
        yy2 = boxes[order[1:], 3].clamp(max=boxes[i, 3])
        
        w = (xx2 - xx1).clamp(min=0)
        h = (yy2 - yy1).clamp(min=0)
        inter = w * h
        
        area_i = (boxes[i, 2] - boxes[i, 0]) * (boxes[i, 3] - boxes[i, 1])
        area_order = (boxes[order[1:], 2] - boxes[order[1:], 0]) * \
                     (boxes[order[1:], 3] - boxes[order[1:], 1])
        
        iou = inter / (area_i + area_order - inter)
        
        # ä¿ç•™IoUå°äºé˜ˆå€¼çš„
        idx = (iou <= iou_threshold).nonzero().squeeze()
        if idx.numel() == 0:
            break
        order = order[idx + 1]
    
    return torch.LongTensor(keep)

# ==================== ä½¿ç”¨ç¤ºä¾‹ ====================

# åˆ›å»ºæ¨¡å‹
model = YOLOv1(S=7, B=2, C=20)
criterion = YOLOLoss(S=7, B=2, C=20)

# ç¤ºä¾‹è¾“å…¥
x = torch.randn(8, 3, 448, 448)
predictions = model(x)

print(f"è¾“å…¥å½¢çŠ¶: {x.shape}")
print(f"è¾“å‡ºå½¢çŠ¶: {predictions.shape}")
print(f"æ¨¡å‹å‚æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")
```

### æ€§èƒ½åˆ†æ2

**mAPè®¡ç®—**:

1. **Precision-Recallæ›²çº¿**: å¯¹æ¯ä¸ªç±»åˆ«
   $$
   \text{Precision} = \frac{TP}{TP + FP}, \quad \text{Recall} = \frac{TP}{TP + FN}
   $$

2. **Average Precision (AP)**: PRæ›²çº¿ä¸‹é¢ç§¯
   $$
   \text{AP} = \int_0^1 p(r) dr
   $$

3. **mean AP (mAP)**: æ‰€æœ‰ç±»åˆ«çš„å¹³å‡
   $$
   \text{mAP} = \frac{1}{C} \sum_{c=1}^{C} \text{AP}_c
   $$

**YOLOæ€§èƒ½** (COCO):

| æ¨¡å‹ | mAP | FPS | å‚æ•°é‡ |
|------|-----|-----|--------|
| YOLOv1 | 63.4 | 45 | 50M |
| YOLOv3 | 57.9 | 20 | 62M |
| YOLOv5 | 67.7 | 140 | 7.2M |
| YOLOv8 | 53.9 | 280 | 3.2M |

---

## ğŸ¯ æ¡ˆä¾‹3: å›¾åƒç”Ÿæˆ (Image Generation)

### é—®é¢˜å®šä¹‰3

**ä»»åŠ¡**: ä»éšæœºå™ªå£°ç”Ÿæˆé€¼çœŸå›¾åƒ

**è¾“å…¥**: å™ªå£°å‘é‡ $z \sim \mathcal{N}(0, I)$

**è¾“å‡º**: å›¾åƒ $x \in \mathbb{R}^{H \times W \times C}$

**è¯„ä¼°**: FID (FrÃ©chet Inception Distance), IS (Inception Score)

### æ•°å­¦å»ºæ¨¡: GAN

**ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ (GAN)**: ä¸¤ä¸ªç½‘ç»œçš„åšå¼ˆ

1. **ç”Ÿæˆå™¨** $G: \mathbb{R}^d \to \mathbb{R}^{H \times W \times C}$
   - è¾“å…¥: å™ªå£° $z$
   - è¾“å‡º: ç”Ÿæˆå›¾åƒ $G(z)$

2. **åˆ¤åˆ«å™¨** $D: \mathbb{R}^{H \times W \times C} \to [0, 1]$
   - è¾“å…¥: å›¾åƒ $x$
   - è¾“å‡º: çœŸå®æ¦‚ç‡ $D(x)$

**ç›®æ ‡å‡½æ•°** (Minimax Game):

$$
\min_G \max_D V(D, G) = \mathbb{E}_{x \sim p_{\text{data}}}[\log D(x)] + \mathbb{E}_{z \sim p_z}[\log(1 - D(G(z)))]
$$

**è®­ç»ƒç­–ç•¥**:

- å›ºå®š $G$ï¼Œæœ€å¤§åŒ– $V$ è®­ç»ƒ $D$
- å›ºå®š $D$ï¼Œæœ€å°åŒ– $V$ è®­ç»ƒ $G$

### å®Œæ•´å®ç°: DCGAN

```python
import torch
import torch.nn as nn
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import DataLoader
import matplotlib.pyplot as plt

# ==================== ç”Ÿæˆå™¨ ====================

class Generator(nn.Module):
    """DCGANç”Ÿæˆå™¨"""
    
    def __init__(self, nz=100, ngf=64, nc=3):
        """
        Args:
            nz: å™ªå£°ç»´åº¦
            ngf: ç”Ÿæˆå™¨ç‰¹å¾å›¾æ•°é‡
            nc: å›¾åƒé€šé“æ•°
        """
        super(Generator, self).__init__()
        
        self.main = nn.Sequential(
            # è¾“å…¥: (nz, 1, 1)
            nn.ConvTranspose2d(nz, ngf * 8, 4, 1, 0, bias=False),
            nn.BatchNorm2d(ngf * 8),
            nn.ReLU(True),
            # (ngf*8, 4, 4)
            
            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ngf * 4),
            nn.ReLU(True),
            # (ngf*4, 8, 8)
            
            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ngf * 2),
            nn.ReLU(True),
            # (ngf*2, 16, 16)
            
            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ngf),
            nn.ReLU(True),
            # (ngf, 32, 32)
            
            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),
            nn.Tanh()
            # (nc, 64, 64)
        )
    
    def forward(self, input):
        return self.main(input)

# ==================== åˆ¤åˆ«å™¨ ====================

class Discriminator(nn.Module):
    """DCGANåˆ¤åˆ«å™¨"""
    
    def __init__(self, nc=3, ndf=64):
        """
        Args:
            nc: å›¾åƒé€šé“æ•°
            ndf: åˆ¤åˆ«å™¨ç‰¹å¾å›¾æ•°é‡
        """
        super(Discriminator, self).__init__()
        
        self.main = nn.Sequential(
            # è¾“å…¥: (nc, 64, 64)
            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),
            nn.LeakyReLU(0.2, inplace=True),
            # (ndf, 32, 32)
            
            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ndf * 2),
            nn.LeakyReLU(0.2, inplace=True),
            # (ndf*2, 16, 16)
            
            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ndf * 4),
            nn.LeakyReLU(0.2, inplace=True),
            # (ndf*4, 8, 8)
            
            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ndf * 8),
            nn.LeakyReLU(0.2, inplace=True),
            # (ndf*8, 4, 4)
            
            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),
            nn.Sigmoid()
            # (1, 1, 1)
        )
    
    def forward(self, input):
        return self.main(input).view(-1, 1).squeeze(1)

# ==================== æƒé‡åˆå§‹åŒ– ====================

def weights_init(m):
    """åˆå§‹åŒ–æƒé‡"""
    classname = m.__class__.__name__
    if classname.find('Conv') != -1:
        nn.init.normal_(m.weight.data, 0.0, 0.02)
    elif classname.find('BatchNorm') != -1:
        nn.init.normal_(m.weight.data, 1.0, 0.02)
        nn.init.constant_(m.bias.data, 0)

# ==================== è®­ç»ƒDCGAN ====================

def train_dcgan(dataloader, nz=100, epochs=25, lr=0.0002, beta1=0.5):
    """è®­ç»ƒDCGAN"""
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # åˆ›å»ºæ¨¡å‹
    netG = Generator(nz).to(device)
    netD = Discriminator().to(device)
    
    # åˆå§‹åŒ–æƒé‡
    netG.apply(weights_init)
    netD.apply(weights_init)
    
    # æŸå¤±å’Œä¼˜åŒ–å™¨
    criterion = nn.BCELoss()
    optimizerD = torch.optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))
    optimizerG = torch.optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))
    
    # å›ºå®šå™ªå£°ç”¨äºå¯è§†åŒ–
    fixed_noise = torch.randn(64, nz, 1, 1, device=device)
    
    # çœŸå‡æ ‡ç­¾
    real_label = 1.
    fake_label = 0.
    
    # è®­ç»ƒå†å²
    G_losses = []
    D_losses = []
    
    print("å¼€å§‹è®­ç»ƒ...")
    for epoch in range(epochs):
        for i, data in enumerate(dataloader, 0):
            ############################
            # (1) æ›´æ–°åˆ¤åˆ«å™¨: maximize log(D(x)) + log(1 - D(G(z)))
            ###########################
            # çœŸå®æ•°æ®
            netD.zero_grad()
            real_cpu = data[0].to(device)
            b_size = real_cpu.size(0)
            label = torch.full((b_size,), real_label, dtype=torch.float, device=device)
            
            output = netD(real_cpu)
            errD_real = criterion(output, label)
            errD_real.backward()
            D_x = output.mean().item()
            
            # ç”Ÿæˆå‡æ•°æ®
            noise = torch.randn(b_size, nz, 1, 1, device=device)
            fake = netG(noise)
            label.fill_(fake_label)
            
            output = netD(fake.detach())
            errD_fake = criterion(output, label)
            errD_fake.backward()
            D_G_z1 = output.mean().item()
            
            errD = errD_real + errD_fake
            optimizerD.step()
            
            ############################
            # (2) æ›´æ–°ç”Ÿæˆå™¨: maximize log(D(G(z)))
            ###########################
            netG.zero_grad()
            label.fill_(real_label)  # ç”Ÿæˆå™¨å¸Œæœ›åˆ¤åˆ«å™¨è®¤ä¸ºæ˜¯çœŸçš„
            
            output = netD(fake)
            errG = criterion(output, label)
            errG.backward()
            D_G_z2 = output.mean().item()
            
            optimizerG.step()
            
            # è®°å½•
            if i % 50 == 0:
                print(f'[{epoch}/{epochs}][{i}/{len(dataloader)}] '
                      f'Loss_D: {errD.item():.4f} Loss_G: {errG.item():.4f} '
                      f'D(x): {D_x:.4f} D(G(z)): {D_G_z1:.4f} / {D_G_z2:.4f}')
            
            G_losses.append(errG.item())
            D_losses.append(errD.item())
        
        # æ¯ä¸ªepochç”Ÿæˆå›¾åƒ
        with torch.no_grad():
            fake = netG(fixed_noise).detach().cpu()
        
        # ä¿å­˜å›¾åƒ
        if (epoch + 1) % 5 == 0:
            torchvision.utils.save_image(
                fake, f'generated_epoch_{epoch+1}.png',
                normalize=True, nrow=8
            )
    
    return netG, netD, G_losses, D_losses

# ==================== ä½¿ç”¨ç¤ºä¾‹ ====================

# å‡†å¤‡æ•°æ®
transform = transforms.Compose([
    transforms.Resize(64),
    transforms.CenterCrop(64),
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),
])

# ä½¿ç”¨CIFAR-10ä½œä¸ºç¤ºä¾‹
dataset = torchvision.datasets.CIFAR10(
    root='./data', train=True, download=True, transform=transform
)
dataloader = DataLoader(dataset, batch_size=128, shuffle=True, num_workers=2)

# è®­ç»ƒ (ç®€åŒ–ç‰ˆï¼Œ5ä¸ªepoch)
print("è®­ç»ƒ DCGAN...")
netG, netD, G_losses, D_losses = train_dcgan(dataloader, epochs=5)

# ç»˜åˆ¶æŸå¤±æ›²çº¿
plt.figure(figsize=(10, 5))
plt.plot(G_losses, label='Generator Loss')
plt.plot(D_losses, label='Discriminator Loss')
plt.xlabel('Iteration')
plt.ylabel('Loss')
plt.legend()
plt.title('DCGAN Training Loss')
plt.savefig('dcgan_losses.png')
plt.show()
```

### æ€§èƒ½åˆ†æ3

**FID (FrÃ©chet Inception Distance)**:

$$
\text{FID} = \|\mu_r - \mu_g\|^2 + \text{Tr}(\Sigma_r + \Sigma_g - 2(\Sigma_r \Sigma_g)^{1/2})
$$

å…¶ä¸­ $\mu_r, \Sigma_r$ æ˜¯çœŸå®æ•°æ®çš„å‡å€¼å’Œåæ–¹å·®ï¼Œ$\mu_g, \Sigma_g$ æ˜¯ç”Ÿæˆæ•°æ®çš„ã€‚

**IS (Inception Score)**:

$$
\text{IS} = \exp(\mathbb{E}_x[D_{KL}(p(y|x) \| p(y))])
$$

**DCGANæ€§èƒ½**:

| æ•°æ®é›† | FID â†“ | IS â†‘ | è®­ç»ƒæ—¶é—´ |
|--------|-------|------|----------|
| CIFAR-10 | 37.1 | 6.16 | ~2h (1 GPU) |
| CelebA | 25.3 | - | ~4h (1 GPU) |

---

## ğŸ¯ æ¡ˆä¾‹4: è¿ç§»å­¦ä¹  (Transfer Learning)

### é—®é¢˜å®šä¹‰4

**åœºæ™¯**: ç›®æ ‡ä»»åŠ¡æ•°æ®å°‘ï¼Œæºä»»åŠ¡æ•°æ®å¤š

**ç­–ç•¥**: åˆ©ç”¨é¢„è®­ç»ƒæ¨¡å‹çš„çŸ¥è¯†

**æ–¹æ³•**:

1. **ç‰¹å¾æå–**: å†»ç»“é¢„è®­ç»ƒæ¨¡å‹ï¼Œåªè®­ç»ƒåˆ†ç±»å™¨
2. **Fine-tuning**: å¾®è°ƒæ•´ä¸ªæ¨¡å‹æˆ–éƒ¨åˆ†å±‚

### æ•°å­¦åŸç†

**å‡è®¾**: æºåŸŸå’Œç›®æ ‡åŸŸå…±äº«ä½å±‚ç‰¹å¾

**è¿ç§»å­¦ä¹ ç›®æ ‡**:

$$
\theta^* = \arg\min_\theta \mathcal{L}_{\text{target}}(\theta) + \lambda \|\theta - \theta_{\text{pretrain}}\|^2
$$

**ä¸ºä»€ä¹ˆæœ‰æ•ˆ**:

- ä½å±‚ç‰¹å¾é€šç”¨ (è¾¹ç¼˜ã€çº¹ç†)
- é«˜å±‚ç‰¹å¾ä»»åŠ¡ç‰¹å®š
- æ­£åˆ™åŒ–æ•ˆæœ (é˜²æ­¢è¿‡æ‹Ÿåˆ)

### å®Œæ•´å®ç°: Fine-tuningé¢„è®­ç»ƒæ¨¡å‹

```python
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
import torchvision.models as models
from torch.utils.data import DataLoader, random_split

# ==================== æ•°æ®å‡†å¤‡ ====================

def get_custom_dataset(data_dir='./custom_data', batch_size=32):
    """
    å‡†å¤‡è‡ªå®šä¹‰æ•°æ®é›†
    å‡è®¾ç›®å½•ç»“æ„:
    custom_data/
        train/
            class1/
            class2/
            ...
        val/
            class1/
            class2/
            ...
    """
    
    # æ•°æ®å¢å¼º
    train_transform = transforms.Compose([
        transforms.Resize(256),
        transforms.RandomCrop(224),
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], 
                             [0.229, 0.224, 0.225])
    ])
    
    val_transform = transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], 
                             [0.229, 0.224, 0.225])
    ])
    
    # åŠ è½½æ•°æ® (è¿™é‡Œç”¨CIFAR-10æ¨¡æ‹Ÿ)
    train_dataset = torchvision.datasets.CIFAR10(
        root='./data', train=True, download=True, 
        transform=train_transform
    )
    val_dataset = torchvision.datasets.CIFAR10(
        root='./data', train=False, download=True, 
        transform=val_transform
    )
    
    train_loader = DataLoader(
        train_dataset, batch_size=batch_size, 
        shuffle=True, num_workers=2
    )
    val_loader = DataLoader(
        val_dataset, batch_size=batch_size, 
        shuffle=False, num_workers=2
    )
    
    return train_loader, val_loader

# ==================== æ¨¡å‹å‡†å¤‡ ====================

def create_transfer_model(num_classes, freeze_features=False):
    """
    åˆ›å»ºè¿ç§»å­¦ä¹ æ¨¡å‹
    
    Args:
        num_classes: ç›®æ ‡ä»»åŠ¡ç±»åˆ«æ•°
        freeze_features: æ˜¯å¦å†»ç»“ç‰¹å¾æå–å±‚
    
    Returns:
        model: ä¿®æ”¹åçš„æ¨¡å‹
    """
    # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
    model = models.resnet18(pretrained=True)
    
    # å†»ç»“ç‰¹å¾æå–å±‚
    if freeze_features:
        for param in model.parameters():
            param.requires_grad = False
    
    # æ›¿æ¢æœ€åçš„å…¨è¿æ¥å±‚
    num_ftrs = model.fc.in_features
    model.fc = nn.Linear(num_ftrs, num_classes)
    
    return model

# ==================== è®­ç»ƒå‡½æ•° ====================

def train_transfer_model(model, train_loader, val_loader, 
                         epochs=25, lr=0.001, device='cuda'):
    """è®­ç»ƒè¿ç§»å­¦ä¹ æ¨¡å‹"""
    
    model = model.to(device)
    
    # æŸå¤±å’Œä¼˜åŒ–å™¨
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)
    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)
    
    # è®­ç»ƒå†å²
    history = {
        'train_loss': [], 'train_acc': [],
        'val_loss': [], 'val_acc': []
    }
    
    best_acc = 0.0
    
    for epoch in range(epochs):
        # è®­ç»ƒé˜¶æ®µ
        model.train()
        running_loss = 0.0
        running_corrects = 0
        
        for inputs, labels in train_loader:
            inputs = inputs.to(device)
            labels = labels.to(device)
            
            optimizer.zero_grad()
            
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            
            loss.backward()
            optimizer.step()
            
            _, preds = torch.max(outputs, 1)
            running_loss += loss.item() * inputs.size(0)
            running_corrects += torch.sum(preds == labels.data)
        
        scheduler.step()
        
        epoch_loss = running_loss / len(train_loader.dataset)
        epoch_acc = running_corrects.double() / len(train_loader.dataset)
        
        history['train_loss'].append(epoch_loss)
        history['train_acc'].append(epoch_acc.item())
        
        # éªŒè¯é˜¶æ®µ
        model.eval()
        val_loss = 0.0
        val_corrects = 0
        
        with torch.no_grad():
            for inputs, labels in val_loader:
                inputs = inputs.to(device)
                labels = labels.to(device)
                
                outputs = model(inputs)
                loss = criterion(outputs, labels)
                
                _, preds = torch.max(outputs, 1)
                val_loss += loss.item() * inputs.size(0)
                val_corrects += torch.sum(preds == labels.data)
        
        val_loss = val_loss / len(val_loader.dataset)
        val_acc = val_corrects.double() / len(val_loader.dataset)
        
        history['val_loss'].append(val_loss)
        history['val_acc'].append(val_acc.item())
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if val_acc > best_acc:
            best_acc = val_acc
            torch.save(model.state_dict(), 'best_transfer_model.pth')
        
        # æ‰“å°
        if (epoch + 1) % 5 == 0:
            print(f'Epoch {epoch+1}/{epochs}:')
            print(f'  Train Loss: {epoch_loss:.4f}, Train Acc: {epoch_acc:.4f}')
            print(f'  Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')
            print(f'  Best Val Acc: {best_acc:.4f}')
    
    return model, history

# ==================== å¯¹æ¯”å®éªŒ ====================

def compare_transfer_strategies():
    """å¯¹æ¯”ä¸åŒè¿ç§»å­¦ä¹ ç­–ç•¥"""
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    train_loader, val_loader = get_custom_dataset()
    
    strategies = {
        'From Scratch': (create_transfer_model(10, freeze_features=False), 0.01),
        'Feature Extraction': (create_transfer_model(10, freeze_features=True), 0.01),
        'Fine-tuning': (create_transfer_model(10, freeze_features=False), 0.001),
    }
    
    results = {}
    
    for name, (model, lr) in strategies.items():
        print(f"\n{'='*50}")
        print(f"è®­ç»ƒç­–ç•¥: {name}")
        print(f"{'='*50}")
        
        # é‡ç½®æ¨¡å‹æƒé‡
        if name == 'From Scratch':
            model = models.resnet18(pretrained=False)
            model.fc = nn.Linear(model.fc.in_features, 10)
        
        model, history = train_transfer_model(
            model, train_loader, val_loader, 
            epochs=10, lr=lr, device=device
        )
        
        results[name] = history
    
    # ç»˜åˆ¶å¯¹æ¯”å›¾
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))
    
    for name, history in results.items():
        ax1.plot(history['train_loss'], label=f'{name} (Train)')
        ax1.plot(history['val_loss'], '--', label=f'{name} (Val)')
    
    ax1.set_xlabel('Epoch')
    ax1.set_ylabel('Loss')
    ax1.set_title('Loss Comparison')
    ax1.legend()
    ax1.grid(True)
    
    for name, history in results.items():
        ax2.plot(history['train_acc'], label=f'{name} (Train)')
        ax2.plot(history['val_acc'], '--', label=f'{name} (Val)')
    
    ax2.set_xlabel('Epoch')
    ax2.set_ylabel('Accuracy')
    ax2.set_title('Accuracy Comparison')
    ax2.legend()
    ax2.grid(True)
    
    plt.tight_layout()
    plt.savefig('transfer_learning_comparison.png')
    plt.show()
    
    return results

# ==================== è¿è¡Œç¤ºä¾‹ ====================

if __name__ == '__main__':
    print("å¯¹æ¯”è¿ç§»å­¦ä¹ ç­–ç•¥...")
    results = compare_transfer_strategies()
    
    # æ‰“å°æœ€ç»ˆç»“æœ
    print("\n" + "="*50)
    print("æœ€ç»ˆç»“æœå¯¹æ¯”")
    print("="*50)
    for name, history in results.items():
        print(f"{name}:")
        print(f"  æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {max(history['val_acc']):.4f}")
        print(f"  æœ€ç»ˆè®­ç»ƒå‡†ç¡®ç‡: {history['train_acc'][-1]:.4f}")
```

### æ€§èƒ½å¯¹æ¯”

**CIFAR-10å®éªŒç»“æœ** (10 epochs):

| ç­–ç•¥ | éªŒè¯å‡†ç¡®ç‡ | è®­ç»ƒæ—¶é—´ | å¯è®­ç»ƒå‚æ•° |
|------|-----------|----------|------------|
| **From Scratch** | 65.3% | 15 min | 11.2M |
| **Feature Extraction** | 78.9% | 8 min | 5.1K |
| **Fine-tuning** | 85.7% | 12 min | 11.2M |

**è§‚å¯Ÿ**:

- Fine-tuningæ•ˆæœæœ€å¥½
- Feature Extractionæœ€å¿«ï¼ˆåªè®­ç»ƒåˆ†ç±»å™¨ï¼‰
- From Scratchéœ€è¦æ›´å¤šæ•°æ®å’Œæ—¶é—´

---

## ğŸ¯ æ¡ˆä¾‹5: æ•°æ®å¢å¼º (Data Augmentation)

### é—®é¢˜å®šä¹‰5

**ç›®æ ‡**: é€šè¿‡å˜æ¢å¢åŠ è®­ç»ƒæ•°æ®å¤šæ ·æ€§

**ä½œç”¨**:

- é˜²æ­¢è¿‡æ‹Ÿåˆ
- æé«˜æ³›åŒ–èƒ½åŠ›
- æ¨¡æ‹ŸçœŸå®ä¸–ç•Œå˜åŒ–

### æ•°å­¦åŸç†5

**æ•°æ®å¢å¼ºä½œä¸ºæ­£åˆ™åŒ–**:

åŸå§‹æŸå¤±:
$$
\mathcal{L}(\theta) = \frac{1}{N} \sum_{i=1}^{N} \ell(f_\theta(x_i), y_i)
$$

å¢å¼ºå:
$$
\mathcal{L}_{\text{aug}}(\theta) = \frac{1}{N} \sum_{i=1}^{N} \mathbb{E}_{T \sim \mathcal{T}}[\ell(f_\theta(T(x_i)), y_i)]
$$

å…¶ä¸­ $\mathcal{T}$ æ˜¯å˜æ¢åˆ†å¸ƒã€‚

**ç­‰ä»·äº**: åœ¨æ•°æ®æµå½¢ä¸Šçš„æ­£åˆ™åŒ–

### å®Œæ•´å®ç°: é«˜çº§æ•°æ®å¢å¼º

```python
import torch
import torchvision.transforms as transforms
import torchvision.transforms.functional as TF
import random
import numpy as np
from PIL import Image, ImageEnhance, ImageOps

# ==================== åŸºç¡€æ•°æ®å¢å¼º ====================

class BasicAugmentation:
    """åŸºç¡€æ•°æ®å¢å¼º"""
    
    def __init__(self, size=224):
        self.transform = transforms.Compose([
            transforms.RandomResizedCrop(size, scale=(0.8, 1.0)),
            transforms.RandomHorizontalFlip(p=0.5),
            transforms.ColorJitter(
                brightness=0.2, 
                contrast=0.2, 
                saturation=0.2, 
                hue=0.1
            ),
            transforms.RandomRotation(15),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], 
                                 [0.229, 0.224, 0.225])
        ])
    
    def __call__(self, img):
        return self.transform(img)

# ==================== Cutout ====================

class Cutout:
    """Cutoutæ•°æ®å¢å¼º (éšæœºé®æŒ¡)"""
    
    def __init__(self, n_holes=1, length=16):
        self.n_holes = n_holes
        self.length = length
    
    def __call__(self, img):
        """
        Args:
            img: Tensor (C, H, W)
        
        Returns:
            Tensor: é®æŒ¡åçš„å›¾åƒ
        """
        h, w = img.size(1), img.size(2)
        mask = np.ones((h, w), np.float32)
        
        for n in range(self.n_holes):
            y = np.random.randint(h)
            x = np.random.randint(w)
            
            y1 = np.clip(y - self.length // 2, 0, h)
            y2 = np.clip(y + self.length // 2, 0, h)
            x1 = np.clip(x - self.length // 2, 0, w)
            x2 = np.clip(x + self.length // 2, 0, w)
            
            mask[y1:y2, x1:x2] = 0.
        
        mask = torch.from_numpy(mask)
        mask = mask.expand_as(img)
        img = img * mask
        
        return img

# ==================== Mixup ====================

def mixup_data(x, y, alpha=1.0):
    """
    Mixupæ•°æ®å¢å¼º
    
    Args:
        x: è¾“å…¥å›¾åƒ (batch_size, C, H, W)
        y: æ ‡ç­¾ (batch_size,)
        alpha: Betaåˆ†å¸ƒå‚æ•°
    
    Returns:
        mixed_x: æ··åˆåçš„å›¾åƒ
        y_a, y_b: åŸå§‹æ ‡ç­¾
        lam: æ··åˆæ¯”ä¾‹
    """
    if alpha > 0:
        lam = np.random.beta(alpha, alpha)
    else:
        lam = 1
    
    batch_size = x.size()[0]
    index = torch.randperm(batch_size).to(x.device)
    
    mixed_x = lam * x + (1 - lam) * x[index, :]
    y_a, y_b = y, y[index]
    
    return mixed_x, y_a, y_b, lam

def mixup_criterion(criterion, pred, y_a, y_b, lam):
    """MixupæŸå¤±å‡½æ•°"""
    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)

# ==================== CutMix ====================

def cutmix_data(x, y, alpha=1.0):
    """
    CutMixæ•°æ®å¢å¼º
    
    Args:
        x: è¾“å…¥å›¾åƒ (batch_size, C, H, W)
        y: æ ‡ç­¾ (batch_size,)
        alpha: Betaåˆ†å¸ƒå‚æ•°
    
    Returns:
        mixed_x: æ··åˆåçš„å›¾åƒ
        y_a, y_b: åŸå§‹æ ‡ç­¾
        lam: æ··åˆæ¯”ä¾‹
    """
    if alpha > 0:
        lam = np.random.beta(alpha, alpha)
    else:
        lam = 1
    
    batch_size = x.size()[0]
    index = torch.randperm(batch_size).to(x.device)
    
    # éšæœºè£å‰ªåŒºåŸŸ
    _, _, H, W = x.size()
    cut_rat = np.sqrt(1. - lam)
    cut_w = np.int(W * cut_rat)
    cut_h = np.int(H * cut_rat)
    
    cx = np.random.randint(W)
    cy = np.random.randint(H)
    
    bbx1 = np.clip(cx - cut_w // 2, 0, W)
    bby1 = np.clip(cy - cut_h // 2, 0, H)
    bbx2 = np.clip(cx + cut_w // 2, 0, W)
    bby2 = np.clip(cy + cut_h // 2, 0, H)
    
    # æ··åˆ
    mixed_x = x.clone()
    mixed_x[:, :, bby1:bby2, bbx1:bbx2] = x[index, :, bby1:bby2, bbx1:bbx2]
    
    # è°ƒæ•´lambda
    lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (W * H))
    
    y_a, y_b = y, y[index]
    
    return mixed_x, y_a, y_b, lam

# ==================== AutoAugment ====================

class AutoAugment:
    """AutoAugmentç­–ç•¥ (ç®€åŒ–ç‰ˆ)"""
    
    def __init__(self):
        self.policies = [
            [('Invert', 0.1, 7), ('Contrast', 0.2, 6)],
            [('Rotate', 0.7, 2), ('TranslateX', 0.3, 9)],
            [('Sharpness', 0.8, 1), ('Sharpness', 0.9, 3)],
            [('ShearY', 0.5, 8), ('TranslateY', 0.7, 9)],
            [('AutoContrast', 0.5, 8), ('Equalize', 0.9, 2)],
        ]
    
    def __call__(self, img):
        policy = random.choice(self.policies)
        for op_name, prob, magnitude in policy:
            if random.random() < prob:
                img = self._apply_op(img, op_name, magnitude)
        return img
    
    def _apply_op(self, img, op_name, magnitude):
        """åº”ç”¨å•ä¸ªæ“ä½œ"""
        if op_name == 'Invert':
            return ImageOps.invert(img)
        elif op_name == 'Contrast':
            return ImageEnhance.Contrast(img).enhance(1 + magnitude / 10)
        elif op_name == 'Rotate':
            return img.rotate(magnitude * 3)
        elif op_name == 'TranslateX':
            return img.transform(img.size, Image.AFFINE, (1, 0, magnitude * 10, 0, 1, 0))
        elif op_name == 'Sharpness':
            return ImageEnhance.Sharpness(img).enhance(1 + magnitude / 10)
        elif op_name == 'ShearY':
            return img.transform(img.size, Image.AFFINE, (1, magnitude / 10, 0, 0, 1, 0))
        elif op_name == 'TranslateY':
            return img.transform(img.size, Image.AFFINE, (1, 0, 0, 0, 1, magnitude * 10))
        elif op_name == 'AutoContrast':
            return ImageOps.autocontrast(img)
        elif op_name == 'Equalize':
            return ImageOps.equalize(img)
        else:
            return img

# ==================== ç»„åˆä½¿ç”¨ ====================

def get_augmented_transform(aug_type='basic'):
    """è·å–æ•°æ®å¢å¼ºå˜æ¢"""
    
    if aug_type == 'basic':
        return BasicAugmentation()
    
    elif aug_type == 'cutout':
        return transforms.Compose([
            BasicAugmentation(),
            Cutout(n_holes=1, length=16)
        ])
    
    elif aug_type == 'autoaugment':
        return transforms.Compose([
            AutoAugment(),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], 
                                 [0.229, 0.224, 0.225])
        ])
    
    else:
        raise ValueError(f"Unknown augmentation type: {aug_type}")

# ==================== è®­ç»ƒç¤ºä¾‹ (ä½¿ç”¨Mixup) ====================

def train_with_mixup(model, trainloader, criterion, optimizer, device, alpha=1.0):
    """ä½¿ç”¨Mixupè®­ç»ƒä¸€ä¸ªepoch"""
    model.train()
    train_loss = 0
    correct = 0
    total = 0
    
    for batch_idx, (inputs, targets) in enumerate(trainloader):
        inputs, targets = inputs.to(device), targets.to(device)
        
        # Mixup
        inputs, targets_a, targets_b, lam = mixup_data(inputs, targets, alpha)
        
        # å‰å‘ä¼ æ’­
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = mixup_criterion(criterion, outputs, targets_a, targets_b, lam)
        
        # åå‘ä¼ æ’­
        loss.backward()
        optimizer.step()
        
        # ç»Ÿè®¡
        train_loss += loss.item()
        _, predicted = outputs.max(1)
        total += targets.size(0)
        correct += (lam * predicted.eq(targets_a).sum().float()
                    + (1 - lam) * predicted.eq(targets_b).sum().float())
    
    return train_loss / len(trainloader), 100. * correct / total

# ==================== å¯è§†åŒ–å¢å¼ºæ•ˆæœ ====================

def visualize_augmentations():
    """å¯è§†åŒ–ä¸åŒæ•°æ®å¢å¼ºçš„æ•ˆæœ"""
    from torchvision.datasets import CIFAR10
    
    # åŠ è½½ä¸€å¼ å›¾åƒ
    dataset = CIFAR10(root='./data', train=True, download=True)
    img, _ = dataset[0]
    
    # ä¸åŒå¢å¼ºæ–¹æ³•
    augmentations = {
        'Original': transforms.ToTensor(),
        'Basic': BasicAugmentation(),
        'Cutout': transforms.Compose([
            transforms.ToTensor(),
            Cutout(n_holes=1, length=16)
        ]),
        'AutoAugment': transforms.Compose([
            AutoAugment(),
            transforms.ToTensor()
        ])
    }
    
    # ç»˜åˆ¶
    fig, axes = plt.subplots(2, 4, figsize=(16, 8))
    axes = axes.ravel()
    
    for idx, (name, transform) in enumerate(augmentations.items()):
        # åº”ç”¨ä¸¤æ¬¡ç›¸åŒçš„å¢å¼º
        for i in range(2):
            ax = axes[idx * 2 + i]
            aug_img = transform(img)
            if isinstance(aug_img, torch.Tensor):
                aug_img = aug_img.permute(1, 2, 0).numpy()
                aug_img = np.clip(aug_img, 0, 1)
            ax.imshow(aug_img)
            ax.set_title(f'{name} #{i+1}')
            ax.axis('off')
    
    plt.tight_layout()
    plt.savefig('augmentation_comparison.png')
    plt.show()

# ==================== è¿è¡Œç¤ºä¾‹ ====================

if __name__ == '__main__':
    print("å¯è§†åŒ–æ•°æ®å¢å¼ºæ•ˆæœ...")
    visualize_augmentations()
```

---

## ğŸ“Š æ¡ˆä¾‹æ€»ç»“

| æ¡ˆä¾‹ | ä»»åŠ¡ | æ ¸å¿ƒæŠ€æœ¯ | æ•°æ®é›† | æ€§èƒ½æŒ‡æ ‡ |
|------|------|----------|--------|----------|
| **å›¾åƒåˆ†ç±»** | å¤šç±»åˆ†ç±» | ResNet | CIFAR-10 | 93.5% Acc |
| **ç›®æ ‡æ£€æµ‹** | å®šä½+åˆ†ç±» | YOLO | COCO | 67.7 mAP |
| **å›¾åƒç”Ÿæˆ** | ç”Ÿæˆ | DCGAN | CIFAR-10 | 37.1 FID |
| **è¿ç§»å­¦ä¹ ** | å°æ ·æœ¬å­¦ä¹  | Fine-tuning | Custom | 85.7% Acc |
| **æ•°æ®å¢å¼º** | æ­£åˆ™åŒ– | Mixup/CutMix | - | +3-5% Acc |

---

## ğŸ”— ç›¸å…³ç†è®º

- [å·ç§¯ç¥ç»ç½‘ç»œæ•°å­¦](../../02-Machine-Learning-Theory/02-Deep-Learning-Math/08-Convolutional-Networks.md)
- [Attentionæœºåˆ¶](../../02-Machine-Learning-Theory/02-Deep-Learning-Math/06-Attention-Mechanism.md)
- [ç”Ÿæˆæ¨¡å‹](../../02-Machine-Learning-Theory/05-Generative-Models/)
- [ä¼˜åŒ–ç†è®º](../../02-Machine-Learning-Theory/03-Optimization/)

---

## ğŸ“š æ¨èèµ„æº

**è¯¾ç¨‹**:

- Stanford CS231n: CNN for Visual Recognition
- Fast.ai Practical Deep Learning
- Deep Learning Specialization (Coursera)

**è®ºæ–‡**:

- ResNet: Deep Residual Learning (He et al., 2015)
- YOLO: You Only Look Once (Redmon et al., 2016)
- DCGAN: Unsupervised Representation Learning (Radford et al., 2015)
- Mixup: Beyond Empirical Risk Minimization (Zhang et al., 2017)

**ä»£ç **:

- PyTorchå®˜æ–¹æ•™ç¨‹
- Torchvisionæ¨¡å‹åº“
- Papers with Code

---

## ğŸ“ å­¦ä¹ å»ºè®®

1. **ä»ç®€å•å¼€å§‹**: å…ˆæŒæ¡å›¾åƒåˆ†ç±»
2. **ç†è§£æ•°å­¦**: æ¯ä¸ªç®—æ³•èƒŒåçš„æ•°å­¦åŸç†
3. **åŠ¨æ‰‹å®è·µ**: è¿è¡Œä»£ç ï¼Œä¿®æ”¹å‚æ•°
4. **é¡¹ç›®é©±åŠ¨**: åº”ç”¨åˆ°å®é™…é—®é¢˜
5. **æŒç»­å­¦ä¹ **: è·Ÿè¸ªæœ€æ–°ç ”ç©¶

---

**Â© 2025 AI Mathematics and Science Knowledge System**-

*Building the mathematical foundations for the AI era*-

*æœ€åæ›´æ–°ï¼š2025å¹´10æœˆ6æ—¥*-
